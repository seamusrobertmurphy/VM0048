[
  {
    "objectID": "assets/inputs/watershed_site.html",
    "href": "assets/inputs/watershed_site.html",
    "title": "VM0048",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "assets/inputs/lakes_site.html",
    "href": "assets/inputs/lakes_site.html",
    "title": "VM0048",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "assets/inputs/chilwa_watershed_4326.html",
    "href": "assets/inputs/chilwa_watershed_4326.html",
    "title": "VM0048",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n      GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "assets/inputs/rivers_site.html",
    "href": "assets/inputs/rivers_site.html",
    "title": "VM0048",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n         0 0     false"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Seamus Murphy",
    "section": "",
    "text": "Select Publications\n\nMurphy, S., Cole, S. M., Kaminski, A. M., Charo-Karisa, H., Basiita, R. K., McDougall, C., Kakwasha, K., Mulilo, T., Rajaratnam, S., & Mekkawy, W. (2024). A gendered conjoint analysis of tilapia trait preference rankings among urban consumers in Zambia: Evidence to inform genetic improvement programs. Aquaculture, 741110; https://doi.org/10.1016/j.aquaculture.2024.741110\nMcDougall, C, Kariuki, J, Lenjiso, B M, Pricilla, M, Mehar, M, Murphy, S, Teeken, B, Akester, M J, Benzie, J, Galie, A, Kulakow, P, Mekkawy, W, Nkengla-Asi, L, Ojango, J M K, Tumuhimbise, R, Umwimana, B, Orr, A. (2022). “Understanding gendered trait preferences: Implications for client-responsive breeding programs” Plos Sustain Transform 1 (8): e0000025. https://doi.org/10.1371/journal.pstr.0000025\nMurphy, S, Arora, D, Kruijssen, F, McDougall, C, P Kantor. (2020). “Gender-Based Market Constraints to Informal Fish Retailing: Evidence from Analysis of Variance and Linear Regression.” PloS ONE 15(3): e0229286. https://doi.org/10.1371/journal.pone.0229286\nMurphy, S, Charo-Karisa, H, Rajaratnam, S, Cole, S M, McDougall, C, Nasr-Allah, A, Kenawy, D, Zead, M Y A, van Brakel, M, L Banks. (2020). “Selective Breeding Trait Preferences for Farmed Tilapia among Low-Income Women and Men Consumers in Egypt; Implications for pro-Poor and Gender-Responsive Fish Breeding Programmes.” Aquaculture. 525: 735042 https://doi.org/10.1016/j.aquaculture.2020.735042\nNasr-Allah, A, Gasparatos, A, Karanja, A, Dompreh, E., Murphy, S, Rossignoli, C M., Philips, M, H Charo-Karisa. (2020). “Employment Generation in the Egyptian Aquaculture Value Chain: Implications for Meeting the Sustainable Development Goals (SDGs).” Aquaculture 520: 734940 https://doi.org/10.1016/j.aquaculture.2020.734940\nAdeleke, M L, Kenawy, D, Nasr-Allah, A, Murphy, S, El-Naggar, G, M Dickson. (2018). “Fish Farmers’ Perceptions, Impacts and Adaptation on/of/to Climate Change in Africa; The Case of Egypt and Nigeria”, in. Fátima Alves, Walter Leal Filho, and Ulisses Azeiteiro (eds.) Theory and Practice of Climate Adaptation, pp. 269–95. Springer International Publishing https://doi.org/10.1007/978-3-319-72874-2_16\nKaush, A, Cleaveland S, Omore A, Murphy S. (2015). Tanzanian Livestock Modernization Initiative; Preliminary Report (2015) Ministry of Livestock & Fisheries Development, CGIAR Repository of Agricultural Research Outputs: 1–38. https://cgspace.cgiar.org/handle/10568/67749\n\n \n  \n   \n  \n    \n     LinkedIn\n  \n  \n    \n     Github",
    "crumbs": [
      "Home",
      "About",
      "Resume"
    ]
  },
  {
    "objectID": "leakage.html#objective",
    "href": "leakage.html#objective",
    "title": "Leakage Belt",
    "section": "Objective:",
    "text": "Objective:\nThis report outlines the geospatial methodology implemented to delineate a VMD0055-compliant leakage belt for the Gola REDD+ Forest Carbon Project in Liberia. The work was conducted as part of the larger REDD+ feasibility assessment work aiming to inform the development and submission of a project proposal that aligns with Verra’s VM0048 project framework.1 Considering these directives and their future timelines, the following aimed to provide procedural guidelines for replicating this analysis and meeting the VM0048 standard. This included an overview of data sources reviewed and their qualifying criteria, methodological recommendations for documenting data processing tasks and reporting accuracy and performance metrics. Following this, we provide a summary of the project’s revised area estimates. In effect, as a result of recent area expansions into nearby community forests, the project’s total conservation zone increased by a factor of 6.04.\nThe project’s expansion necessitated identifying potential zones where deforestation pressures might shift due to enhanced conservation measures. We delineated a leakage belt from surrounding forestland meeting eligibility criteria defined in VM0048 and VMD0055 guidelines. These criteria include topographical constraints (slope gradients), anthropogenic factors (proximity to roads and settlements), and ecological considerations (excluding protected areas and wetlands), all aimed at ensuring the leakage area represents forests at risk of shifted deforestation rather than areas that would not normally face such pressures.\n\nProject Boundaries\n\nData imports:\n\nImported the Liberia national boundary and county shapefiles.2\nFiltered counties to select the Grand Cape Mount and Gharpolu jurisdictions, relevant for the REDD+ project area.\n\n\n\nData processing:\n\nA project coordinate system was declared as the EPSG:326293 projected reference system, encouraging best practices, while matching package requirements and avoiding delays in shapefile processing downstream.\nSpatial data validation was performed prior to area calculations, targeting geometry checks due to their material influence on two-dimensional measurements. This also follows best practice dealing with new shapefiles, or rather old shapefiles with longer lifespans and more extensive revisions, that tend to involve orphaned artifacts, topology errors, or schema issues affect compromising our\n\nWe checked for schema conformity and domain consistency, relational fields, and potential for vertical integration. The check reviewed internal rules, file naming conventions, data types and value ranges.\nReferencing OGC Standard (ISO, 2019),4 we conducted topology checks on polygonal structure and linework. Our screening identified 138 geometry violations, identifying 138 violations. These included overlapping borders, un-noded intersections, unclosed polygons, and 108 orphaned artifacts formed by banana polygons, self-touching holes, inverted shells, and dangling nodes. Geometry errors were extracted, corrected and recovered with the following functions run from a bash terminal deploying R, Python, and C++ libraries.\n\nsimplifyCoverageVW()5 This function employs the Visvalingam–Whyatt algorithm to address geometry complexity along polygon edges by reducing vertices by a specified tolerance. This is one of the more forgiving functions as processed polygons are simplified but never removed entirely. However, this means that minimal polygons may remain unchanged or convert to triangle geometries, and that coverages with invalid topology may not be screened from valid results.\ngeos::hausdorffDistance() The Hausdorff Distance function was employed to address similar problematic linework. However, it offers additional parameters allowing more precise estimates between polygon edges and target geometries, which better facilitates linework alignment using the snapping tool.\ngeos::maximumInscribedCircle() The Maximum Inscribed Circle algorithm is a useful function for locating the smallest and narrowest strips or slivers. As the naming suggests, it characterizes the invalid polygons based on the size of the largest circle that can fit inside them. This function is especially useful for dealing with high numbers of very small slivers, as found here. By specifying narrowness thresholds, it offers screening parameters that help identify the smallest of orphans sometimes invisible to the eye.\nsf::st_intersection()6 A personal favorite of mine, this function provides a popular tool for repairing geometry overlays, though it is better known by its use in clipping operations. Despite some key differences to more common methods, st_intersection() effectively decomposes and exposes objects of overlapping, nested, or self-intersecting geometries. Where it varies is in the function’s use of vertex-based indexing and its “valid_linework” approach that is unlike the “valid_structure” approach more commonly applied. As a result, the function proved instrumental to detecting smaller artifacts (&lt;100ha) that previously eluded cast() and other algorithms derived from structural rules and forms of polygons. By introducing two variables of n_overlap and origins to record vertex dependencies and self-intersections, the function elegantly exposes all overlapping slivers and embedded nodes, while also segmenting their invalid geometries, and enabling their easy extraction or recovery and reclassification into the valid network.\n\n\n\nArea Calculation:\n\nComputed total hectares of project sites.\nFinal area estimates were reported below which yielded a total project footprint of 769,050 ha in the newest expansion.\n\n\ncountry = sf::read_sf(\"/Users/seamus/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/AOI/Archive/Liberia-National-Border/liberia_boundary_national.shp\", quiet=TRUE) |&gt;sf::st_transform(32629)\n\ncounties = sf::st_read(\"/Users/seamus/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/AOI/Archive/Liberia-Jurisdiction-Boundaries/places_poly_county.shp\", quiet=TRUE) |&gt;sf::st_transform(32629)\n\njurisdiction = counties |&gt;dplyr::filter(name==\"Grand Cape Mount County\"|name==\"Gharpolu County\")\njurisdiction$name = 'Grand Cape Mount & Gharpolu Counties'\n\npop = sf::st_read(\"/Users/seamus/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/POP/Archive/Villages-Extended-Metric.gpkg\", quiet=TRUE) |&gt; sf::st_make_valid() |&gt; sf::st_cast(\"MULTIPOINT\")\n\naoi = sf::read_sf(\"/Users/seamus/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/AOI/Archive/ProjectArea_CF-Expansion_051525/updated_areas.shp\", quiet=TRUE) |&gt;\n  sf::st_make_valid() |&gt;\n  sf::st_transform(\"EPSG:32629\") |&gt;  \n  sf::st_cast(\"MULTIPOLYGON\") |&gt; sf::st_as_sf()# |&gt; dplyr::select(\"Name\")\n\n# check for hidden artefacts\nst_geometry_type(aoi)\naoi_valid &lt;- st_make_valid(aoi)\naoi_intersections &lt;- st_intersection(aoi_valid)\naoi_intersections$area_ha &lt;- round(as.numeric(st_area(aoi_intersections) * 0.0001), 3)\nartefacts &lt;- aoi_intersections %&gt;% filter(area_ha &lt; 100) |&gt; dplyr::select(-origins)\n\n# process artefacts \ntable(sf::st_geometry_type(artefacts))\nartefacts_points &lt;- artefacts %&gt;% filter(st_geometry_type(.) %in% c(\"POINT\", \"MULTIPOINT\"))\nartefacts_lines &lt;- artefacts %&gt;% filter(st_geometry_type(.) %in% c(\"LINESTRING\", \"MULTILINESTRING\"))\nartefacts_polygons &lt;- artefacts %&gt;% filter(st_geometry_type(.) %in% c(\"POLYGON\", \"MULTIPOLYGON\"))\nst_write(artefacts_points, \"./data/AOI/Archive/artefact_check_points.shp\", append=F, quiet=TRUE)\nst_write(artefacts_lines, \"./data/AOI/Archive/artefact_check_lines.shp\", append=F, quiet=TRUE)\nst_write(artefacts_polygons, \"./data/AOI/Archive/artefact_check_polygons.shp\", append=F, quiet=TRUE)\n\ncat(\"Points:\", nrow(artefacts_points), \"\\n\")\ncat(\"Lines:\", nrow(artefacts_lines), \"\\n\")\ncat(\"Polygons:\", nrow(artefacts_polygons), \"\\n\")\n\naoi$area_ha = round(as.numeric(sf::st_area(aoi) * 0.0001, 4))\naoi |&gt; sf::st_drop_geometry() |&gt; janitor::adorn_totals() |&gt; \n  flextable::flextable() |&gt; \n  flextable::fontsize(size=8,part=\"all\") |&gt; \n  flextable::autofit() \n\n\ntmap::tmap_mode(\"view\")\ntmap::tm_shape(aoi) + tmap::tm_borders(lwd=0.5, col=\"white\") +\n  tmap::tm_text(text=\"Name\", size=0.5, col=\"white\") +  \n  tmap::tm_shape(country) + tmap::tm_borders(lwd=0.8, col=\"orange\") +\n  tmap::tm_shape(counties) + tmap::tm_borders(lwd=1, col=\"brown\") +\n  tmap::tm_text(text=\"name\", size=0.8, col=\"brown\") +\n  tmap::tm_scalebar(position = c(\"RIGHT\", \"BOTTOM\"), text.size = .5) + \n  tmap::tm_basemap(\"Esri.WorldImagery\") +\n  tmap::tm_view(set_zoom_limits = c(8,14))\n\n\n\n\nDerive Leakage Belt\nImplemented per the VM0048 and VMD0055 methodologies, the leakage belt is defined as a buffer zone around the project area in which potential deforestation leakage will be monitored. The following steps were taken to delineate this belt in accordance with those requirements:\n\nLeakage belt radius:\n\nWe created an initial 5.5km buffer around the project’s area of interest (AOI), before a second buffer of the first was extended an additional 4.5 km outward. This two-step buffer operation was originally employed to smoothen buffer geometry that was produced by pockets of non-project area and complicated by complex perimeters of project sites.\nAll output geometries were checked and repaired systematically using the folloiwng three geometry corrections:\n\nst_cast(), st_zm(), st_make_valid() \n\n\n\nConcave Hull Application:\nThe concavehull() function was used to refine polygon edges by more accurately matching project perimeters where linework is more complex. Effectively, using a concave hull instead of a simple convex buffer ensures the leakage delineation addresses all indentations of the forest boundary and avoids convex gaps not adjacent to the project. \nLeakage Belt Finalization:\n\nCalculated intersection of leakage buffer with the national boundary to define eligible leakage areas.\nComputed final area (ha) for monitoring maximum and mininum thresholds.\n\n\n\nleakage_belt         = sf::st_difference(leakage_belt_whole, st_union(st_combine(aoi_union)))\nleakage_belt$area_ha = round(as.numeric(sf::st_area(leakage_belt) * 0.0001, 4)) \nleakage_belt         = sf::st_intersection(country, leakage_belt)\n\ntmap::tmap_mode(\"view\")\ntmap::tm_shape(leakage_belt) + \n  tmap::tm_polygons(col=\"yellow\",fill=\"yellow\",fill_alpha=0.3)+\n  tmap::tm_shape(aoi) + tmap::tm_borders(lwd=0.4, col=\"white\") + \n  tmap::tm_text(text=\"Name\", size=0.5, col=\"white\") +\n  tmap::tm_basemap(\"Esri.WorldImagery\")\n\n# save locally\n#sf::wt_write(leakage_belt, \"OneDrive.../20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/LEAKAGE/Archive/LeakageBelt_10k-Radius_UnFiltered.zip\") \n#sf::st_write(leakage_belt_whole, \"OneDrive.../20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/LEAKAGE/Archive/LeakageBelt_10k-Radius_UnFiltered-Whole.shp\")\n\n\n\n\nDerive Leakage Masks\nAfter delineating the initial 10 km leakage belt, we applied a series of exclusion masks to remove areas that are not eligible for leakage accounting as per VM0048/VMD0055 criteria. The creation of these masks ensures that the final leakage belt includes only areas where project-related leakage could occur, excluding areas where deforestation is unlikely or not attributable to project activities. Both VM0048 and VMD0055 explicitly stipulate the removal of certain land categories from the leakage belt to ensure accurate and conservative leakage monitoring. In practice, this meant excluding zones near major roads, wetlands, steep slopes, and existing protected areas. Verra’s guidance also emphasizes confirming the legal definitions and extents of these excluded areas in consultation with local stakeholders and authorities. Notably, spatial datasets for features like wetlands, rural roads, and community protection areas can be highly variable in quality; thus, our mask development included careful verification to align with official definitions and the latest available data. Below, we detail the construction of each mask layer:\n\nRoads Mask\nFollowing leakage belt exclusion criteria outlined in VMD0055, we removed areas that were located within 10km of road infrastructure. This was implemented to reduce false-positive leakage signals.\nImplementation steps:\n\nRoad Data Processing:\n\nImported and validated two road datasets and checked for geometry errors or merging issues.\nThe Douglas-Peucker algorithm7 was employed on larger datasets to reduce computational load by simplifying vertex networks, while maintaining structural and linework integrity.\n\nBuffering roads:\n\nCreated 10 km buffer around roads with simplified geometries to produce a leakage exclusion mask.\nUnified separate buffers into a single comprehensive road mask for spatial consistency.\n\n\n\nroads_ext = sf::st_read(\"/Users/seamus/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/ROADS/Archive/Roads_Gola_RSPB-OSM-Combined/Roads_Gola_RSPB-OSM-Merged.shp\") |&gt; \n  sf::st_make_valid() |&gt; sf::st_cast(\"MULTILINESTRING\") |&gt; rmapshaper::ms_simplify(keep=0.5)\nroads_one = sf::st_read(\"~/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/ROADS/Archive/roads_simplified_one.shp\")\nroads_two = sf::st_read(\"~/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/ROADS/Archive/roads_simplified_two.shp\")\n\n# we have simplify mask shapefiles and split them up to shorten computing \n# time & avoid crashing. See option for \"harsh\" simplification on line 163\nroads_one_simplified = roads_one |&gt; sf::st_make_valid() |&gt; sf::st_cast(\"MULTILINESTRING\") |&gt; \n  rmapshaper::ms_simplify(keep=0.5)\nroads_two_simplified = roads_two |&gt; sf::st_make_valid() |&gt; sf::st_cast(\"MULTILINESTRING\") |&gt; \n  rmapshaper::ms_simplify(keep=0.5)\n\n# bigger file needs more simplificaiotn\nroads_one_simplified_harsh = rmapshaper::ms_simplify(\n  roads_one_simplified, keep=0.01) \n\n# now apply buffer operation, but note this takes time. Its \n# advised processing inputs as much as possible before running\nroads_one_buffer = sf::st_buffer(\n  roads_one_simplified_harsh, \n  dist = 10000, \n  nQuadSegs = 5,\n  endCapStyle=\"ROUND\", \n  joinStyle = \"ROUND\",\n  mitreLimit = 1,\n  singleSide = FALSE\n  )\n\nroads_two_buffer = sf::st_buffer(\n  roads_two_simplified, \n  dist = 10000, \n  nQuadSegs = 5,\n  endCapStyle=\"ROUND\", \n  joinStyle = \"ROUND\",\n  mitreLimit = 1,\n  singleSide = FALSE\n  )\n\n# Combine, dissolve and cast to single feature\nroads_mask = sf::st_combine(roads_one_buffer, roads_two_buffer) |&gt;\n  sf::st_union() |&gt; sf::st_cast(\"POLYGON\")\n\n# Visual check\ntmap::tmap_mode(\"view\")\ntmap::tm_shape(roads_mask) + tmap::tm_borders(lwd=0) +\n  tmap::tm_shape(roads_one_simplified_harsh) + tmap::tm_lines(lwd=2, col=\"red\") +\n  tmap::tm_shape(roads_two_simplified) + tmap::tm_lines(lwd=2, col=\"green\") +\n  tmap::tm_shape(roads_mask) + tmap::tm_borders(lwd=1, col=\"pink\") + \n  #tmap::tm_graticules(lines=T,labels.rot=c(0,90),lwd=0.2) +\n  tmap::tm_scale_bar(position = c(\"RIGHT\", \"BOTTOM\"), text.size = .5) + \n  tmap::tm_compass(color.dark = \"gray60\", text.color = \"gray60\", position = c(\"left\", \"top\")) +\n  tmap::tm_basemap(\"Esri.WorldImagery\")\n\n\n# Save output to MASKS folder and purge memory\n#sf::st_write(roads_mask, \"/Users/seamus/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/MASKS/LeakageMask_Roads_10km-Buffer_051625.shp\", delete_dsn=T)\n\n\n\nHabitat Masks\nHabitat masks were derived using wetlands and protected area datasets confirmed through discussions with the client. Both VM0048 and VMD0055 guidelines explicitly stipulate the exclusion of certain land categories from leakage belts to ensure accurate and conservative leakage monitoring. As highlighted during design meetings in March, Verra has provided additional guidance to project developers wishing to confirm the legal definitions of these area designations. While high variance and inconsistency is typical of spatial datasets representing wetlands, conservation habitats, artisanal farming and rural road networks in forested landscapes, Verra has also acknowledged that such mapping criteria particularly related to proected areas is likely to require considerable discussions and negotiations with local stakeholders, national government, and with Verra’s VM0048 committee.\nImplementation steps:\n\nWetlands data processing:\n\nImported wetland raster datasets from peer-reviewed and approved sources as mandated by VMD0055.\nCropped wetlands raster precisely to the spatial extent of the identified leakage belt.\nReclassified wetland habitat classes based explicitly on VM0048 criteria, distinguishing eligible classes clearly, adhering to procedures outlined in Appendix 2 of VMD0055.\n\nWetland mask generation:\n\nConverted classified wetlands into a binary mask layer, ensuring compatibility and direct alignment with VM0048/VMD0055 requirements to exclude wetlands from leakage areas.\n\n\n\n# Prepare shell for cropping \nleakage_belt_crop = sf::st_as_sf(leakage_belt_whole) |&gt; terra::vect()\n\n# import inputs, and simplify\nwaterways = sf::st_read(\"/Users/seamus/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/HYDRO/Waterways/Winrock_Waterways_Gola_051625.gpkg\", quiet=T) |&gt; \n  sf::st_make_valid() |&gt; \n  sf::st_cast(\"MULTILINESTRING\") \n\nwetlands= terra::rast(\"/Users/seamus/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/HABITAT/Wetlands/GLWD_EPSG32629.tif\")\nwetlands = terra::crop(wetlands, leakage_belt_crop, mask=T)\n\n# tidy labeling\ncode_dict_2 &lt;- data.frame(\n  id = c(1, 4, 7, 10, 12, 14, 15, 18, 20, 21, 26, 31),\n  label = c(\n    \"Freshwater lake\",                              # 1\n    \"Large river\",                                  # 4\n    \"Small streams\",                                # 7\n    \"Riverine, regularly flooded, forested\",        # 10\n    \"Riverine, seasonally flooded, forested\",       # 12\n    \"Riverine, seasonally saturated, forested\",     # 14\n    \"Riverine, seasonally saturated, non-forested\", # 15\n    \"Palustrine, seasonally saturated, forested\",   # 18\n    \"Ephemeral, forested\",                          # 20\n    \"Ephemeral, non-forested\",                      # 21\n    \"Tropical peatland, forested\",                  # 26\n    \"Other coastal wetland\"                         # 31\n  ))\n\nlevels(wetlands) &lt;- code_dict_2\nwetlands[wetlands == 0] &lt;- NA\n\n# derive wetland mask\nwetlands_mask &lt;- wetlands\nwetland_classes &lt;- c(1, 4, 7, 10, 12, 14, 15, 18, 20, 21, 26, 31)\nterra::values(wetlands_mask) &lt;- ifelse(terra::values(wetlands) %in% wetland_classes, 1, NA)\n\ntmap::tmap_mode(\"view\")\ntmap::tm_shape(leakage_belt_whole) + tmap::tm_borders(lwd=0) +\n  tmap::tm_shape(leakage_belt)+tmap::tm_polygons(col=\"yellow\",fill=\"yellow\",fill_alpha=0.4,lwd=1.5) + \n  tmap::tm_shape(wetlands) + tmap::tm_raster(col.legend = tm_legend(\"Wetlands (GLWD\")) +\n  tmap::tm_shape(aoi) + tmap::tm_borders(lwd=1, col=\"red\") + \n  tmap::tm_text(text=\"Name\", size=0.3, col=\"black\") +\n  tmap::tm_scalebar(position = c(\"RIGHT\", \"BOTTOM\"), text.size = .5) + \n  tmap::tm_compass(color.dark = \"gray60\", text.color = \"gray60\", position = c(\"left\", \"top\")) +\n  tmap::tm_basemap(\"Esri.WorldImagery\")\n\nImplementation steps:\n\nProtected areas mask:\n\nObtained spatial datasets from the World Database on Protected Areas (WDPA),8 ensuring compliance with Verra’s approved data sources.\nConducted spatial overlay analysis to identify and exclude legally protected areas classified under IUCN categories I, II, and III, existing managed timber concessions, and UDef PAs and UDef LBs previously validated or verified within the past five years, as stipulated by VMD0055 Appendix 2.\nEnsured all data underwent verification of legal status and eligibility through consultation with local stakeholders and Liberian regulatory authorities, following VMD0055 standards.\n\nLegal and Compliance Considerations:\n\nAll data inputs were verified against regulatory standards, ensuring legality and eligibility for inclusion/exclusion from the leakage belt.\nInitial analyses deliberately excluded protected lands pending further verification of conservation areas’ legal statuses with stakeholders, regulatory bodies, and Verra, in accordance with VMD0055 guidelines.\nDocumentation of all masking operations and criteria applied was systematically recorded for transparency, validation, and future auditing processes, explicitly aligning with VM0048 (Sections 8.3) and VMD0055 (Section 5.1.3-5.2; Appendix 2).\n\n\n\nprotected_areas = sf::st_read(\"/Users/seamus/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/HABITAT/Protected Areas/Archive/WDPA_Mar2025_Public_32629_GOLA.shp\")\n\ntmap::tmap_mode(\"view\")\ntmap::tm_shape(leakage_belt_whole) + tmap::tm_borders(lwd=0) +\n  tmap::tm_shape(leakage_belt) + \n  tmap::tm_polygons(col=\"yellow\",fill=\"yellow\",fill_alpha=0.4, lwd=1)+ \n  tmap::tm_shape(protected_areas) + \n  tmap::tm_polygons(fill=\"ORIG_NAME\", fill.legend = tm_legend(\"Protected Areas (WDPA)\")) +\n  tmap::tm_shape(aoi) + tmap::tm_borders(lwd=1, col=\"red\") + \n  tmap::tm_text(text=\"Name\", size=0.5, col=\"grey\") +\n  tmap::tm_scalebar(position = c(\"RIGHT\", \"BOTTOM\"), text.size = .5) + \n  tmap::tm_compass(color.dark=\"gray60\", text.color=\"gray60\", position=c(\"left\",\"top\")) +\n  tmap::tm_basemap(\"Esri.WorldImagery\")\n\n\n\nSlope Mask\nImplementation steps:\nSlope masking operations are performed to comply explicitly with VM0048 and VMD0055 standards, which require excluding areas exceeding a slope gradient of 10% from leakage belt delineation to prevent erroneous leakage attribution.\n\nSlope data acquisition:\n\nUtilized Digital Elevation Model (DEM) data sourced from HydroSHEDS (V2),9 which is derived primarily from Shuttle Radar Topography Mission (SRTM) elevation models, including products that are conditioned with void-filling, stream burning, filtering, and manual corrections to ensure hydrological integrity and accuracy. This source is recognized and approved by Verra as a credible data source for hydrological analyses and leakage delineations. Higher resolution DEMs with similar gold standard processing are also available in the ESA Copernicus collection (25m resolution) and many more. Best warehouse for publicly available and transparent methodological reporting can be found through OpenTopography platform.10\n\nSlope processing:\n\nCalculated slope gradients from the DEM in degrees, subsequently converting these values into percent slope.\nIdentified and classified areas with slope gradients greater than 10%, (&gt; not &gt;=) marking them explicitly for exclusion based on criteria detailed in VM0048 (Section 8.3) and VMD0055 (Section 5.1.3, Appendix 2).\n\nSlope mask generation:\n\nTransformed high-gradient areas identified as invalid (&gt;10% slope) into polygon geometries, performing subsequent geoprocessing operations to dissolve and simplify these features, ensuring computational efficiency without compromising compliance with VMD0055 standards.\n\nJustifying VM0048-compliance:\n\nDocumented HydroSHEDS source information, citing technical documentation explicitly regarding processing steps and geometric corrections as mandated by VM0048 and VMD0055 methodologies.\nMaintained records of slope calculations workflows, mask generation processes to provide transparency, facilitate third-party verification through replication.\n\n\n\n# skipping these operations here (est. time 12 mins)\nDEM = terra::rast(\"/Users/seamus/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/DEM/DEM_EPSG32629.tif\") \n\n# derive slope percentage from degree \nslope_degrees = terra::terrain(DEM, v=\"slope\", unit=\"degrees\")\nslope_percent = tan(slope_degrees * (pi / 180)) * 100\nslope_percent = terra::clamp(slope_percent, 0, 100) \nslope_invalid = slope_percent &gt; 10\nslope_invalid[slope_invalid == 0] &lt;- NA\nslope_mask = terra::as.polygons(slope_invalid, dissolve=T)|&gt;sf::st_as_sf()|&gt;sf::st_union()\n\n# save locally & reload to purge cache\nsf::st_write(slope_mask, \"/Users/seamus/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/MASK/LeakageMask_Slope10%-Invalid_051625.zip\", delete_dsn=T)\nslope_mask = sf::st_read(\"/Users/seamus/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/MASK/Archive/LeakageMask_Slope10%-Invalid_051625/slope_poly_simplified.shp\")\n\ntmap::tm_shape(leakage_belt) + tmap::tm_polygons(col=\"yellow\",fill=\"yellow\",fill_alpha=0.4, lwd=1.5)+ \n  tmap::tm_shape(aoi) + tmap::tm_borders(lwd=1.5, col=\"red\") + \n  tmap::tm_text(text=\"Name\", size=0.3, col=\"white\") +\n  tmap::tm_shape(slope_mask) + tmap::tm_polygons(fill=\"purple\", fill_alpha=0.6, lwd=0)+ \n  tmap::tm_scalebar(position = c(\"RIGHT\", \"BOTTOM\"), text.size = .5) + \n  tmap::tm_compass(color.dark = \"gray60\", text.color = \"gray60\", position = c(\"left\", \"top\")) +\n  tmap::tm_basemap(\"Esri.WorldImagery\")\n\n\n\n\nApply Leakage Masks\nAfter creating the four masks for roads, wetlands, protected areas, slope thresholds, we applied these to the unscreened leakage belt, resulting in a leakage belt compliant with all VM0048/VMD0055 requirements. The process can be applied via successive clipping of ineligible or eligible areas, which yields the final geometry used for leakage area analysis.\n\nMask application: We overlaid the unfiltered leakage belt with each exclusion mask to carve out the invalid zones. In practice, this was done by spatial difference or intersection operations: we subtracted the slope, wetland, and protected area masks from the leakage belt applying st_difference() function to each, and we intersected the belt with the inverse of the road mask to exclude areas within the 10km buffers surrounding roads. The result is that all areas within 10km of roads, on steep slopes &gt;10%, in wetlands, or in protected areas were removed. What remained is the valid leakage area – a polygon, or set of polygons, representing the leakage belt after all exclusions. We ensured that throughout this overlay process, geometry validity and topology were preserved (using st_make_valid and snapping as needed to handle any slivers created at mask boundaries). The final output was a clean leakage belt polygon meeting every required criterion.\nResults: We documented each masking operation and saved all resulting datasets for transparency and future audit. For example, the final filtered leakage belt shapefile was saved in the project archive. Additionally, intermediate products like the individual mask layers and the intermediate mask layers were preserved with clear filenames. This documentation aimed to ensures auditors can trace each step of the analysis, facilitating their required replication more easily. Documentation of these methods aligns with ISO 19115-1 metadata standards for data lineage, as well as ISO 19105 conformance testing guidelines, by providing evidence for each criterion applied.\n\nThe final deliverable of a valid leakage belt shapefile was saved with the filename LeakageBelt_10km_051625.shp.\n\n\n\n# clip\nroads_leakage           = sf::st_intersection(leakage_belt, roads_mask)\nslope_leakage           = sf::st_difference(leakage_belt, slope_mask)\nwetlands_leakage        = sf::st_difference(leakage_belt, wetlands_mask)\nprotected_areas_leakage = sf::st_difference(leakage_belt, protected_areas)\n\n# It may make better sense to derive and apply these seperately for faster processing\nleakage_area_a     = sf::st_union(roads_leakage, slope_leakage)\nleakage_area_b     = sf::st_union(leakage_area_a, wetlands_leakage)\nleakage_area_valid = sf::st_union(leakage_area_b, protected_areas_leakage)\n\n# save ouput before it crashes\nsf::st_write(leakage_area_valid, \"/Users/seamus/Library/CloudStorage/OneDrive-WinrockInternationalInstituteforAgriculturalDevelopment/20087 - RSPB Gola Feasibility/Deliverables/Spatial Data/LEAKAGE/Archive/LeakageBelt_10km_051625/LeakageBelt_10k-Radius_Filtered-WDPA_GLWD_SLOPE-10PC_ROADS-10KM.shp\", delete_dsn=T)\n\n# Visualise\ntmap::tmap_mode(\"view\")\ntmap::tm_shape(leakage_belt_valid) + tmap::tm_polygons(col=\"yellow\",fill=\"yellow\",fill_alpha=1, lwd=0) + \n  tmap::tm_shape(country) + tmap::tm_borders(lwd=1.5, col=\"grey30\") + \n  tmap::tm_shape(counties) + tmap::tm_borders(lwd=0.5, col=\"grey70\") + \n  tmap::tm_shape(aoi) + tmap::tm_borders(lwd=0.5, col=\"red\") + \n  tmap::tm_basemap(\"Esri.WorldImagery\")\n\n\nVisual review\nTo validate the spatial logic, we conducted a visual review of all layers using interactive maps. While static maps provided previously report confirmed inputs at a coarse scale, more useful insights may be drawn from the interactive maps below. By loading the project area, the unfiltered leakage belt, and each mask for roads, wetlands, protected areas, slope together, readers may toggle layers and inspect overlaps. This helps confirm that the masks and final leakage outputs were correctly aligned with input features and exclusion zones. In this way, we invite feedback from reviewers on further improvements or spatial updates needed, especially around settlements and boundaries where multiple exclusion criteria overlapped. In the following maps, users may verify attribute information of any target features using mouse cursor. This interactive review is a quality control step to catch any anomalies before finalizing the outputs.\nMap Guide:\n\nToggle individual mask layers on/off to isolate specific criteria\nZoom and pan to examine local edge effects, especially near community clusters or county boundaries where multiple exclusion zones might converge.\nInspect features by hovering or clicking, to see their attributes, such as the name of protected areas or the slope percentage of a given cell, confirming that features are correctly classified and that the clipping occurred as expected.\n\n\n# Visual check\ntmap::tmap_mode(\"view\")\ntmap::tm_shape(leakage_belt_whole) + tmap::tm_borders(lwd=0) +\n  tmap::tm_shape(country) + tmap::tm_borders(lwd=1.5, col=\"grey30\") + \n  tmap::tm_shape(counties) + tmap::tm_borders(lwd=0.5, col=\"grey70\") + \n  tmap::tm_shape(leakage_belt) + tmap::tm_polygons(col=\"yellow\",fill=\"yellow\",fill_alpha=0.4, lwd=1)+ \n  tmap::tm_shape(wetlands) + tmap::tm_raster(col.legend = tm_legend(\"Wetlands (GLWD\")) +\n  tmap::tm_shape(waterways) + tmap::tm_lines(lwd=\"ORD_STRA\", lwd.scale=tm_scale_asis(values.scale=0.4),col=\"skyblue\")+ \n  tmap::tm_shape(protected_areas) + tmap::tm_polygons(fill=\"ORIG_NAME\",fill.legend=tm_legend(\"Protected Areas (WDPA)\"))+\n  tmap::tm_shape(slope_mask) + tmap::tm_raster(title=\"\", palette=\"purple\", labels=\"Slope Exclusion Zone\") +\n  tmap::tm_shape(roads_mask) + tmap::tm_borders(col=\"green\", lwd=1.5) +\n  tmap::tm_shape(roads_ext) +tmap::tm_lines(col=\"Category\",   col.legend=tm_legend(\"Road network\")) +\n  tmap::tm_shape(aoi) + tmap::tm_borders(lwd=1, col=\"red\") + \n  tmap::tm_text(text=\"Name\", size=0.5, col=\"beige\") +\n  tmap::tm_shape(pop) + tm_symbols(size=0.4, col = \"pink\", id=\"name\", popup.vars = TRUE) +\n  tmap::tm_add_legend(type=\"symbols\", col=\"pink\", size=1, labels=\"Settlments\") +\n    tmap::tm_basemap(\"Esri.WorldImagery\")\n\n\n\n\nTally Leakage Area Features\n\nIntersections\nTo inform the project’s monitoring strategy and stakeholder engagement plans, we intersected the leakage area polygon with three spatial datasets: road networks, waterway networks, and village locations. Linear features were quantified by their total lengths in kilometers, while point features were counted based on their occurrence within the leakage belt.\nThe resulting spatial visualizations enable the project team to clearly assess the distribution and density of these deforestation drivers, identifying areas at greatest risk due to human activities and physical accessibility.\n\n\nResults\nQuantifying infrastructure and settlement density within the leakage zone directly informs targeted leakage mitigation strategies. Understanding the spatial distribution of communities and infrastructure helps project proponents tailor interventions such as community outreach, agricultural intensification programs, and alternative livelihood development specifically aimed at reducing deforestation pressures.\nOur analysis revealed substantial infrastructure and population within the leakage belt:\n\nWaterways: 1,235.5 km\nRoad Network: 2,135.5 km\nTotal Leakage Area within 10 km of Project Boundary: 118,109 ha\n\nThese findings highlight critical areas for potential leakage activity, guiding strategic interventions and resource allocation to effectively address deforestation risk.\n\nwaterways_count_whole = sf::st_intersection(waterways, sf::st_as_sf(leakage_belt_crop))\nwaterways_count_valid = sf::st_intersection(waterways, leakage_belt)\nwaterways_length_whole = sum(sf::st_length(waterways_count_whole))\nwaterways_length_valid = sum(sf::st_length(waterways_count_valid))\n\nroad_count_whole = sf::st_intersection(roads_ext, sf::st_as_sf(leakage_belt_crop))\nroad_count_valid = sf::st_intersection(roads_ext, leakage_belt)\nroad_length_whole = sum(sf::st_length(road_count_whole)) + sum(sf::st_length(road_count_whole))\nroad_length_valid = sum(sf::st_length(road_count_valid)) + sum(sf::st_length(road_count_valid))\n\ncommunity_count_whole = sf::st_intersection(pop, sf::st_as_sf(leakage_belt_crop))\ncommunity_count_valid = sf::st_intersection(pop, leakage_belt)\n\nwaterways_length_whole\nwaterways_length_valid\nroad_length_whole\nroad_length_valid\ncommunity_count_whole\ncommunity_count_valid\n\n\ndevtools::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.0 (2023-04-21)\n os       macOS 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_CA.UTF-8\n ctype    en_CA.UTF-8\n tz       America/Vancouver\n date     2025-08-26\n pandoc   3.7.0.2 @ /opt/local/bin/ (via rmarkdown)\n quarto   1.7.33 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package           * version   date (UTC) lib source\n abind               1.4-8     2024-09-12 [1] CRAN (R 4.3.3)\n askpass             1.2.1     2024-10-04 [1] CRAN (R 4.3.3)\n base64enc           0.1-3     2015-07-28 [1] CRAN (R 4.3.3)\n cachem              1.1.0     2024-05-16 [1] CRAN (R 4.3.3)\n class               7.3-23    2025-01-01 [1] CRAN (R 4.3.3)\n classInt            0.4-11    2025-01-08 [1] CRAN (R 4.3.3)\n cli                 3.6.5     2025-04-23 [1] CRAN (R 4.3.3)\n codetools           0.2-20    2024-03-31 [1] CRAN (R 4.3.1)\n colorspace          2.1-1     2024-07-26 [1] CRAN (R 4.3.3)\n cols4all          * 0.8       2024-10-16 [1] CRAN (R 4.3.3)\n crosstalk           1.2.1     2023-11-23 [1] CRAN (R 4.3.3)\n curl                6.4.0     2025-06-22 [1] CRAN (R 4.3.3)\n data.table          1.17.8    2025-07-10 [1] CRAN (R 4.3.3)\n DBI                 1.2.3     2024-06-02 [1] CRAN (R 4.3.3)\n deldir              2.0-4     2024-02-28 [1] CRAN (R 4.3.3)\n devtools            2.4.5     2022-10-11 [1] CRAN (R 4.3.0)\n dichromat           2.0-0.1   2022-05-02 [1] CRAN (R 4.3.3)\n digest              0.6.37    2024-08-19 [1] CRAN (R 4.3.3)\n distill           * 1.6       2023-10-06 [1] CRAN (R 4.3.1)\n downlit             0.4.4     2024-06-10 [1] CRAN (R 4.3.3)\n dplyr             * 1.1.4     2023-11-17 [1] CRAN (R 4.3.1)\n e1071               1.7-16    2024-09-16 [1] CRAN (R 4.3.3)\n ellipsis            0.3.2     2021-04-29 [1] CRAN (R 4.3.3)\n evaluate            1.0.4     2025-06-18 [1] CRAN (R 4.3.3)\n farver              2.1.2     2024-05-13 [1] CRAN (R 4.3.3)\n fastmap             1.2.0     2024-05-15 [1] CRAN (R 4.3.3)\n flextable         * 0.9.9     2025-05-31 [1] CRAN (R 4.3.3)\n fontBitstreamVera   0.1.1     2017-02-01 [1] CRAN (R 4.3.3)\n fontLiberation      0.1.0     2016-10-15 [1] CRAN (R 4.3.3)\n fontquiver          0.2.1     2017-02-01 [1] CRAN (R 4.3.3)\n fs                  1.6.6     2025-04-12 [1] CRAN (R 4.3.3)\n gdtools             0.4.2     2025-03-27 [1] CRAN (R 4.3.3)\n generics            0.1.4     2025-05-09 [1] CRAN (R 4.3.3)\n ggplot2             3.5.2     2025-04-09 [1] CRAN (R 4.3.3)\n glue                1.8.0     2024-09-30 [1] CRAN (R 4.3.3)\n gtable              0.3.6     2024-10-25 [1] CRAN (R 4.3.3)\n htmltools           0.5.8.1   2024-04-04 [1] CRAN (R 4.3.3)\n htmlwidgets         1.6.4     2023-12-06 [1] CRAN (R 4.3.1)\n httpuv              1.6.16    2025-04-16 [1] CRAN (R 4.3.3)\n interp              1.1-6     2024-01-26 [1] CRAN (R 4.3.3)\n jpeg                0.1-11    2025-03-21 [1] CRAN (R 4.3.3)\n jsonlite            2.0.0     2025-03-27 [1] CRAN (R 4.3.3)\n KernSmooth          2.23-26   2025-01-01 [1] CRAN (R 4.3.3)\n knitr             * 1.50      2025-03-16 [1] CRAN (R 4.3.3)\n later               1.4.2     2025-04-08 [1] CRAN (R 4.3.3)\n latex2exp         * 0.9.6     2022-11-28 [1] CRAN (R 4.3.0)\n lattice           * 0.22-7    2025-04-02 [1] CRAN (R 4.3.3)\n latticeExtra      * 0.6-30    2022-07-04 [1] CRAN (R 4.3.3)\n leafem            * 0.2.4     2025-05-01 [1] CRAN (R 4.3.3)\n leafgl            * 0.2.2     2024-11-13 [1] CRAN (R 4.3.3)\n leaflegend          1.2.1     2024-05-09 [1] CRAN (R 4.3.3)\n leaflet           * 2.2.2     2024-03-26 [1] CRAN (R 4.3.1)\n leaflet.extras    * 2.0.1     2024-08-19 [1] CRAN (R 4.3.3)\n leaflet.providers * 2.0.0     2023-10-17 [1] CRAN (R 4.3.3)\n leafsync            0.1.0     2019-03-05 [1] CRAN (R 4.3.0)\n lifecycle           1.0.4     2023-11-07 [1] CRAN (R 4.3.3)\n logger              0.4.0     2024-10-22 [1] CRAN (R 4.3.3)\n lwgeom              0.2-14    2024-02-21 [1] CRAN (R 4.3.1)\n magrittr            2.0.3     2022-03-30 [1] CRAN (R 4.3.3)\n maptiles          * 0.10.0    2025-05-07 [1] CRAN (R 4.3.3)\n memoise             2.0.1     2021-11-26 [1] CRAN (R 4.3.3)\n microbenchmark      1.5.0     2024-09-04 [1] CRAN (R 4.3.3)\n mime                0.13      2025-03-17 [1] CRAN (R 4.3.3)\n miniUI              0.1.2     2025-04-17 [1] CRAN (R 4.3.3)\n officer             0.6.10    2025-05-30 [1] CRAN (R 4.3.3)\n openssl             2.3.3     2025-05-26 [1] CRAN (R 4.3.3)\n pacman              0.5.1     2019-03-11 [1] CRAN (R 4.3.3)\n palmerpenguins    * 0.1.1     2022-08-15 [1] CRAN (R 4.3.3)\n pillar              1.11.0    2025-07-04 [1] CRAN (R 4.3.3)\n pkgbuild            1.4.8     2025-05-26 [1] CRAN (R 4.3.3)\n pkgconfig           2.0.3     2019-09-22 [1] CRAN (R 4.3.3)\n pkgload             1.4.0     2024-06-28 [1] CRAN (R 4.3.3)\n png                 0.1-8     2022-11-29 [1] CRAN (R 4.3.3)\n profvis             0.4.0     2024-09-20 [1] CRAN (R 4.3.3)\n PROJ              * 0.6.0     2025-04-03 [1] CRAN (R 4.3.3)\n proj4               1.0-15    2025-03-21 [1] CRAN (R 4.3.3)\n promises            1.3.3     2025-05-29 [1] CRAN (R 4.3.3)\n proxy               0.4-27    2022-06-09 [1] CRAN (R 4.3.3)\n purrr               1.1.0     2025-07-10 [1] CRAN (R 4.3.0)\n R6                  2.6.1     2025-02-15 [1] CRAN (R 4.3.3)\n ragg                1.4.0     2025-04-10 [1] CRAN (R 4.3.3)\n raster            * 3.6-32    2025-03-28 [1] CRAN (R 4.3.3)\n RColorBrewer        1.1-3     2022-04-03 [1] CRAN (R 4.3.3)\n Rcpp              * 1.1.0     2025-07-02 [1] CRAN (R 4.3.3)\n RcppThread        * 2.2.0     2025-01-07 [1] CRAN (R 4.3.3)\n remotes             2.5.0     2024-03-17 [1] CRAN (R 4.3.3)\n reproj            * 0.7.0     2024-06-11 [1] CRAN (R 4.3.3)\n rlang               1.1.6     2025-04-11 [1] CRAN (R 4.3.3)\n rmapshaper        * 0.5.0     2023-04-11 [1] CRAN (R 4.3.0)\n rmarkdown         * 2.29      2024-11-04 [1] CRAN (R 4.3.3)\n s2                  1.1.9     2025-05-23 [1] CRAN (R 4.3.3)\n scales              1.4.0     2025-04-24 [1] CRAN (R 4.3.3)\n sessioninfo         1.2.3     2025-02-05 [1] CRAN (R 4.3.3)\n sf                * 1.0-22    2025-08-25 [1] Github (r-spatial/sf@3660edf)\n shiny               1.11.1    2025-07-03 [1] CRAN (R 4.3.3)\n sp                * 2.2-0     2025-02-01 [1] CRAN (R 4.3.3)\n spacesXYZ           1.6-0     2025-06-06 [1] CRAN (R 4.3.3)\n stars               0.6-8     2025-02-01 [1] CRAN (R 4.3.3)\n stringi             1.8.7     2025-03-27 [1] CRAN (R 4.3.3)\n stringr             1.5.1     2023-11-14 [1] CRAN (R 4.3.1)\n systemfonts         1.2.3     2025-04-30 [1] CRAN (R 4.3.3)\n terra             * 1.8-60    2025-07-21 [1] CRAN (R 4.3.0)\n textshaping         1.0.1     2025-05-01 [1] CRAN (R 4.3.3)\n tibble              3.3.0     2025-06-08 [1] CRAN (R 4.3.3)\n tidyr               1.3.1     2024-01-24 [1] CRAN (R 4.3.1)\n tidyselect          1.2.1     2024-03-11 [1] CRAN (R 4.3.1)\n tidyterra         * 0.7.2     2025-04-14 [1] CRAN (R 4.3.3)\n tinytex           * 0.57      2025-04-15 [1] CRAN (R 4.3.3)\n tmap              * 4.1       2025-05-12 [1] CRAN (R 4.3.3)\n tmaptools         * 3.2       2025-01-13 [1] CRAN (R 4.3.3)\n units               0.8-7     2025-03-11 [1] CRAN (R 4.3.3)\n urlchecker          1.0.1     2021-11-30 [1] CRAN (R 4.3.3)\n usethis             3.1.0     2024-11-26 [1] CRAN (R 4.3.3)\n uuid                1.2-1     2024-07-29 [1] CRAN (R 4.3.3)\n V8                  6.0.4     2025-06-04 [1] CRAN (R 4.3.3)\n vctrs               0.6.5     2023-12-01 [1] CRAN (R 4.3.3)\n viridisLite         0.4.2     2023-05-02 [1] CRAN (R 4.3.3)\n withr               3.0.2     2024-10-28 [1] CRAN (R 4.3.3)\n wk                  0.9.4     2024-10-11 [1] CRAN (R 4.3.3)\n xaringan          * 0.30      2024-03-23 [1] CRAN (R 4.3.1)\n xaringanExtra     * 0.8.0     2024-05-19 [1] CRAN (R 4.3.3)\n xfun                0.53      2025-08-19 [1] CRAN (R 4.3.0)\n XML                 3.99-0.18 2025-01-01 [1] CRAN (R 4.3.3)\n xml2                1.3.8     2025-03-14 [1] CRAN (R 4.3.3)\n xtable              1.8-4     2019-04-21 [1] CRAN (R 4.3.3)\n yaml                2.3.10    2024-07-26 [1] CRAN (R 4.3.3)\n zip                 2.3.3     2025-05-13 [1] CRAN (R 4.3.3)\n\n [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\n * ── Packages attached to the search path.\n\n──────────────────────────────────────────────────────────────────────────────\n\n#Sys.getenv()\n#.libPaths()",
    "crumbs": [
      "Home",
      "Leakage"
    ]
  },
  {
    "objectID": "leakage.html#footnotes",
    "href": "leakage.html#footnotes",
    "title": "Leakage Belt",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\nhttps://verra.org/wp-content/uploads/2023/11/VM0048-Reducing-Emissions-from-Deforestation-and-Forest-Degradation-v1.0-1-1.pdf\nhttps://verra.org/wp-content/uploads/2024/10/VMD0055-Estimation-of-Emission-Reductions-from-Avoiding-Unplanned-Deforestation-v1.1-CLEAN-2024.10.21.24.pdf\n\n↩︎\nPlease consult chunk text to confirm data sources, otherwise outlined in this markdown’s report content↩︎\nhttps://epsg.io/32629↩︎\nISO 19107:2019 Geographic information — Spatial schema https://www.iso.org/obp/ui/#iso:std:iso:19107:ed-2:v1:en↩︎\nhttps://github.com/JanCaha/r_package_qgis/blob/master/R/qgis_coveragesimplify.R↩︎\n\nFor interested users, options for deploying both “valid_linework” or “valid_structure” functions are available in sf::st_make_valid(geos_method=\"valid_structure\") operations. However, perhaps most impressive is how the st_intersection() effectively exposes all overlaps, segments all invalid geometries: and assigns a vertex-based index that enables easy extraction, recovery, or reclassification of geometry errors, all of which was achieved by explicitly assigning self-intersections to the features domain. Lastly, if users prefer to quickly discard all errors and skip geometry inspections, then the st_difference function may be more suitable.\n\n↩︎\nDouglas, D. H., & Peucker, T. K. (1973). Algorithms for the reduction of the number of points required to represent a digitized line or its caricature. Cartographica: the international journal for geographic information and geovisualization, 10(2), 112-122.↩︎\nhttps://developers.google.com/earth-engine/datasets/catalog/WCMC_WDPA_current_polygons↩︎\n\nhttps://agupubs.onlinelibrary.wiley.com/doi/10.1029/2008EO100001\nhttps://data.hydrosheds.org/file/technical-documentation/HydroSHEDS_TechDoc_v1_4.pdf\n\n↩︎\nhttps://portal.opentopography.org/datasets↩︎",
    "crumbs": [
      "Home",
      "Leakage"
    ]
  },
  {
    "objectID": "uncertainty.html#aois-projection",
    "href": "uncertainty.html#aois-projection",
    "title": "Uncertainty",
    "section": "1. AOIs & projection",
    "text": "1. AOIs & projection\n\ncrs_master &lt;- st_crs(\"epsg:4326\")\naoi_site   = sf::read_sf(\"./assets/inputs/chilwa_watershed_4326.shp\") |&gt;\n  st_cast() |&gt; st_transform(crs_master)\naoi_country &lt;- giscoR::gisco_get_countries(country = \"Malawi\", resolution = \"3\") |&gt;\n  st_cast() |&gt; st_transform(crs_master)\naoi_region &lt;- giscoR::gisco_get_countries(\n  country = c(\"Malawi\", \"Zambia\", \"Tanzania\", \"Mozambique\"), resolution = \"3\") |&gt;\n  st_cast() |&gt; st_transform(crs_master)\n\n# Interactive map mode: \"view\"\ntmap::tmap_mode(\"view\")\ntmap::tm_shape(aoi_region) +\n  tmap::tm_borders(lwd = 1, col = \"green\") +\n  tmap::tm_shape(aoi_country) +\n  tmap::tm_borders(lwd = 2, col = \"red\")"
  },
  {
    "objectID": "uncertainty.html#download-population-data",
    "href": "uncertainty.html#download-population-data",
    "title": "Uncertainty",
    "section": "2. Download population data",
    "text": "2. Download population data\n\n# best 1x1km raster format (person/km^2)\n#url &lt;- \"https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/GHS_POP_GLOBE_R2023A/GHS_POP_E2025_GLOBE_R2023A_54009_1000/V1-0/GHS_POP_E2025_GLOBE_R2023A_54009_1000_V1_0.zip\"\n# file_name = \"GHS_POP_E2025_GLOBE_R2023A_54009_1000_V1_0.tif\"\n# download.file(url = url, path = getwd(), destfile = file_name)\npop = terra::rast(\"~/repos/datasets/population/GHS_POP_E2025_GLOBE_R2023A_54009_1000_V1_0.tif\")\npop = terra::project(pop, \"EPSG:4326\") # reproject to fix NAs\npop = terra::crop(pop, aoi_country, snap = \"in\", mask = T)\nnames(pop)[1] &lt;- \"density_km\" # number of persons per sq kilometer\n\ntmap::tm_shape(aoi_country) +\n  tmap::tm_borders(lwd = 0) +\n  tmap::tm_shape(pop) +\n  tm_raster(\n    style           = \"fixed\",\n    alpha           = 1,\n    palette         = \"OrRd\",\n    title           = \"People/Km^2\",\n    breaks          = c(0, 0.01, 10, 100, 200, 1000, 2000, 50000)\n  )"
  },
  {
    "objectID": "uncertainty.html#customize-layout",
    "href": "uncertainty.html#customize-layout",
    "title": "Uncertainty",
    "section": "3. Customize layout",
    "text": "3. Customize layout\n\n# static mapping mode\ntmap::tmap_mode(\"plot\") \n\ntmap::tm_shape(aoi_country) +\n  tmap::tm_borders(lwd = 0) +\n  tmap::tm_shape(pop) +\n  tm_raster(\n    style           = \"fixed\",\n    alpha           = 1,\n    palette         = \"OrRd\",\n    title           = \"People/Km^2\",\n    breaks          = c(0, 0.01, 10, 100, 200, 1000, 2000, 50000)\n  ) +\n  tmap::tm_shape(aoi_region) +\n  tmap::tm_borders(lwd = 0.5, col = \"black\") +\n  tmap::tm_shape(aoi_site) +\n  tmap::tm_borders(lwd = 1, col = \"red\", fill_alpha = 0.5) +\n  tmap::tm_graticules(\n    lines           = T, \n    labels.rot      = c(0, 90), \n    lwd             = 0.2\n    ) +\n  tmap::tm_scalebar(\n    breaks          = c(0, 50, 100, 200),\n    position        = c(\"RIGHT\", \"BOTTOM\"),\n    text.size       = 0.5\n    ) +\n  tmap::tm_compass(\n    type            = \"4star\",\n    size            = 1,\n    color.dark      = \"gray60\",\n    text.color      = \"gray60\",\n    position        = c(\"LEFT\", \"top\")\n    ) +\n  tmap::tm_credits(\n    text            = \"EPSG:4326\", \n    color           = \"gray60\",\n    size            = 0.5,\n    position        = c(\"left\", \"BOTTOM\")\n    ) +\n  tmap::tm_layout(\n    main.title      = \"Population Density\",\n    title.size      = 1,\n    title.position  = c(\"right\", \"top\"),\n    legend.outside  = FALSE,\n    legend.position = c(\"left\", \"bottom\"),\n    legend.text.size= 0.5,\n    legend.title.size = 0.5\n    ) -&gt; map_population\nmap_population\n\n\n\n\nFigure 1: Population Map"
  },
  {
    "objectID": "uncertainty.html#save-output",
    "href": "uncertainty.html#save-output",
    "title": "Uncertainty",
    "section": "4. Save output",
    "text": "4. Save output\n\ntmap::tmap_save(map_population, \"assets/outputs/04-population-map.png\", asp = 0, dpi = 600)\n\n\ndevtools::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.0 (2023-04-21)\n os       macOS 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_CA.UTF-8\n ctype    en_CA.UTF-8\n tz       America/Vancouver\n date     2025-08-26\n pandoc   3.7.0.2 @ /opt/local/bin/ (via rmarkdown)\n quarto   1.7.33 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package            * version    date (UTC) lib source\n abind              * 1.4-8      2024-09-12 [1] CRAN (R 4.3.3)\n ape                  5.8-1      2024-12-16 [1] CRAN (R 4.3.3)\n assertthat           0.2.1      2019-03-21 [1] CRAN (R 4.3.3)\n backports            1.5.0      2024-05-23 [1] CRAN (R 4.3.3)\n base64enc            0.1-3      2015-07-28 [1] CRAN (R 4.3.3)\n bit                  4.6.0      2025-03-06 [1] CRAN (R 4.3.3)\n bit64                4.6.0-1    2025-01-16 [1] CRAN (R 4.3.3)\n bitops               1.0-9      2024-10-03 [1] CRAN (R 4.3.3)\n boot                 1.3-31     2024-08-28 [1] CRAN (R 4.3.3)\n brew                 1.0-10     2023-12-16 [1] CRAN (R 4.3.3)\n brio                 1.1.5      2024-04-24 [1] CRAN (R 4.3.3)\n broom                1.0.9      2025-07-28 [1] CRAN (R 4.3.0)\n bslib              * 0.9.0      2025-01-30 [1] CRAN (R 4.3.3)\n cachem               1.1.0      2024-05-16 [1] CRAN (R 4.3.3)\n callr                3.7.6      2024-03-25 [1] CRAN (R 4.3.3)\n car                  3.1-3      2024-09-27 [1] CRAN (R 4.3.3)\n carData              3.0-5      2022-01-06 [1] CRAN (R 4.3.3)\n caret              * 7.0-1      2024-12-10 [1] CRAN (R 4.3.3)\n class                7.3-23     2025-01-01 [1] CRAN (R 4.3.3)\n classInt             0.4-11     2025-01-08 [1] CRAN (R 4.3.3)\n cli                * 3.6.5      2025-04-23 [1] CRAN (R 4.3.3)\n clue                 0.3-66     2024-11-13 [1] CRAN (R 4.3.3)\n cluster              2.1.8.1    2025-03-12 [1] CRAN (R 4.3.3)\n coda                 0.19-4.1   2024-01-31 [1] CRAN (R 4.3.3)\n codetools            0.2-20     2024-03-31 [1] CRAN (R 4.3.1)\n colorspace           2.1-1      2024-07-26 [1] CRAN (R 4.3.3)\n cols4all           * 0.8        2024-10-16 [1] CRAN (R 4.3.3)\n contfrac             1.1-12     2018-05-17 [1] CRAN (R 4.3.3)\n coro                 1.1.0      2024-11-05 [1] CRAN (R 4.3.3)\n corpcor              1.6.10     2021-09-16 [1] CRAN (R 4.3.3)\n covr               * 3.6.4      2023-11-09 [1] CRAN (R 4.3.1)\n cowplot            * 1.2.0      2025-07-07 [1] CRAN (R 4.3.3)\n crayon               1.5.3      2024-06-20 [1] CRAN (R 4.3.3)\n crosstalk            1.2.1      2023-11-23 [1] CRAN (R 4.3.3)\n cubature             2.1.4      2025-06-02 [1] CRAN (R 4.3.3)\n data.table           1.17.8     2025-07-10 [1] CRAN (R 4.3.3)\n DBI                  1.2.3      2024-06-02 [1] CRAN (R 4.3.3)\n deldir               2.0-4      2024-02-28 [1] CRAN (R 4.3.3)\n dendextend         * 1.19.0     2024-11-15 [1] CRAN (R 4.3.3)\n deSolve              1.40       2023-11-27 [1] CRAN (R 4.3.3)\n devtools             2.4.5      2022-10-11 [1] CRAN (R 4.3.0)\n DiagrammeR         * 1.0.11     2024-02-02 [1] CRAN (R 4.3.1)\n dichromat            2.0-0.1    2022-05-02 [1] CRAN (R 4.3.3)\n digest             * 0.6.37     2024-08-19 [1] CRAN (R 4.3.3)\n doParallel           1.0.17     2022-02-07 [1] CRAN (R 4.3.3)\n downlit            * 0.4.4      2024-06-10 [1] CRAN (R 4.3.3)\n dplyr              * 1.1.4      2023-11-17 [1] CRAN (R 4.3.1)\n dtw                * 1.23-1     2022-09-19 [1] CRAN (R 4.3.3)\n dtwclust           * 6.0.0      2024-07-23 [1] CRAN (R 4.3.3)\n e1071              * 1.7-16     2024-09-16 [1] CRAN (R 4.3.3)\n easypackages         0.1.0      2016-12-05 [1] CRAN (R 4.3.0)\n elevatr            * 0.99.0     2023-09-12 [1] CRAN (R 4.3.0)\n ellipsis             0.3.2      2021-04-29 [1] CRAN (R 4.3.3)\n elliptic             1.4-0      2019-03-14 [1] CRAN (R 4.3.3)\n evaluate             1.0.4      2025-06-18 [1] CRAN (R 4.3.3)\n exactextractr      * 0.10.0     2023-09-20 [1] CRAN (R 4.3.1)\n extrafont            0.19       2023-01-18 [1] CRAN (R 4.3.3)\n extrafontdb          1.0        2012-06-11 [1] CRAN (R 4.3.3)\n farver               2.1.2      2024-05-13 [1] CRAN (R 4.3.3)\n fastmap              1.2.0      2024-05-15 [1] CRAN (R 4.3.3)\n flexclust            1.5.0      2025-02-28 [1] CRAN (R 4.3.3)\n FNN                * 1.1.4.1    2024-09-22 [1] CRAN (R 4.3.3)\n forcats            * 1.0.0      2023-01-29 [1] CRAN (R 4.3.0)\n foreach              1.5.2      2022-02-02 [1] CRAN (R 4.3.3)\n Formula              1.2-5      2023-02-24 [1] CRAN (R 4.3.3)\n fs                   1.6.6      2025-04-12 [1] CRAN (R 4.3.3)\n future             * 1.40.0     2025-04-10 [1] CRAN (R 4.3.3)\n future.apply         1.11.3     2024-10-27 [1] CRAN (R 4.3.3)\n FuzzyNumbers         0.4-7      2021-11-15 [1] CRAN (R 4.3.3)\n FuzzyNumbers.Ext.2   3.2        2017-09-05 [1] CRAN (R 4.3.3)\n gdalcubes          * 0.7.1      2025-03-20 [1] CRAN (R 4.3.3)\n gdalUtilities      * 1.2.5      2023-08-10 [1] CRAN (R 4.3.0)\n generics             0.1.4      2025-05-09 [1] CRAN (R 4.3.3)\n geojsonsf          * 2.0.3      2022-05-30 [1] CRAN (R 4.3.3)\n geos               * 0.2.4      2023-11-30 [1] CRAN (R 4.3.3)\n ggmap              * 4.0.1      2025-04-07 [1] CRAN (R 4.3.3)\n ggplot2            * 3.5.2      2025-04-09 [1] CRAN (R 4.3.3)\n ggplotify          * 0.1.2      2023-08-09 [1] CRAN (R 4.3.0)\n ggpubr             * 0.6.1      2025-06-27 [1] CRAN (R 4.3.3)\n ggrepel            * 0.9.6      2024-09-07 [1] CRAN (R 4.3.3)\n ggsignif             0.6.4      2022-10-13 [1] CRAN (R 4.3.0)\n ggspatial          * 1.1.9      2023-08-17 [1] CRAN (R 4.3.0)\n ggstats            * 0.10.0     2025-07-02 [1] CRAN (R 4.3.3)\n giscoR             * 0.6.1      2025-08-11 [1] Github (rOpenGov/giscoR@adfed30)\n globals              0.17.0     2025-04-16 [1] CRAN (R 4.3.3)\n glue                 1.8.0      2024-09-30 [1] CRAN (R 4.3.3)\n gmm                  1.8        2023-06-06 [1] CRAN (R 4.3.3)\n gower                1.0.2      2024-12-17 [1] CRAN (R 4.3.3)\n gridExtra            2.3        2017-09-09 [1] CRAN (R 4.3.3)\n gridGraphics         0.5-1      2020-12-13 [1] CRAN (R 4.3.3)\n gtable               0.3.6      2024-10-25 [1] CRAN (R 4.3.3)\n hardhat              1.4.1      2025-01-31 [1] CRAN (R 4.3.3)\n hdf5r              * 1.3.12     2025-01-20 [1] CRAN (R 4.3.3)\n hexbin               1.28.5     2024-11-13 [1] CRAN (R 4.3.3)\n hms                  1.1.3      2023-03-21 [1] CRAN (R 4.3.0)\n htmltools          * 0.5.8.1    2024-04-04 [1] CRAN (R 4.3.3)\n htmlwidgets          1.6.4      2023-12-06 [1] CRAN (R 4.3.1)\n httpuv               1.6.16     2025-04-16 [1] CRAN (R 4.3.3)\n httr               * 1.4.7      2023-08-15 [1] CRAN (R 4.3.0)\n httr2              * 1.1.2      2025-03-26 [1] CRAN (R 4.3.3)\n hypergeo             1.2-14     2025-03-24 [1] CRAN (R 4.3.3)\n interp               1.1-6      2024-01-26 [1] CRAN (R 4.3.3)\n ipred                0.9-15     2024-07-18 [1] CRAN (R 4.3.3)\n iterators            1.0.14     2022-02-05 [1] CRAN (R 4.3.3)\n jpeg                 0.1-11     2025-03-21 [1] CRAN (R 4.3.3)\n jquerylib            0.1.4      2021-04-26 [1] CRAN (R 4.3.3)\n jsonlite           * 2.0.0      2025-03-27 [1] CRAN (R 4.3.3)\n KernSmooth           2.23-26    2025-01-01 [1] CRAN (R 4.3.3)\n knitr                1.50       2025-03-16 [1] CRAN (R 4.3.3)\n kohonen            * 3.0.12     2023-06-09 [1] CRAN (R 4.3.3)\n later                1.4.2      2025-04-08 [1] CRAN (R 4.3.3)\n lattice            * 0.22-7     2025-04-02 [1] CRAN (R 4.3.3)\n latticeExtra         0.6-30     2022-07-04 [1] CRAN (R 4.3.3)\n lava                 1.8.1      2025-01-12 [1] CRAN (R 4.3.3)\n lazyeval             0.2.2      2019-03-15 [1] CRAN (R 4.3.3)\n leafem             * 0.2.4      2025-05-01 [1] CRAN (R 4.3.3)\n leafgl             * 0.2.2      2024-11-13 [1] CRAN (R 4.3.3)\n leaflegend           1.2.1      2024-05-09 [1] CRAN (R 4.3.3)\n leaflet            * 2.2.2      2024-03-26 [1] CRAN (R 4.3.1)\n leaflet.providers    2.0.0      2023-10-17 [1] CRAN (R 4.3.3)\n leafpop              0.1.0      2021-05-22 [1] CRAN (R 4.3.0)\n leafsync             0.1.0      2019-03-05 [1] CRAN (R 4.3.0)\n libgeos            * 3.11.1-3   2025-03-19 [1] CRAN (R 4.3.3)\n lifecycle            1.0.4      2023-11-07 [1] CRAN (R 4.3.3)\n listenv              0.9.1      2024-01-29 [1] CRAN (R 4.3.3)\n logger               0.4.0      2024-10-22 [1] CRAN (R 4.3.3)\n lubridate          * 1.9.4      2024-12-08 [1] CRAN (R 4.3.3)\n luz                * 0.4.0      2023-04-17 [1] CRAN (R 4.3.0)\n lwgeom             * 0.2-14     2024-02-21 [1] CRAN (R 4.3.1)\n magrittr             2.0.3      2022-03-30 [1] CRAN (R 4.3.3)\n mapedit            * 0.7.0      2025-04-20 [1] CRAN (R 4.3.3)\n maptiles           * 0.10.0     2025-05-07 [1] CRAN (R 4.3.3)\n mapview            * 2.11.2     2023-10-13 [1] CRAN (R 4.3.1)\n MASS                 7.3-60.0.1 2024-01-13 [1] CRAN (R 4.3.1)\n Matrix               1.6-5      2024-01-11 [1] CRAN (R 4.3.1)\n matrixcalc           1.0-6      2022-09-14 [1] CRAN (R 4.3.3)\n MCMCglmm             2.36       2024-05-06 [1] CRAN (R 4.3.1)\n memoise              2.0.1      2021-11-26 [1] CRAN (R 4.3.3)\n mgcv               * 1.9-3      2025-04-04 [1] CRAN (R 4.3.0)\n microbenchmark       1.5.0      2024-09-04 [1] CRAN (R 4.3.3)\n mime                 0.13       2025-03-17 [1] CRAN (R 4.3.3)\n miniUI               0.1.2      2025-04-17 [1] CRAN (R 4.3.3)\n ModelMetrics         1.2.2.2    2020-03-17 [1] CRAN (R 4.3.3)\n modeltools           0.2-24     2025-05-02 [1] CRAN (R 4.3.3)\n MomTrunc             6.1        2024-10-28 [1] CRAN (R 4.3.3)\n mvtnorm              1.3-3      2025-01-10 [1] CRAN (R 4.3.3)\n ncdf4              * 1.24       2025-03-25 [1] CRAN (R 4.3.3)\n nlme               * 3.1-168    2025-03-31 [1] CRAN (R 4.3.3)\n nnet               * 7.3-20     2025-01-01 [1] CRAN (R 4.3.3)\n openxlsx           * 4.2.8      2025-01-25 [1] CRAN (R 4.3.3)\n parallelly           1.45.0     2025-06-02 [1] CRAN (R 4.3.3)\n pillar               1.11.0     2025-07-04 [1] CRAN (R 4.3.3)\n pkgbuild             1.4.8      2025-05-26 [1] CRAN (R 4.3.3)\n pkgconfig            2.0.3      2019-09-22 [1] CRAN (R 4.3.3)\n pkgload              1.4.0      2024-06-28 [1] CRAN (R 4.3.3)\n plotly             * 4.11.0     2025-06-19 [1] CRAN (R 4.3.3)\n plyr                 1.8.9      2023-10-02 [1] CRAN (R 4.3.3)\n png                  0.1-8      2022-11-29 [1] CRAN (R 4.3.3)\n prettyunits          1.2.0      2023-09-24 [1] CRAN (R 4.3.3)\n pROC                 1.18.5     2023-11-01 [1] CRAN (R 4.3.3)\n processx             3.8.6      2025-02-21 [1] CRAN (R 4.3.3)\n prodlim              2025.04.28 2025-04-28 [1] CRAN (R 4.3.3)\n profvis              0.4.0      2024-09-20 [1] CRAN (R 4.3.3)\n progress             1.2.3      2023-12-06 [1] CRAN (R 4.3.1)\n progressr            0.15.1     2024-11-22 [1] CRAN (R 4.3.3)\n promises             1.3.3      2025-05-29 [1] CRAN (R 4.3.3)\n proxy              * 0.4-27     2022-06-09 [1] CRAN (R 4.3.3)\n ps                   1.9.1      2025-04-12 [1] CRAN (R 4.3.3)\n purrr              * 1.1.0      2025-07-10 [1] CRAN (R 4.3.0)\n R6                   2.6.1      2025-02-15 [1] CRAN (R 4.3.3)\n randomForest       * 4.7-1.2    2024-09-22 [1] CRAN (R 4.3.3)\n rappdirs             0.3.3      2021-01-31 [1] CRAN (R 4.3.3)\n raster             * 3.6-32     2025-03-28 [1] CRAN (R 4.3.3)\n rasterVis          * 0.51.6     2023-11-01 [1] CRAN (R 4.3.3)\n rayshader          * 0.37.3     2024-02-21 [1] CRAN (R 4.3.1)\n rbibutils            2.3        2024-10-04 [1] CRAN (R 4.3.3)\n RColorBrewer       * 1.1-3      2022-04-03 [1] CRAN (R 4.3.3)\n Rcpp               * 1.1.0      2025-07-02 [1] CRAN (R 4.3.3)\n RcppArmadillo      * 14.6.0-1   2025-07-02 [1] CRAN (R 4.3.3)\n RcppCensSpatial    * 0.3.0      2022-06-27 [1] CRAN (R 4.3.0)\n RcppEigen          * 0.3.4.0.2  2024-08-24 [1] CRAN (R 4.3.3)\n RcppParallel       * 5.1.10     2025-01-24 [1] CRAN (R 4.3.3)\n RCurl                1.98-1.17  2025-03-22 [1] CRAN (R 4.3.3)\n Rdpack               2.6.4      2025-04-09 [1] CRAN (R 4.3.3)\n reactable          * 0.4.4      2023-03-12 [1] CRAN (R 4.3.0)\n readr              * 2.1.5      2024-01-10 [1] CRAN (R 4.3.1)\n recipes              1.3.1      2025-05-21 [1] CRAN (R 4.3.3)\n relliptical          1.3.0      2024-02-07 [1] CRAN (R 4.3.1)\n remotes              2.5.0      2024-03-17 [1] CRAN (R 4.3.3)\n reshape2             1.4.4      2020-04-09 [1] CRAN (R 4.3.0)\n rex                  1.2.1      2021-11-26 [1] CRAN (R 4.3.3)\n rgl                * 1.3.24     2025-06-25 [1] CRAN (R 4.3.3)\n rlang                1.1.6      2025-04-11 [1] CRAN (R 4.3.3)\n rmarkdown            2.29       2024-11-04 [1] CRAN (R 4.3.3)\n rpart                4.1.24     2025-01-07 [1] CRAN (R 4.3.3)\n rsconnect          * 1.5.0      2025-06-26 [1] CRAN (R 4.3.3)\n RSpectra             0.16-2     2024-07-18 [1] CRAN (R 4.3.3)\n rstatix              0.7.2      2023-02-01 [1] CRAN (R 4.3.0)\n RStoolbox          * 1.0.2.1    2025-02-03 [1] CRAN (R 4.3.3)\n rstudioapi           0.17.1     2024-10-22 [1] CRAN (R 4.3.3)\n rts                * 1.1-14     2023-10-01 [1] CRAN (R 4.3.3)\n Rttf2pt1             1.3.12     2023-01-22 [1] CRAN (R 4.3.3)\n Ryacas0              0.4.4      2023-01-12 [1] CRAN (R 4.3.3)\n s2                 * 1.1.9      2025-05-23 [1] CRAN (R 4.3.3)\n sandwich             3.1-1      2024-09-15 [1] CRAN (R 4.3.3)\n sass                 0.4.10     2025-04-11 [1] CRAN (R 4.3.3)\n satellite            1.0.5      2024-02-10 [1] CRAN (R 4.3.3)\n scales             * 1.4.0      2025-04-24 [1] CRAN (R 4.3.3)\n sessioninfo          1.2.3      2025-02-05 [1] CRAN (R 4.3.3)\n settings             0.2.7      2021-05-07 [1] CRAN (R 4.3.3)\n sf                 * 1.0-22     2025-08-25 [1] Github (r-spatial/sf@3660edf)\n shiny                1.11.1     2025-07-03 [1] CRAN (R 4.3.3)\n shinyjs              2.1.0      2021-12-23 [1] CRAN (R 4.3.0)\n shinyWidgets         0.9.0      2025-02-21 [1] CRAN (R 4.3.3)\n sits               * 1.5.2      2025-02-12 [1] CRAN (R 4.3.3)\n sp                 * 2.2-0      2025-02-01 [1] CRAN (R 4.3.3)\n spacesXYZ            1.6-0      2025-06-06 [1] CRAN (R 4.3.3)\n spData             * 2.3.4      2025-01-08 [1] CRAN (R 4.3.3)\n spdep              * 1.3-13     2025-06-10 [1] CRAN (R 4.3.3)\n stars              * 0.6-8      2025-02-01 [1] CRAN (R 4.3.3)\n StempCens            1.2.0      2025-06-11 [1] CRAN (R 4.3.3)\n stringi              1.8.7      2025-03-27 [1] CRAN (R 4.3.3)\n stringr            * 1.5.1      2023-11-14 [1] CRAN (R 4.3.1)\n supercells         * 1.0.0      2024-02-11 [1] CRAN (R 4.3.1)\n survival             3.8-3      2024-12-17 [1] CRAN (R 4.3.3)\n svglite              2.2.1      2025-05-12 [1] CRAN (R 4.3.3)\n systemfonts          1.2.3      2025-04-30 [1] CRAN (R 4.3.3)\n tensorA              0.36.2.1   2023-12-13 [1] CRAN (R 4.3.3)\n terra              * 1.8-60     2025-07-21 [1] CRAN (R 4.3.0)\n terrainr           * 0.7.5      2023-10-04 [1] CRAN (R 4.3.1)\n testthat           * 3.2.3      2025-01-13 [1] CRAN (R 4.3.3)\n textshaping          1.0.1      2025-05-01 [1] CRAN (R 4.3.3)\n tibble             * 3.3.0      2025-06-08 [1] CRAN (R 4.3.3)\n tidyr              * 1.3.1      2024-01-24 [1] CRAN (R 4.3.1)\n tidyselect           1.2.1      2024-03-11 [1] CRAN (R 4.3.1)\n tidyterra          * 0.7.2      2025-04-14 [1] CRAN (R 4.3.3)\n tidyverse          * 2.0.0      2023-02-22 [1] CRAN (R 4.3.0)\n timechange           0.3.0      2024-01-18 [1] CRAN (R 4.3.3)\n timeDate             4041.110   2024-09-22 [1] CRAN (R 4.3.3)\n tlrmvnmvt            1.1.2      2022-06-09 [1] CRAN (R 4.3.3)\n tmap               * 4.1        2025-05-12 [1] CRAN (R 4.3.3)\n tmaptools          * 3.2        2025-01-13 [1] CRAN (R 4.3.3)\n tmvtnorm             1.6        2023-12-05 [1] CRAN (R 4.3.3)\n torch                0.15.1     2025-07-10 [1] CRAN (R 4.3.3)\n tzdb                 0.5.0      2025-03-15 [1] CRAN (R 4.3.3)\n unifir               0.2.4      2024-02-01 [1] CRAN (R 4.3.3)\n units                0.8-7      2025-03-11 [1] CRAN (R 4.3.3)\n urlchecker           1.0.1      2021-11-30 [1] CRAN (R 4.3.3)\n usethis              3.1.0      2024-11-26 [1] CRAN (R 4.3.3)\n uuid                 1.2-1      2024-07-29 [1] CRAN (R 4.3.3)\n vctrs                0.6.5      2023-12-01 [1] CRAN (R 4.3.3)\n viridis              0.6.5      2024-01-29 [1] CRAN (R 4.3.1)\n viridisLite          0.4.2      2023-05-02 [1] CRAN (R 4.3.3)\n visNetwork           2.1.2      2022-09-29 [1] CRAN (R 4.3.0)\n withr                3.0.2      2024-10-28 [1] CRAN (R 4.3.3)\n wk                   0.9.4      2024-10-11 [1] CRAN (R 4.3.3)\n xfun                 0.53       2025-08-19 [1] CRAN (R 4.3.0)\n xgboost            * 1.7.11.1   2025-05-15 [1] CRAN (R 4.3.3)\n XML                  3.99-0.18  2025-01-01 [1] CRAN (R 4.3.3)\n xml2                 1.3.8      2025-03-14 [1] CRAN (R 4.3.3)\n xtable               1.8-4      2019-04-21 [1] CRAN (R 4.3.3)\n xts                * 0.14.1     2024-10-15 [1] CRAN (R 4.3.3)\n yaml                 2.3.10     2024-07-26 [1] CRAN (R 4.3.3)\n yulab.utils          0.2.0      2025-01-29 [1] CRAN (R 4.3.3)\n zeallot              0.2.0      2025-05-27 [1] CRAN (R 4.3.3)\n zip                  2.3.3      2025-05-13 [1] CRAN (R 4.3.3)\n zoo                * 1.8-14     2025-04-10 [1] CRAN (R 4.3.3)\n\n [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\n * ── Packages attached to the search path.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "baseline.html",
    "href": "baseline.html",
    "title": "Baseline Emissions",
    "section": "",
    "text": "!pip install leafmap geemap==0.30.4 geopandas numpy session_info rasterio pycrs pandasai\nopenai matplotlib-scalebar==0.9.0 contextily\nfrom IPython import get_ipython\nfrom IPython.display import display, HTML\ndisplay(HTML(\"&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;\"))\nget_ipython().run_line_magic('load_ext', 'autoreload')\nget_ipython().run_line_magic('autoreload', '2')\nimport ee, json, geemap, ipyleaflet, os, session_info, json, tempfile, rasterio, time, shutil\nimport geopandas as gpd\nimport pandas as pd\nimport numpy as np\nfrom rasterio.mask import mask\nfrom rasterio.io import MemoryFile\nfrom rasterio.warp import calculate_default_transform, reproject, Resampling\nfrom rasterio.plot import show\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib_scalebar.scalebar import ScaleBar\nimport contextily as ctx\nfrom shapely.geometry import shape, mapping, Polygon",
    "crumbs": [
      "Home",
      "Baseline"
    ]
  },
  {
    "objectID": "baseline.html#aoi",
    "href": "baseline.html#aoi",
    "title": "Baseline Emissions",
    "section": "1. AOI",
    "text": "1. AOI\n\ncountry = ee.FeatureCollection('FAO/GAUL/2015/level1').filter(\n    ee.Filter.equals(\"ADM0_NAME\", \"Liberia\"))\nstates_all = country.aggregate_array('ADM1_NAME').distinct().getInfo()\nstates_all\n\nstate =  ee.FeatureCollection('FAO/GAUL/2015/level1').filter(\n    ee.Filter.equals('ADM1_NAME', \"Barima Waini (region N°1)\"))\nred = {\"color\": \"red\", \"width\": 2, \"lineType\": \"solid\", \"fillColor\": \"00000000\"}\nwhite = {\"color\": \"white\", \"width\": 1, \"lineType\": \"solid\", \"fillColor\": \"00000000\"}\ncountry_label = ee.FeatureCollection([ee.Feature(\n    country.geometry().centroid(), {'country_name': country.first().get(\"ADM0_NAME\").getInfo()})])\n\nMap = geemap.Map()\nMap.centerObject(country, 6)\nMap.add_basemap('Esri.WorldImagery')\nMap.addLayer(country.style(**white), {}, \"Guyana\")\nMap.addLayer(state.style(**red), {}, \"Barima Waini (region N°1)\")\nMap.add_labels(state,\"ADM1_NAME\",font_size=\"9pt\",font_color=\"red\",font_family=\"arial\",font_weight=\"bold\",)\nMap.add_labels(country_label, \"country_name\", font_size=\"12pt\", font_color=\"white\", font_family=\"arial\",)\nMap\n\nFigure 1: Interactive map showing area of interest polygons (AOI)",
    "crumbs": [
      "Home",
      "Baseline"
    ]
  },
  {
    "objectID": "baseline.html#masking",
    "href": "baseline.html#masking",
    "title": "Baseline Emissions",
    "section": "2. Masking",
    "text": "2. Masking\n\n# derive masking, scaling, and ndvi function\ndef maskL8sr(image):\n    qaMask = image.select('QA_PIXEL').bitwiseAnd(int('11111', 2)).eq(0)\n    saturationMask = image.select('QA_RADSAT').eq(0)\n    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n    thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n    ndvi = image.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI').toFloat()\n    image = image.addBands(opticalBands, None, True) \\\n                 .addBands(thermalBands, None, True) \\\n                 .addBands(ndvi)\n    return image.select(\n        ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'NDVI'],\n        ['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']\n    ).updateMask(qaMask).updateMask(saturationMask)\n\n# create collections for 2014 and 2024\ncollection_2014 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n                    .filterDate('2014-01-01', '2014-12-31') \\\n                    .filterBounds(country) \\\n                    .map(maskL8sr)\n\ncollection_2019 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n                    .filterDate('2019-01-01', '2019-12-31') \\\n                    .filterBounds(country) \\\n                    .map(maskL8sr)\n\ncollection_2024 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n                    .filterDate('2024-01-01', '2024-12-31') \\\n                    .filterBounds(country) \\\n                    .map(maskL8sr)\n\n# median composites for 2014 and 2024\ncomposite_2014 = collection_2014.select(['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']).median().clip(country).toFloat()\ncomposite_2019 = collection_2019.select(['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']).median().clip(country).toFloat()\ncomposite_2024 = collection_2024.select(['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']).median().clip(country).toFloat()\n\n\n# visualization\nndviVis = {'min': 0.2, 'max': 0.8, 'palette': ['red', 'yellow', 'green']}\nrgbVis = {'bands': ['RED', 'GREEN', 'BLUE'],'min': 0, 'max': 0.3, 'gamma': 1.4}\nMap = geemap.Map()\nMap.centerObject(country, 8)\nMap.addLayer(composite_2014.select('NDVI'), ndviVis, 'NDVI 2014')\nMap.addLayer(composite_2019.select('NDVI'), ndviVis, 'NDVI 2019')\nMap.addLayer(composite_2024.select('NDVI'), ndviVis, 'NDVI 2024')\nMap.addLayer(composite_2014.select(['RED', 'GREEN', 'BLUE']), rgbVis, 'RGB 2014')\nMap.addLayer(composite_2019.select(['RED', 'GREEN', 'BLUE']), rgbVis, 'RGB 2019')\nMap.addLayer(composite_2024.select(['RED', 'GREEN', 'BLUE']), rgbVis, 'RGB 2024')\nMap.addLayer(country, {}, 'Area of Interest')\nMap.addLayerControl()\nMap",
    "crumbs": [
      "Home",
      "Baseline"
    ]
  },
  {
    "objectID": "baseline.html#metadata",
    "href": "baseline.html#metadata",
    "title": "Baseline Emissions",
    "section": "3. Metadata",
    "text": "3. Metadata\n\n# confirm dates, scene IDs, band names of images\nfirstImage_2014 = collection_2014.first()\nsceneId_2014 = firstImage_2014.get('system:index').getInfo()\nprint(f\"Scene ID for collection_2014: {sceneId_2014}\")\n\nfirstImage_2019 = collection_2019.first()\nsceneId_2019 = firstImage_2019.get('system:index').getInfo()\nprint(f\"Scene ID for collection_2019: {sceneId_2019}\")\n\nfirstImage_2024 = collection_2024.first()\nsceneId_2024 = firstImage_2024.get('system:index').getInfo()\nprint(f\"Scene ID for collection_2024: {sceneId_2024}\")\n\nbandNames_2014 = composite_2014.bandNames().getInfo()\nprint(f\"Band names: {bandNames_2014}\")\n\nbandNames_2019 = composite_2019.bandNames().getInfo()\nprint(f\"Band names: {bandNames_2019}\")\n\nbandNames_2024 = composite_2024.bandNames().getInfo()\nprint(f\"Band names: {bandNames_2024}\")\n\nScene ID for collection_2014: LC08_198055_20140104\nScene ID for collection_2019: LC08_198055_20190102\nScene ID for collection_2024: LC08_198055_20240116\nBand names: ['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']\nBand names: ['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']\nBand names: ['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']",
    "crumbs": [
      "Home",
      "Baseline"
    ]
  },
  {
    "objectID": "baseline.html#export",
    "href": "baseline.html#export",
    "title": "Baseline Emissions",
    "section": "4. Export",
    "text": "4. Export\n\nfrom datetime import datetime\n\n# extract pathrow and date from scene ID\ndef get_pathrow_date(image_collection):\n  first_image = image_collection.first()\n  scene_id = first_image.get('system:index').getInfo()\n  parts = scene_id.split('_')\n  pathrow = parts[1]\n  date_str = parts[2]\n  date_obj = datetime.strptime(date_str, '%Y%m%d')\n  date = date_obj.strftime('%Y-%m-%d')\n  return pathrow, date\n\n# define export parameters\ndef define_export_params(image, pathrow, date, band_name):\n  description = f'composite_{date}_{band_name if isinstance(band_name, str) else \"RGB\"}_export'[:100]\n  return {\n    'image': image.select(band_name),\n    'description': description,\n    'folder': 'VT0007-deforestation-map',\n    'fileNamePrefix': f'LANDSAT_TM-ETM-OLI_{pathrow}_{band_name if isinstance(band_name, str) else \"RGB\"}_{date}',\n    'scale': 30,\n    'region': country.geometry(),\n    'maxPixels': 1e13,\n    'fileFormat': 'GeoTIFF',\n    'formatOptions': {'cloudOptimized': True}\n  }\n\n# get pathrow and date for each collection\npathrow_2014, date_2014 = get_pathrow_date(collection_2014)\npathrow_2019, date_2019 = get_pathrow_date(collection_2019)\npathrow_2024, date_2024 = get_pathrow_date(collection_2024)\n\n# get band names\nbandNames_2014 = composite_2014.bandNames().getInfo()\nbandNames_2019 = composite_2019.bandNames().getInfo()\nbandNames_2024 = composite_2024.bandNames().getInfo()\n\n# export to cloud bucket\nfor band_name in bandNames_2014:\n    export_params_2014 = define_export_params(composite_2014, pathrow_2014, date_2014, band_name)\n    task_2014 = ee.batch.Export.image.toDrive(**export_params_2014)\n    task_2014.start()\n    print(f\"Exporting 2014 image for band {band_name}. Task ID: {task_2014.id}\")\n\nfor band_name in bandNames_2019:\n    export_params_2019 = define_export_params(composite_2019, pathrow_2019, date_2019, band_name)\n    task_2019 = ee.batch.Export.image.toDrive(**export_params_2019)\n    task_2019.start()\n    print(f\"Exporting 2019 image for band {band_name}. Task ID: {task_2019.id}\")\n\nfor band_name in bandNames_2024:\n    export_params_2024 = define_export_params(composite_2024, pathrow_2024, date_2024, band_name)\n    task_2024 = ee.batch.Export.image.toDrive(**export_params_2024)\n    task_2024.start()\n    print(f\"Exporting 2024 image for band {band_name}. Task ID: {task_2024.id}\")\n\nexport_params_2014_rgb = define_export_params(composite_2014, pathrow_2014, date_2014, ['RED', 'GREEN', 'BLUE'])\nexport_params_2014_rgb['image'] = composite_2014.visualize(**rgbVis)\ntask_2014_rgb = ee.batch.Export.image.toDrive(**export_params_2014_rgb)\ntask_2014_rgb.start()\nprint(f\"Exporting 2014 RGB image. Task ID: {task_2014_rgb.id}\")\n\nexport_params_2019_rgb = define_export_params(composite_2019, pathrow_2019, date_2019, ['RED', 'GREEN', 'BLUE'])\nexport_params_2019_rgb['image'] = composite_2019.visualize(**rgbVis)\ntask_2019_rgb = ee.batch.Export.image.toDrive(**export_params_2019_rgb)\ntask_2019_rgb.start()\nprint(f\"Exporting 2019 RGB image. Task ID: {task_2019_rgb.id}\")\n\nexport_params_2024_rgb = define_export_params(composite_2024, pathrow_2024, date_2024, ['RED', 'GREEN', 'BLUE'])\nexport_params_2024_rgb['image'] = composite_2024.visualize(**rgbVis)\ntask_2024_rgb = ee.batch.Export.image.toDrive(**export_params_2024_rgb)\ntask_2024_rgb.start()\nprint(f\"Exporting 2024 RGB image. Task ID: {task_2024_rgb.id}\")\n\nExporting 2014 image for band BLUE. Task ID: IRDIBYVEMKUAVGKZQ5HXKPBC\nExporting 2014 image for band GREEN. Task ID: EEWSBCRWWKUPRQWV4TQZ3B6C\nExporting 2014 image for band RED. Task ID: WXC6RRPJFOILRBYH5C3WOKTP\nExporting 2014 image for band NIR08. Task ID: 6PKRX3FP7ABDPURUHPZYDPWE\nExporting 2014 image for band SWIR16. Task ID: XK6EE5UFGWCCG7QSIDKKTJF5\nExporting 2014 image for band SWIR22. Task ID: W57UBUFB7HRB3EKMLJHNEW6H\nExporting 2014 image for band NDVI. Task ID: ZY7IGAO2K3CIVCUGRXKDNXVA\nExporting 2019 image for band BLUE. Task ID: E3J5YYQM2ZI2HSRDCBPRBWI4\nExporting 2019 image for band GREEN. Task ID: XVQICHKGYHHCLCFS2H4DEVUK\nExporting 2019 image for band RED. Task ID: 7ISMPTUBERKDVN2OZ2DR7U56\nExporting 2019 image for band NIR08. Task ID: 5QGL7XCZ6QPT2NKXEZFKXIPR\nExporting 2019 image for band SWIR16. Task ID: 4TDZ3QLG3JXJ5DXGZIIPPQAX\nExporting 2019 image for band SWIR22. Task ID: SK4Q6PS6IXIVWUICHTRX55UL\nExporting 2019 image for band NDVI. Task ID: 4XWVQ4UNRFEA4JV25IL22THI\nExporting 2024 image for band BLUE. Task ID: BITRT6BI7PKM6P6Z3FWPTEEL\nExporting 2024 image for band GREEN. Task ID: 2VUH34ENCZVIAYSRD3BJQG2G\nExporting 2024 image for band RED. Task ID: 2U5PRUP3VUAJIIC6WPR7L4IG\nExporting 2024 image for band NIR08. Task ID: Y2M2FPLUNIDRRKMEYTWWDBPD\nExporting 2024 image for band SWIR16. Task ID: WPGNYNGXEOCB67CX6VGCPOLG\nExporting 2024 image for band SWIR22. Task ID: L43YZOYPUYVWUMGJCCHS46UA\nExporting 2024 image for band NDVI. Task ID: 3LRYV6LDKHOGQ2TJ4Z3FV4QT\nExporting 2014 RGB image. Task ID: WWHVXMWV2RUT5IKPZNVCFQLA\nExporting 2024 RGB image. Task ID: DA6UDTKJM5NG4QQHHLQ7S2KZ\n\nRuntime Info\n\nsession_info.show()\n\n-----\nbackports           NA\nee                  1.2.0\ngeemap              0.16.4\ngoogle              NA\nipyleaflet          0.19.2\nnumpy               1.26.4\nsession_info        1.0.0\n-----\nClick to view modules imported as dependencies\n-----\nIPython             7.34.0\njupyter_client      6.1.12\njupyter_core        5.7.2\njupyterlab          4.3.3\nnotebook            6.5.5\n-----\nPython 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\nLinux-6.1.85+-x86_64-with-glibc2.35\n-----\nSession information updated at 2024-12-15 22:22\n\ndevtools::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.0 (2023-04-21)\n os       macOS 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Vancouver\n date     2025-08-26\n pandoc   3.6.1 @ /usr/local/bin/ (via rmarkdown)\n quarto   1.7.33 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package           * version    date (UTC) lib source\n abind               1.4-8      2024-09-12 [1] CRAN (R 4.3.3)\n animation         * 2.7        2021-10-07 [1] CRAN (R 4.3.3)\n backports           1.5.0      2024-05-23 [1] CRAN (R 4.3.3)\n base64enc           0.1-3      2015-07-28 [1] CRAN (R 4.3.3)\n bibtex            * 0.5.1      2023-01-26 [1] CRAN (R 4.3.3)\n BIOMASS           * 2.2.4      2025-05-19 [1] CRAN (R 4.3.3)\n cachem              1.1.0      2024-05-16 [1] CRAN (R 4.3.3)\n cellranger          1.1.0      2016-07-27 [1] CRAN (R 4.3.0)\n chromote            0.5.1      2025-04-24 [1] CRAN (R 4.3.3)\n class               7.3-23     2025-01-01 [1] CRAN (R 4.3.3)\n classInt            0.4-11     2025-01-08 [1] CRAN (R 4.3.3)\n cli                 3.6.5      2025-04-23 [1] CRAN (R 4.3.3)\n codetools           0.2-20     2024-03-31 [1] CRAN (R 4.3.1)\n colorspace          2.1-1      2024-07-26 [1] CRAN (R 4.3.3)\n cols4all            0.8        2024-10-16 [1] CRAN (R 4.3.3)\n crosstalk           1.2.1      2023-11-23 [1] CRAN (R 4.3.3)\n data.table          1.17.8     2025-07-10 [1] CRAN (R 4.3.3)\n DBI                 1.2.3      2024-06-02 [1] CRAN (R 4.3.3)\n devtools            2.4.5      2022-10-11 [1] CRAN (R 4.3.0)\n dials               1.4.0      2025-02-13 [1] CRAN (R 4.3.3)\n DiceDesign          1.10       2023-12-07 [1] CRAN (R 4.3.3)\n dichromat           2.0-0.1    2022-05-02 [1] CRAN (R 4.3.3)\n digest              0.6.37     2024-08-19 [1] CRAN (R 4.3.3)\n dplyr             * 1.1.4      2023-11-17 [1] CRAN (R 4.3.1)\n e1071               1.7-16     2024-09-16 [1] CRAN (R 4.3.3)\n ellipsis            0.3.2      2021-04-29 [1] CRAN (R 4.3.3)\n evaluate            1.0.4      2025-06-18 [1] CRAN (R 4.3.3)\n extrafont         * 0.19       2023-01-18 [1] CRAN (R 4.3.3)\n extrafontdb         1.0        2012-06-11 [1] CRAN (R 4.3.3)\n farver              2.1.2      2024-05-13 [1] CRAN (R 4.3.3)\n fastmap             1.2.0      2024-05-15 [1] CRAN (R 4.3.3)\n forcats             1.0.0      2023-01-29 [1] CRAN (R 4.3.0)\n foreach             1.5.2      2022-02-02 [1] CRAN (R 4.3.3)\n fs                  1.6.6      2025-04-12 [1] CRAN (R 4.3.3)\n furrr               0.3.1      2022-08-15 [1] CRAN (R 4.3.0)\n future              1.40.0     2025-04-10 [1] CRAN (R 4.3.3)\n future.apply        1.11.3     2024-10-27 [1] CRAN (R 4.3.3)\n generics            0.1.4      2025-05-09 [1] CRAN (R 4.3.3)\n geodata           * 0.6-2      2024-06-10 [1] CRAN (R 4.3.3)\n ggplot2           * 3.5.2      2025-04-09 [1] CRAN (R 4.3.3)\n globals             0.17.0     2025-04-16 [1] CRAN (R 4.3.3)\n glue                1.8.0      2024-09-30 [1] CRAN (R 4.3.3)\n gower               1.0.2      2024-12-17 [1] CRAN (R 4.3.3)\n GPfit               1.0-9      2025-04-12 [1] CRAN (R 4.3.3)\n gridExtra           2.3        2017-09-09 [1] CRAN (R 4.3.3)\n gtable              0.3.6      2024-10-25 [1] CRAN (R 4.3.3)\n hardhat             1.4.1      2025-01-31 [1] CRAN (R 4.3.3)\n hms                 1.1.3      2023-03-21 [1] CRAN (R 4.3.0)\n htmltools         * 0.5.8.1    2024-04-04 [1] CRAN (R 4.3.3)\n htmlwidgets         1.6.4      2023-12-06 [1] CRAN (R 4.3.1)\n httpuv              1.6.16     2025-04-16 [1] CRAN (R 4.3.3)\n ipred               0.9-15     2024-07-18 [1] CRAN (R 4.3.3)\n iterators           1.0.14     2022-02-05 [1] CRAN (R 4.3.3)\n janitor           * 2.2.1      2024-12-22 [1] CRAN (R 4.3.3)\n jquerylib           0.1.4      2021-04-26 [1] CRAN (R 4.3.3)\n jsonlite            2.0.0      2025-03-27 [1] CRAN (R 4.3.3)\n kableExtra        * 1.4.0      2024-01-24 [1] CRAN (R 4.3.1)\n KernSmooth          2.23-26    2025-01-01 [1] CRAN (R 4.3.3)\n knitr             * 1.50       2025-03-16 [1] CRAN (R 4.3.3)\n later               1.4.2      2025-04-08 [1] CRAN (R 4.3.3)\n lattice             0.22-7     2025-04-02 [1] CRAN (R 4.3.3)\n lava                1.8.1      2025-01-12 [1] CRAN (R 4.3.3)\n leafem              0.2.4      2025-05-01 [1] CRAN (R 4.3.3)\n leaflegend          1.2.1      2024-05-09 [1] CRAN (R 4.3.3)\n leaflet             2.2.2      2024-03-26 [1] CRAN (R 4.3.1)\n leaflet.providers   2.0.0      2023-10-17 [1] CRAN (R 4.3.3)\n leafsync            0.1.0      2019-03-05 [1] CRAN (R 4.3.0)\n lhs                 1.2.0      2024-06-30 [1] CRAN (R 4.3.3)\n lifecycle           1.0.4      2023-11-07 [1] CRAN (R 4.3.3)\n listenv             0.9.1      2024-01-29 [1] CRAN (R 4.3.3)\n logger              0.4.0      2024-10-22 [1] CRAN (R 4.3.3)\n lubridate           1.9.4      2024-12-08 [1] CRAN (R 4.3.3)\n lwgeom              0.2-14     2024-02-21 [1] CRAN (R 4.3.1)\n magrittr            2.0.3      2022-03-30 [1] CRAN (R 4.3.3)\n maptiles            0.10.0     2025-05-07 [1] CRAN (R 4.3.3)\n MASS                7.3-60.0.1 2024-01-13 [1] CRAN (R 4.3.1)\n Matrix              1.6-5      2024-01-11 [1] CRAN (R 4.3.1)\n memoise             2.0.1      2021-11-26 [1] CRAN (R 4.3.3)\n microbenchmark      1.5.0      2024-09-04 [1] CRAN (R 4.3.3)\n mime                0.13       2025-03-17 [1] CRAN (R 4.3.3)\n miniUI              0.1.2      2025-04-17 [1] CRAN (R 4.3.3)\n minpack.lm          1.2-4      2023-09-11 [1] CRAN (R 4.3.3)\n nnet                7.3-20     2025-01-01 [1] CRAN (R 4.3.3)\n openxlsx          * 4.2.8      2025-01-25 [1] CRAN (R 4.3.3)\n pacman              0.5.1      2019-03-11 [1] CRAN (R 4.3.3)\n parallelly          1.45.0     2025-06-02 [1] CRAN (R 4.3.3)\n parsnip             1.3.2      2025-05-28 [1] CRAN (R 4.3.3)\n pillar              1.11.0     2025-07-04 [1] CRAN (R 4.3.3)\n pkgbuild            1.4.8      2025-05-26 [1] CRAN (R 4.3.3)\n pkgconfig           2.0.3      2019-09-22 [1] CRAN (R 4.3.3)\n pkgload             1.4.0      2024-06-28 [1] CRAN (R 4.3.3)\n plyr                1.8.9      2023-10-02 [1] CRAN (R 4.3.3)\n png                 0.1-8      2022-11-29 [1] CRAN (R 4.3.3)\n processx            3.8.6      2025-02-21 [1] CRAN (R 4.3.3)\n prodlim             2025.04.28 2025-04-28 [1] CRAN (R 4.3.3)\n profvis             0.4.0      2024-09-20 [1] CRAN (R 4.3.3)\n PROJ              * 0.6.0      2025-04-03 [1] CRAN (R 4.3.3)\n proj4               1.0-15     2025-03-21 [1] CRAN (R 4.3.3)\n promises            1.3.3      2025-05-29 [1] CRAN (R 4.3.3)\n proxy               0.4-27     2022-06-09 [1] CRAN (R 4.3.3)\n ps                  1.9.1      2025-04-12 [1] CRAN (R 4.3.3)\n purrr               1.1.0      2025-07-10 [1] CRAN (R 4.3.0)\n R6                  2.6.1      2025-02-15 [1] CRAN (R 4.3.3)\n rappdirs            0.3.3      2021-01-31 [1] CRAN (R 4.3.3)\n raster              3.6-32     2025-03-28 [1] CRAN (R 4.3.3)\n RColorBrewer        1.1-3      2022-04-03 [1] CRAN (R 4.3.3)\n Rcpp                1.1.0      2025-07-02 [1] CRAN (R 4.3.3)\n recipes             1.3.1      2025-05-21 [1] CRAN (R 4.3.3)\n remotes             2.5.0      2024-03-17 [1] CRAN (R 4.3.3)\n reproj            * 0.7.0      2024-06-11 [1] CRAN (R 4.3.3)\n reticulate          1.42.0     2025-03-25 [1] CRAN (R 4.3.3)\n rlang               1.1.6      2025-04-11 [1] CRAN (R 4.3.3)\n rmarkdown           2.29       2024-11-04 [1] CRAN (R 4.3.3)\n rpart               4.1.24     2025-01-07 [1] CRAN (R 4.3.3)\n rsample             1.3.0      2025-04-02 [1] CRAN (R 4.3.3)\n rstudioapi          0.17.1     2024-10-22 [1] CRAN (R 4.3.3)\n Rttf2pt1            1.3.12     2023-01-22 [1] CRAN (R 4.3.3)\n s2                  1.1.9      2025-05-23 [1] CRAN (R 4.3.3)\n scales              1.4.0      2025-04-24 [1] CRAN (R 4.3.3)\n sessioninfo         1.2.3      2025-02-05 [1] CRAN (R 4.3.3)\n sf                * 1.0-22     2025-08-25 [1] Github (r-spatial/sf@3660edf)\n shiny               1.11.1     2025-07-03 [1] CRAN (R 4.3.3)\n snakecase           0.11.1     2023-08-27 [1] CRAN (R 4.3.0)\n sp                  2.2-0      2025-02-01 [1] CRAN (R 4.3.3)\n spacesXYZ           1.6-0      2025-06-06 [1] CRAN (R 4.3.3)\n stars               0.6-8      2025-02-01 [1] CRAN (R 4.3.3)\n stringi             1.8.7      2025-03-27 [1] CRAN (R 4.3.3)\n stringr             1.5.1      2023-11-14 [1] CRAN (R 4.3.1)\n survival            3.8-3      2024-12-17 [1] CRAN (R 4.3.3)\n svglite             2.2.1      2025-05-12 [1] CRAN (R 4.3.3)\n systemfonts         1.2.3      2025-04-30 [1] CRAN (R 4.3.3)\n terra             * 1.8-60     2025-07-21 [1] CRAN (R 4.3.0)\n textshaping         1.0.1      2025-05-01 [1] CRAN (R 4.3.3)\n tibble              3.3.0      2025-06-08 [1] CRAN (R 4.3.3)\n tidyr               1.3.1      2024-01-24 [1] CRAN (R 4.3.1)\n tidyselect          1.2.1      2024-03-11 [1] CRAN (R 4.3.1)\n timechange          0.3.0      2024-01-18 [1] CRAN (R 4.3.3)\n timeDate            4041.110   2024-09-22 [1] CRAN (R 4.3.3)\n tinytex           * 0.57       2025-04-15 [1] CRAN (R 4.3.3)\n tmap              * 4.1        2025-05-12 [1] CRAN (R 4.3.3)\n tmaptools         * 3.2        2025-01-13 [1] CRAN (R 4.3.3)\n tune              * 1.3.0      2025-02-21 [1] CRAN (R 4.3.3)\n units               0.8-7      2025-03-11 [1] CRAN (R 4.3.3)\n urlchecker          1.0.1      2021-11-30 [1] CRAN (R 4.3.3)\n useful            * 1.2.6.1    2023-10-24 [1] CRAN (R 4.3.1)\n usethis             3.1.0      2024-11-26 [1] CRAN (R 4.3.3)\n vctrs               0.6.5      2023-12-01 [1] CRAN (R 4.3.3)\n viridisLite         0.4.2      2023-05-02 [1] CRAN (R 4.3.3)\n webshot           * 0.5.5      2023-06-26 [1] CRAN (R 4.3.0)\n webshot2          * 0.1.2      2025-04-23 [1] CRAN (R 4.3.3)\n websocket           1.4.4      2025-04-10 [1] CRAN (R 4.3.3)\n withr               3.0.2      2024-10-28 [1] CRAN (R 4.3.3)\n wk                  0.9.4      2024-10-11 [1] CRAN (R 4.3.3)\n workflows           1.2.0      2025-02-19 [1] CRAN (R 4.3.3)\n xfun                0.53       2025-08-19 [1] CRAN (R 4.3.0)\n XML                 3.99-0.18  2025-01-01 [1] CRAN (R 4.3.3)\n xml2                1.3.8      2025-03-14 [1] CRAN (R 4.3.3)\n xtable              1.8-4      2019-04-21 [1] CRAN (R 4.3.3)\n yaml                2.3.10     2024-07-26 [1] CRAN (R 4.3.3)\n yardstick           1.3.2      2025-01-22 [1] CRAN (R 4.3.3)\n zip                 2.3.3      2025-05-13 [1] CRAN (R 4.3.3)\n\n [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\n * ── Packages attached to the search path.\n\n──────────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "Home",
      "Baseline"
    ]
  },
  {
    "objectID": "deforisk.html",
    "href": "deforisk.html",
    "title": "Deforestation Risk",
    "section": "",
    "text": "Import AOI & visualize:\nset.seed(77777)\n# Import project aoi\naoi = sf::read_sf(\"./data/aoi/AllLandscapes_merge_v02.shp\") |&gt; \n  sf::st_cast(\"POLYGON\") |&gt; sf::st_cast(\"MULTIPOLYGON\") |&gt; \n  dplyr::select(Name) |&gt; sf::st_transform(4326) |&gt;\n  dplyr::filter(\n    Name == \"Gola Forest National Park\" | \n      Name == \"Norman\" | \n      Name == \"Tonglay\") \n\naoi_gola = aoi |&gt; dplyr::filter(Name == \"Gola Forest National Park\")\naoi_tong = aoi |&gt; dplyr::filter(Name == \"Tonglay\")\naoi_norm = aoi |&gt; dplyr::filter(Name == \"Norman\")\n\n# Import country aoi\nquery = osmdata::opq(\"Liberia\") |&gt; # opq = overpass query\n  osmdata::add_osm_feature(key = \"boundary\", value = \"administrative\") |&gt;\n  osmdata::osmdata_sf()\nboundaries = query$osm_multipolygons\ncountry  = boundaries |&gt; dplyr::filter(admin_level == \"2\", name == \"Liberia\") |&gt;\n  dplyr::select(name, admin_level, geometry) |&gt; sf::st_cast() |&gt; sf::st_transform(4326)\nsf::st_write(country, \"./data/aoi/liberia_boundary_national.shp\", delete_layer=T)",
    "crumbs": [
      "Home",
      "Risk"
    ]
  },
  {
    "objectID": "deforisk.html#area-check",
    "href": "deforisk.html#area-check",
    "title": "Deforestation Risk",
    "section": "Area check",
    "text": "Area check\nIn Liberia, the official definition of forest land is provided by the Forestry Development Authority (Government of Liberia 2019), including areas of land that meet the following criteria:\n\nCanopy cover of minimum 30%;\nCanopy height of minimum 5m or the capacity to reach it;\nCovering a minimum of 1 hectare of land.\n\n\nleakage = terra::as.polygons(slope_1_only_glwd_clip) |&gt; sf::st_as_sf()\nleakage_country = terra::as.polygons(slope_1_only_glwd_clip_country) |&gt; sf::st_as_sf()\n\nleakage_country$area_ha = round(as.numeric(sf::st_area(leakage_country) * 0.0001, 4))\nleakage_country |&gt; sf::st_drop_geometry() |&gt; janitor::adorn_totals() \nleakage$area_ha = round(as.numeric(sf::st_area(leakage) * 0.0001, 4))\nleakage |&gt; sf::st_drop_geometry() |&gt; janitor::adorn_totals() \n\nslivers = aoi |&gt; dplyr::filter(as.numeric(area_ha) &lt; 1)  # no artefacts found\n\nResults indicate the spatial dataset is free from topological errors, and forest ‘islands’ and spatial artefacts smaller than approved area definition. Results also match Areahav2 values derived previously and reported in ER_Workbook_Gola_Liberia.xlsx",
    "crumbs": [
      "Home",
      "Risk"
    ]
  },
  {
    "objectID": "deforisk.html#activity-data",
    "href": "deforisk.html#activity-data",
    "title": "Deforestation Risk",
    "section": "Activity data",
    "text": "Activity data\nThis section documents inputs and procedures used to derive national and project-level deforestation maps. This follows three main steps:\n\nCompare land cover training samples for Liberia;\nClassify & assess accuracy of forest cover maps for 2014, 2019, and 2024;\nSpatially map deforestation risk, allocate jurisdictional deforestation & compare with FREL.\n\n\nTraining samples\nTraining samples for the country and project area were extracted from two gold standard global land cover time series datasets: the GLanCE dataset (Stanimirova et al. 2023) and TimeSpec4LULC dataset. Both training datasets were processed with continuous change and class migration algorithms. While Verra is yet to establish requirements for addressing feature class migration in classification of baseline activity data (verraVM0048ReducingEmissions2023a?; verraVMD0055EstimationEmission2024?; Verra 2021), we may recommend incorporating this remote sensing best practice or showcase its improvements to accuracy metrics, as follows.\nTable 2: Class conversions of training samples\n\nLevel-1 classes in the GLanCE and TimeSpec4LULC datasets were recoded below to match class labels cited in the “Lookups” sheet of “ER_Workbook_Gola_Liberia.xlsx”, and the report titled “Liberia’s Forest Reference Emission Level Submission to the UNFCCC (Woodcock et al., n.d.; governmentofliberiaLiberiasForestReference2019?).\nTo address class imbalances, the Winrock team derived additional training samples and appended to the GLanCE datapoint collection. This sampling aimed to improve class-to-country proportionality while targeting plot-to-pixel dimensions and homogenous rule throughout training sample selection.\n\n# import & tidy samples\nsamples_raw = read.csv(\"./data/training_samples/glance_training.csv\")\nsamples_clean = samples_raw |&gt;\n  dplyr::select(Lon, Lat, Glance_Class_ID_level1, Start_Year, End_Year)|&gt;\n  dplyr::rename(longitude = Lon) |&gt;\n  dplyr::rename(latitude = Lat) |&gt;\n  dplyr::rename(label_old = Glance_Class_ID_level1) |&gt;\n  dplyr::mutate(start_date = as.Date(paste(Start_Year,\"01\",\"01\",sep = \"-\")))|&gt;\n  dplyr::mutate(end_date = as.Date(paste(End_Year, \"01\", \"01\", sep = \"-\")))|&gt;\n  dplyr::select(longitude, latitude, start_date, end_date, label_old)|&gt;\n  dplyr::mutate(code = case_when(\n    label_old == '4' ~ 0, \n    label_old == '7' ~ 1, \n    label_old == '6' ~ 2, \n    label_old == '5' ~ 3, \n    label_old == '1' ~ 4, \n    label_old == '3' ~ 99, \n    label_old == '2' ~ 88)\n    ) |&gt;\n  dplyr::mutate(label = case_when(\n    code == '0'  ~ \"Bareground\", \n    code == '1'  ~ \"Regrowth\", \n    code == '2'  ~ \"Farmbush\", \n    code == '3'  ~ \"Forest\", \n    code == '4'  ~ \"Water\", \n    code == '99' ~ \"Urban\", \n    code == '88' ~ \"Snow\")\n    ) |&gt; \n  dplyr::mutate(label = as.factor(label)) |&gt;\n  dplyr::mutate(id = row_number()) |&gt; \n  dplyr::select(-label_old)\n\n# filter to project area\nsamples_sf       = sf::st_as_sf(samples_clean, crs = 4326, coords = c(\"longitude\", \"latitude\"))\nsamples_clipped  = sf::st_intersection(samples_sf, country) # n = 364\nsamples_country  = samples_sf[samples_clipped, ] |&gt; sf::st_transform(4326)\nsamples          = sf::st_crop(samples_country, st_bbox(country))\nsf::st_write(samples, \"./data/training_samples/glance_spatial_clip.shp\", delete_dsn = T)\nwrite.csv(samples, \"./data/training_samples/glance_spatial_clip.csv\", row.names = F)\ndplyr::count(samples, label)\n\n# Winrock training samples\nsamples_winrock &lt;- sf::st_read(\"./data/training_samples/samples_winrock3.shp\") |&gt; sf::st_cast() |&gt; sf::st_transform(4326)\n#samples_winrock &lt;- sf::st_read(\"./data/training_samples/samples_winrock2.shp\") |&gt; sf::st_cast() |&gt; sf::st_transform(4326)\n#samples_winrock &lt;- sf::st_read(\"./data/training_samples/samples_winrock.shp\") |&gt; sf::st_cast() |&gt; sf::st_transform(4326)\nsamples_winrock &lt;- samples_winrock |&gt;\n  dplyr::select(Name)|&gt;\n  dplyr::mutate(\n    start_date = as.Date(\"2014-01-01\"),\n    end_date = as.Date(\"2024-01-01\"),\n    id = row_number()\n  )\n\nsamples_winrock$label &lt;- case_when(\n  stringr::str_detect(samples_winrock$Name, \"^Bareland\")  ~ \"Bareground\",\n  stringr::str_detect(samples_winrock$Name, \"^Regrowth\")  ~ \"Regrowth\",\n  stringr::str_detect(samples_winrock$Name, \"^Farmbush\")  ~ \"Farmbush\",\n  stringr::str_detect(samples_winrock$Name, \"^Forest\")  ~ \"Forest\",\n  stringr::str_detect(samples_winrock$Name, \"^Water\")   ~ \"Water\",\n  stringr::str_detect(samples_winrock$Name, \"^Swamp\")   ~ \"Swamp\",\n  TRUE ~ \"MISSING\"\n  ) |&gt; as.factor()\n\nsamples_winrock$code &lt;- case_when(\n  samples_winrock$label == \"Bareground\" ~ 0,\n  samples_winrock$label == \"Regrowth\"   ~ 1,\n  samples_winrock$label == \"Farmbush\"   ~ 2,\n  samples_winrock$label == \"Water\"      ~ 4,\n  samples_winrock$label == \"Swamp\"      ~ 5,\n  TRUE                                  ~ NA_real_  # Use NA_real_ for numeric NA\n)\n\nsamples_winrock &lt;- samples_winrock[!(samples_winrock$label == \"Forest\"), ]\nsamples_winrock$label &lt;- droplevels(samples_winrock$label)\n\nsamples_winrock &lt;- samples_winrock |&gt;\n  dplyr::select(-Name)\nsamples_combined &lt;- rbind(samples, samples_winrock)\nst_write(samples_combined, \"./data/training_samples/samples_combined.shp\", delete_dsn=T)\nsamples = sf::st_read(\"./data/training_samples/samples_combined.shp\")\ndplyr::count(samples, label)\n\n\n\nRaster collection\nThe dataset of STAC-formatted Landsat Collection-2-Level-2 was extracted from the Google Earth Engine Catalog and processed using a cloudless and pixel quality ranking mask before back-filling with median normalization. This was implemented in a Colab python runtime here. The collection of unclassified rasters was temporarily stored in a Google Drive folder and the consolidated, resampled and labelled full stack is available to download directly from here. In addition, full script and all runtime setups are available from the project’s github repository here\nLandsat data was acquired instead of Sentinel imagery due to start date of project’s 10-year baseline occurring before the launch of the Sentinel 2 satellite. The following chunk provides an alternative worflow, though less reliable, R-native workflow for acquiring, aligning, and processing rasters for the extent of Liberia.\nThe processes above were repeated for three baseline interval years of 2014, 2019, and 2024 and then saved into consolidated raster stack and visualized below.\n\n# import\nNDVI_2014=terra::rast(\"./data/STACK/LANDSAT_TM-ETM-OLI_198055_NDVI_2014-01-04.tif\")\nNDVI_2019=terra::rast(\"./data/STACK/LANDSAT_TM-ETM-OLI_198055_NDVI_2019-01-02.tif\")\nNDVI_2024=terra::rast(\"./data/STACK/LANDSAT_TM-ETM-OLI_198055_NDVI_2024-01-16.tif\")\nSTACK=raster::brick(\"./data/STACK/LANDSAT_TM-ETM-OLI_198055_STACK-&-DEM_2014-01-04_2024-01-16_INTERP.tif\")\n\n# visualize\nhist(NDVI_2014, main = \"NDVI Distribution, 2014\", col = \"springgreen\") \nhist(NDVI_2019, main = \"NDVI Distribution, 2019\", col = \"springgreen\")\nhist(NDVI_2024, main = \"NDVI Distribution, 2024\", col = \"springgreen\")\nplot(NDVI_2014,main=\"NDVI, 2014\",xlim=c(-11.5,-7.5),ylim=c(4.1,8.6),border=\"gray\")\nplot(st_geometry(samples), add=T)\nplot(NDVI_2019,main=\"NDVI, 2014\",xlim=c(-11.5,-7.5),ylim=c(4.1,8.6),border=\"gray\")\nplot(st_geometry(samples), add=T)\nplot(NDVI_2024,main=\"NDVI, 2014\",xlim=c(-11.5,-7.5),ylim=c(4.1,8.6),border=\"gray\")\nplot(st_geometry(samples), add=T)\n\n\n\nImage classification\nWe trained a Random Forest model fitted with 500 decision trees. The dataset was partitioned using a 70:30 ratio which was which was trained using Monte Carlo resampling regime (k=100). Accuracy assessments were reported using a confusion matrix. Uncertainty metrics were then used to explore best subset of variables according to magnitude and performances of recursive modeling, which informed final model selection.\n\n# extract signatures\nsignatures_2014 = raster::extract(STACK_2014, samples ,df=T) # watch for data formats\nsamples_signatures_2014 &lt;- dplyr::inner_join(signatures_2014, samples, by=c(\"ID\"=\"id\"))\nsamples_signatures_2014$geometry &lt;- NULL # set geometry to NULL for model training\n\n# Stratify to ensure all classes are present in both train and test\nstratified_partition &lt;- function(data, group_col, train_ratio = 0.7) {\n  split_data &lt;- lapply(split(data, data[[group_col]]), function(df) {\n    train_size &lt;- max(1, floor(train_ratio * nrow(df)))\n    train_idx &lt;- sample(seq_len(nrow(df)), size = train_size)\n    list(train = df[train_idx, ], test = df[-train_idx, ])\n  })\n  train_data &lt;- do.call(rbind, lapply(split_data, `[[`, \"train\"))\n  test_data &lt;- do.call(rbind, lapply(split_data, `[[`, \"test\"))\n  list(train = train_data, test = test_data)\n  }\npartitioned_data_2014 &lt;- stratified_partition(samples_signatures_2014,group_col=\"label\", train_ratio=0.7)\ntrainData_2014 &lt;- partitioned_data_2014$train\ntestData_2014 &lt;- partitioned_data_2014$test\n#table(trainData_2014$label)\n#table(testData_2014$label)\n\n# synthetic minotrity oversampling technique\ntrainData_2014&lt;-performanceEstimation::smote(label ~ .,data=trainData_2014,perc.over=30,perc.under=30)\ntestData_2014&lt;-performanceEstimation::smote(label ~ .,data=testData_2014,perc.over=30,perc.under=30)\n# interpolate missing cloud pixels with class-median-normalization\ntrainData_2014 &lt;- trainData_2014 |&gt; group_by(label) |&gt; mutate(across(where(is.numeric),\n    ~ ifelse(is.na(.), median(., na.rm = T), .))) |&gt; ungroup()\ntestData_2014 &lt;- testData_2014 |&gt; group_by(label) |&gt; mutate(across(where(is.numeric),\n    ~ ifelse(is.na(.), median(., na.rm = T), .))) |&gt; ungroup()\n\n# assign model variables\nresponse  &lt;- c(\"label\")\npredictors_2014 &lt;- c(\n  \"NDVI_2014\", \"BLUE_2014\", \"GREEN_2014\", \"RED_2014\", \n  \"NIR08_2014\", \"SWIR16_2014\", \"SWIR22_2014\", \"DEM\"\n  )\n# set training parameters\ncv_regime &lt;- caret::trainControl(\n  method          = 'LGOCV',\n  number          = 100,\n  savePredictions = T,\n  verboseIter     = F\n  )\n\n# train classifier\nrf_model_2014 &lt;- caret::train(\n  label~.,\n  data = trainData_2014[, c(predictors_2014, \"label\")], # drop ID var\n  trControl = cv_regime,\n  method    = \"rf\", \n  metric    = 'Kappa', \n  ntree     = 500,\n  tuneLength= 6,\n  importance= T\n  )\n\nAccuracy assessments1\nResults suggested a moderate concordance between observed and predicted classes with optimal model performance during cross-validation at mtry of 3. Overall statistics reported Kappa Index of 71.04%, Accuracy of 88.61% (0.95CI 84.46%, 95.71%), and a smaller No Information Rate of 0.8158 (p&lt;0.01). In addition, key classes of Forest were predicted with robust Sensitivity (98.92%) and Specificity (76.16%).\nTo address model weaknesses, the team recommends sourcing additional verified training samples, or alternatively applying a weighted Random Forest, Gradient Boosting or Support Vector Machines kernels (SVM) to improve performance of underrepresented classes. Note, these modeling updates will require substantial runtimes.\n\nrf_test_2014 &lt;- predict(rf_model_2014, testData_2014)\nprint(rf_model_2014) # cv results\ncaret::confusionMatrix(rf_test_2014,testData_2014$label) # blind test results\n\nRandom Forest \n\n1862 samples\n   8 predictor\n   7 classes: 'Bareground', 'Farmbush', 'Forest', 'Regrowth', 'Swamp', 'Urban', 'Water' \n\nNo pre-processing\nResampling: Repeated Train/Test Splits Estimated (100 reps, 75%) \nSummary of sample sizes: 1399, 1399, 1399, 1399, 1399, 1399, ... \nResampling results across tuning parameters:\n\n  mtry  Accuracy   Kappa    \n  2     0.9976674  0.9935532\n  3     0.9976674  0.9935535\n  4     0.9976674  0.9935553\n  5     0.9976674  0.9935596\n  6     0.9976674  0.9935626\n  8     0.9976674  0.9935652\n\nKappa was used to select the optimal model using the largest value.\nThe final value used for the model was mtry = 8.\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   Bareground Farmbush Forest Regrowth Swamp Urban Water\n  Bareground         28        8      0        0     0     3     0\n  Farmbush            0       10      0        0     0     0     0\n  Forest              4        0    696        8     0     0     0\n  Regrowth            0        0      8       41     0     0     0\n  Swamp               0        0      0        0    31     0     0\n  Urban               0        4      0        0     0    80     0\n  Water               0        0      0        0     0     0    10\n\nOverall Statistics\n                                          \n               Accuracy : 0.9624          \n                 95% CI : (0.9481, 0.9737)\n    No Information Rate : 0.7562          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.9086          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: Bareground Class: Farmbush Class: Forest Class: Regrowth Class: Swamp Class: Urban\nSensitivity                    0.87500         0.45455        0.9886         0.83673       1.0000      0.96386\nSpecificity                    0.98776         1.00000        0.9471         0.99093       1.0000      0.99528\nPos Pred Value                 0.71795         1.00000        0.9831         0.83673       1.0000      0.95238\nNeg Pred Value                 0.99552         0.98697        0.9641         0.99093       1.0000      0.99646\nPrevalence                     0.03437         0.02363        0.7562         0.05263       0.0333      0.08915\nDetection Rate                 0.03008         0.01074        0.7476         0.04404       0.0333      0.08593\nDetection Prevalence           0.04189         0.01074        0.7605         0.05263       0.0333      0.09023\nBalanced Accuracy              0.93138         0.72727        0.9679         0.91383       1.0000      0.97957\n                     Class: Water\nSensitivity               1.00000\nSpecificity               1.00000\nPos Pred Value            1.00000\nNeg Pred Value            1.00000\nPrevalence                0.01074\nDetection Rate            0.01074\nDetection Prevalence      0.01074\nBalanced Accuracy         1.00000\n\n\nModel calibration\nWe employed recursive predictor subsetting to identify predictors of greatest magnitude and non-informative features to enhance model performance and reduce model complexity, respectively. This aims to limit potential of multicolinearity, despite inherent robustness of randomForest algorithms against such violations. The subsetted model was evaluated on the test dataset. The confusion matrix and performance metrics were summarized below.\n\nindex_feature_2014 &lt;- createMultiFolds(trainData_2014$label, times=5) \npredictor_seq_2014 &lt;-seq(from=1, to=length(predictors_2014),by=2)\n\nsubset_regime_2014 &lt;- rfeControl(\n  method=\"LGOCV\",\n  number = 10,\n  verbose=FALSE,\n  functions=rfFuncs,\n  index=index_feature_2014\n  )\n\nrf_model_subset_2014 &lt;- caret::rfe(\n  label~.,\n  data = trainData_2014[, c(predictors_2014, \"label\")], \n  sizes = predictor_seq_2014,\n  metric = \"Kappa\",\n  ntree=500,\n  method=\"rf\",\n  rfeControl = subset_regime_2014\n  )\n\nrf_subset_test_2014 &lt;- predict(rf_model_subset_2014,testData_2014)\nprint(rf_model_subset_2014)\ncaret::confusionMatrix(rf_subset_test_2014$pred,testData_2014$label)\n\nRecursive feature selection\n\nOuter resampling method: Repeated Train/Test Splits Estimated (50 reps, 75%) \n\nResampling performance over subset size:\n\n\nThe top 3 variables (out of 3):\n   BLUE_2014, DEM, SWIR22_2014\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   Bareground Farmbush Forest Regrowth Swamp Urban Water\n  Bareground         28        8     12        0     0     3     0\n  Farmbush            0       10      8        0     0     0     0\n  Forest              4        4    679       32    31     9     0\n  Regrowth            0        0      0        0     0     0     0\n  Swamp               0        0      0        0     0    10     0\n  Urban               0        0      5       17     0    61     0\n  Water               0        0      0        0     0     0    10\n\nOverall Statistics\n                                         \n               Accuracy : 0.8464         \n                 95% CI : (0.8216, 0.869)\n    No Information Rate : 0.7562         \n    P-Value [Acc &gt; NIR] : 1.085e-11      \n                                         \n                  Kappa : 0.5879         \n                                         \n Mcnemar's Test P-Value : NA             \n\nStatistics by Class:\n\n                     Class: Bareground Class: Farmbush Class: Forest Class: Regrowth Class: Swamp Class: Urban Class: Water\nSensitivity                    0.87500         0.45455        0.9645         0.00000      0.00000      0.73494      1.00000\nSpecificity                    0.97442         0.99120        0.6476         1.00000      0.98889      0.97406      1.00000\nPos Pred Value                 0.54902         0.55556        0.8946             NaN      0.00000      0.73494      1.00000\nNeg Pred Value                 0.99545         0.98686        0.8547         0.94737      0.96634      0.97406      1.00000\nPrevalence                     0.03437         0.02363        0.7562         0.05263      0.03330      0.08915      0.01074\nDetection Rate                 0.03008         0.01074        0.7293         0.00000      0.00000      0.06552      0.01074\nDetection Prevalence           0.05478         0.01933        0.8153         0.00000      0.01074      0.08915      0.01074\nBalanced Accuracy              0.92471         0.72287        0.8060         0.50000      0.49444      0.85450      1.00000\n\n\n \n \nVariables Accuracy Kappa AccuracySD KappaSD Selected\n1   1   0.9981  0.9949  0.003389    0.008870    \n2   3   0.9994  0.9983  0.001759    0.004588    *\n3   5   0.9991  0.9978  0.001984    0.005188    \n4   7   0.9989  0.9972  0.002423    0.006388    \n5   8   0.9989  0.9972  0.002423    0.006388    \n\n\n\n\n\n\n\n\n\n\n\n\n\nVa riables\n&lt;S3: AsIs&gt;\nA ccuracy\n&lt;S3: AsIs&gt;\nKappa\n&lt;S3: AsIs&gt;\nAcc uracySD\n&lt;S3: AsIs&gt;\nKappaSD\n&lt;S3: AsIs&gt;\nS elected\n&lt;S3: AsIs&gt;\n\n\n\n\n1\n1\n0.9981\n0.9949\n0 .003389\n0 .008870\n\n\n\n2\n3\n0.9994\n0.9983\n0 .001759\n0 .004588\n*\n\n\n3\n5\n0.9991\n0.9978\n0 .001984\n0 .005188\n\n\n\n4\n7\n0.9989\n0.9972\n0 .002423\n0 .006388\n\n\n\n5\n8\n0.9989\n0.9972\n0 .002423\n0 .006388\n\n\n\n\nIn summary, the subset model achieved an Accuracy of 88.58% and a Kappa Index of 0.6338. These metrics closely align with the results of the original model, suggesting minimal or no loss in predictive power despite using fewer predictors. Similarly, high-performing classes of Forest maintained sensitivity and specificity (SE = 0.9667, SP = 0.8462). Given that the reduction in complexity offered by the subsetted model does not provide significant benefits in this context, we recommend proceeding with the original model to make spatial predictions.\nThese modelling operations were repeated for 2019 and 2024 (see Appendix).\nSpatial predictions were made using their respective models and outputs of classified LULC rasters were saved in the same Google Drive folder linked above in previous sections.\n\ncounties = sf::st_read(\"./data/covariates/places_poly_county.shp\")\njurisdiction = counties |&gt; dplyr::filter(\n  name == \"Grand Cape Mount County\" | name == \"Gharpolu County\" ) |&gt; terra::vect()\njurisdiction$name = 'Grand Cape Mount & Gharpolu Counties'\n\nLULC_COUNTY_2014=terra::rast(\"./data/LULC/LULC_LIBERIA_2014-01-04.tif\") |&gt; \n  terra::crop(jurisdiction, mask=T) |&gt; terra::trim()\nLULC_COUNTY_2019=terra::rast(\"./data/LULC/LULC_LIBERIA_2019-01-02.tif\") |&gt; \n  terra::crop(jurisdiction, mask=T) |&gt; terra::trim()\nLULC_COUNTY_2024=terra::rast(\"./data/LULC/LULC_LIBERIA_2024-01-16.tif\") |&gt; \n  terra::crop(jurisdiction, mask=T) |&gt; terra::trim()\n\ncode_dict &lt;- data.frame(id = c(1, 2, 3, 4, 5, 6, 7),\n  label = c(\"Bareground\", \"Cropland\", \"Forest\", \"Shrubland\", \"Wetland\", \"Urban\", \"Water\"))\nlevels(LULC_COUNTY_2014) &lt;- code_dict\nlevels(LULC_COUNTY_2019) &lt;- code_dict\nlevels(LULC_COUNTY_2024) &lt;- code_dict\n\nLULC_COUNTY_2014 = terra::project(LULC_COUNTY_2014, \"EPSG:32629\")\nLULC_COUNTY_2019 = terra::project(LULC_COUNTY_2019, \"EPSG:32629\")\nLULC_COUNTY_2024 = terra::project(LULC_COUNTY_2024, \"EPSG:32629\")\njurisdiction = jurisdiction |&gt; terra::project(\"EPSG:32629\")\npixel_area_ha &lt;- 0.088914  # 29.80124 x 29.80124 m² converted to hectares\n\n\ncompute_land_cover_summary &lt;- function(jurisdiction, rasters, pixel_area) {\n  results &lt;- list()\n    if (terra::nrow(jurisdiction) == 0) {\n    stop(\"The provided SpatVector jurisdiction is empty.\")\n  }\n  for (region in unique(jurisdiction$name)) {\n    for (year in names(rasters)) {\n      cropped_raster &lt;- terra::crop(\n        rasters[[year]],\n        jurisdiction[jurisdiction$name == region, ],\n        mask = TRUE\n      )\n      if (terra::ncell(cropped_raster) == 0) {\n        warning(paste(\"Cropped raster for\", region, year, \"is empty. Skipping.\"))\n        next\n      }\n      freq &lt;- terra::freq(cropped_raster)\n      freq$area_ha &lt;- freq$count * pixel_area\n      freq$percentage &lt;- (freq$area_ha / sum(freq$area_ha)) * 100\n      freq$region &lt;- region\n      freq$year &lt;- year\n      results[[paste(region, year, sep = \"_\")]] &lt;- freq\n    }\n  }\n  \n  return(do.call(rbind, results))\n}\n\n# Organize rasters into a named list\nrasters &lt;- list(\n  \"2014\" = LULC_COUNTY_2014,\n  \"2019\" = LULC_COUNTY_2019,\n  \"2024\" = LULC_COUNTY_2024\n)\n\n# Compute land cover summary\nland_cover_summary &lt;- compute_land_cover_summary(jurisdiction, rasters, pixel_area_ha)\nwrite.csv(land_cover_summary, \"./data/tables/land_cover_stats.csv\", row.names = F)\nland_cover_summary\n\n\nLULC_LIBERIA_2014=terra::rast(\"./data/LULC/LULC_LIBERIA_2014-01-04.tif\")\nLULC_LIBERIA_2019=terra::rast(\"./data/LULC/LULC_LIBERIA_2019-01-02.tif\")\nLULC_LIBERIA_2024=terra::rast(\"./data/LULC/LULC_LIBERIA_2024-01-16.tif\")\n\ncode_dict &lt;- data.frame(id = c(1, 2, 3, 4, 5, 6, 7),\n  label = c(\n    \"Bareground\", \"Cropland\", \n    \"Forest\", \"Shrubland\", \n    \"Wetland\", \"Urban\", \n    \"Water\"))\n\nlevels(LULC_LIBERIA_2014) &lt;- code_dict\nlevels(LULC_LIBERIA_2019) &lt;- code_dict\nlevels(LULC_LIBERIA_2024) &lt;- code_dict\n\nLULC_LIBERIA_2014 = terra::project(LULC_LIBERIA_2014, \"EPSG:32629\")\nLULC_LIBERIA_2019 = terra::project(LULC_LIBERIA_2019, \"EPSG:32629\")\nLULC_LIBERIA_2024 = terra::project(LULC_LIBERIA_2024, \"EPSG:32629\")\ncountry_metric = sf::st_transform(country, 32629) |&gt; terra::vect()\npixel_area_ha &lt;- 0.088914  # 29.80124 x 29.80124 m² converted to hectares\n\n\ncompute_land_cover_summary &lt;- function(country_metric, rasters, pixel_area) {\n  results &lt;- list()\n    if (terra::nrow(country_metric) == 0) {\n    stop(\"The provided SpatVector jurisdiction is empty.\")\n  }\n  for (region in unique(country_metric$name)) {\n    for (year in names(rasters)) {\n      cropped_raster &lt;- terra::crop(\n        rasters[[year]],\n        country_metric[country_metric$name == region, ],\n        mask = TRUE\n      )\n      if (terra::ncell(cropped_raster) == 0) {\n        warning(paste(\"Cropped raster for\", region, year, \"is empty. Skipping.\"))\n        next\n      }\n      freq &lt;- terra::freq(cropped_raster)\n      freq$area_ha &lt;- freq$count * pixel_area\n      freq$percentage &lt;- (freq$area_ha / sum(freq$area_ha)) * 100\n      freq$region &lt;- region\n      freq$year &lt;- year\n      results[[paste(region, year, sep = \"_\")]] &lt;- freq\n    }\n  }\n  \n  return(do.call(rbind, results))\n}\n\n# Organize rasters into a named list\nrasters &lt;- list(\n  \"2014\" = LULC_LIBERIA_2014,\n  \"2019\" = LULC_LIBERIA_2019,\n  \"2024\" = LULC_LIBERIA_2024\n)\n\n# Compute land cover summary\nland_cover_summary &lt;- compute_land_cover_summary(country_metric, rasters, pixel_area_ha)\nwrite.csv(land_cover_summary, \"./data/tables/land_cover_country.csv\", row.names = F)\nland_cover_summary\n\n\ncountry_merc = sf::st_transform(country, 3857) |&gt; terra::vect()\nLULC_LIBERIA_2017=terra::rast(\"./data/LULC/IO_LULC_LIBERIA_2017.tif\") |&gt; terra::crop(country_merc, mask=T)\nLULC_LIBERIA_2023=terra::rast(\"./data/LULC/IO_LULC_LIBERIA_2023.tif\") |&gt; terra::crop(country_merc, mask=T)\ncode_dict &lt;- data.frame(id = c(1, 2, 4, 5, 7, 10, 11),  \n  label = c(\"Water\", \"Forest\", \"Wetland\", \"Bareground\",\n            \"Built\", \"Cropland\", \"Rangeland\"))\nlevels(LULC_LIBERIA_2017) &lt;- code_dict\nlevels(LULC_LIBERIA_2023) &lt;- code_dict\n\npixel_area_ha &lt;- res(LULC_LIBERIA_2017)[1] * res(LULC_LIBERIA_2017)[2] / 10000\ncompute_land_cover_summary &lt;- function(country_merc, rasters, pixel_area) {\n  results &lt;- list()\n  if (terra::nrow(country_merc) == 0)\n    {stop(\"The provided SpatVector jurisdiction is empty.\")}\n  for (region in unique(country_merc$name)) \n    {for (year in names(rasters)) \n      {cropped_raster &lt;- terra::crop(rasters[[year]],\n        country_merc[country_merc$name == region, ],\n        mask = TRUE)\n      if (terra::ncell(cropped_raster) == 0) \n        {warning(paste(\"Cropped raster for\", region, year, \"is empty. Skipping.\"))next}\n      freq = terra::freq(cropped_raster)\n      freq$area_ha = freq$count * pixel_area\n      freq$percentage = (freq$area_ha / sum(freq$area_ha)) * 100\n      freq$region = region\n      freq$year = year\n      results[[paste(region, year, sep = \"_\")]] &lt;- freq\n      }\n    }\n  return(do.call(rbind, results))\n  }\n\n# Organize rasters into a named list\nrasters &lt;- list(\"2017\" = LULC_LIBERIA_2017,\n                \"2023\" = LULC_LIBERIA_2023)\n\n# Compute land cover summary\nland_cover_summary &lt;- compute_land_cover_summary(country_merc, rasters, pixel_area_ha)\nwrite.csv(land_cover_summary, \"./data/tables/land_cover_country_io.csv\", row.names = F)\nland_cover_summary\n\n\ncounties = sf::st_read(\"./data/covariates/places_poly_county.shp\")\njurisdiction_merc = counties |&gt; dplyr::filter(\n  name == \"Grand Cape Mount County\" | name == \"Gharpolu County\" ) |&gt; \n  terra::vect() |&gt; \n  terra::project(\"EPSG:3857\")\njurisdiction_merc$name = 'Grand Cape Mount & Gharpolu Counties'\nvoi = sf::st_transform(aoi, 3857) |&gt; terra::vect()\n\ncountry_merc = sf::st_transform(country, 3857) |&gt; terra::vect()\nLULC_LIBERIA_2017=terra::rast(\"./data/LULC/IO_LULC_LIBERIA_2017.tif\") |&gt; terra::crop(country_merc, mask=T)\nLULC_LIBERIA_2023=terra::rast(\"./data/LULC/IO_LULC_LIBERIA_2023.tif\") |&gt; terra::crop(country_merc, mask=T)\ncode_dict &lt;- data.frame(id = c(1, 2, 4, 5, 7, 10, 11),  \n  label = c(\"Water\", \"Forest\", \"Wetland\", \"Bareground\",\n            \"Built\", \"Cropland\", \"Rangeland\"))\nlevels(LULC_LIBERIA_2017) &lt;- code_dict\nlevels(LULC_LIBERIA_2023) &lt;- code_dict\n\nLULC_PROJECT_2017 = LULC_LIBERIA_2017 |&gt; terra::crop(voi, mask=T)\nLULC_PROJECT_2023 = LULC_LIBERIA_2023 |&gt; terra::crop(voi, mask=T)\nLULC_COUNTY_2017 = LULC_LIBERIA_2017 |&gt; terra::crop(jurisdiction_merc, mask=T)\nLULC_COUNTY_2023 = LULC_LIBERIA_2023 |&gt; terra::crop(jurisdiction_merc, mask=T)\n\ncode_dict &lt;- data.frame(id = c(1, 2, 4, 5, 7, 10, 11),  \n  label = c(\"Water\", \"Forest\", \"Wetland\", \"Bareground\",\n            \"Built\", \"Cropland\", \"Rangeland\"))\n\nlevels(LULC_COUNTY_2017) &lt;- code_dict\nlevels(LULC_COUNTY_2023) &lt;- code_dict\nlevels(LULC_PROJECT_2017) &lt;- code_dict\nlevels(LULC_PROJECT_2023) &lt;- code_dict\n\ncompute_land_cover_summary &lt;- function(jurisdiction_merc, rasters, pixel_area) {\n  results &lt;- list()\n    if (terra::nrow(jurisdiction_merc) == 0) {\n    stop(\"The provided SpatVector jurisdiction is empty.\")\n  }\n  for (region in unique(jurisdiction_merc$name)) {\n    for (year in names(rasters)) {\n      cropped_raster &lt;- terra::crop(\n        rasters[[year]],\n        jurisdiction_merc[jurisdiction_merc$name == region, ],\n        mask = TRUE\n      )\n      if (terra::ncell(cropped_raster) == 0) {\n        warning(paste(\"Cropped raster for\", region, year, \"is empty. Skipping.\"))\n        next\n      }\n      freq &lt;- terra::freq(cropped_raster)\n      freq$area_ha &lt;- freq$count * pixel_area\n      freq$percentage &lt;- (freq$area_ha / sum(freq$area_ha)) * 100\n      freq$region &lt;- region\n      freq$year &lt;- year\n      results[[paste(region, year, sep = \"_\")]] &lt;- freq\n    }\n  }\n  \n  return(do.call(rbind, results))\n}\n\n# Organize rasters into a named list\nrasters &lt;- list(\n  \"2017\" = LULC_COUNTY_2017,\n  \"2023\" = LULC_COUNTY_2023\n)\n\n# Compute land cover summary\nland_cover_summary &lt;- compute_land_cover_summary(jurisdiction_merc, rasters, pixel_area_ha)\nwrite.csv(land_cover_summary, \"./data/tables/land_cover_county_io.csv\", row.names = F)\nland_cover_summary\n\n\nland_cover_summary$value &lt;- factor(land_cover_summary$value,\n  levels = c(\"Forest\", \"Water\", \"Rangeland\", \"Built\", \"Cropland\", \"Bareground\", \"Wetland\")\n  )\n\nggplot(land_cover_summary, aes(x = year, y = percentage, fill = value)) +\n  geom_bar(stat = \"identity\", position = \"stack\", width = 0.4) +\n  ggrepel::geom_text_repel(\n  aes(label = paste0(round(percentage, 1), \"%\")),  \n  size = 2.5,  # Smaller text size\n  max.overlaps = Inf,\n  box.padding = 0.3,  \n  point.padding = 0.2,  \n  segment.size = 0.2\n  ) + \n  labs(title = \"Land cover change in Grand Cape Mount & Gharpolu counties\",\n       x = NULL,\n       y = \"Proportion (%)\",\n       fill = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 11, face = \"bold\"),\n    axis.title = element_text(size = 10),\n    axis.text.x = element_text(size = 9, angle = 0, face = \"bold\", hjust = 0.5),\n    axis.text.y = element_text(size = 10),\n    legend.position = \"bottom\"\n  )\n\n\nggplot(land_cover_summary, aes(x = year, y = percentage, fill = value)) + \n  geom_bar(stat = \"identity\", position = \"stack\", width = 0.4) + \n  ggrepel::geom_text_repel(\n    aes(label = paste0(round(percentage, 1), \"%\")),  \n    size = 3, \n    color = \"black\",\n    box.padding = 0.3,  \n    point.padding = 0.2,  \n    direction = \"x\",  # Adjust text to move horizontally\n    max.overlaps = Inf  \n  ) + \n  coord_flip() +  # Flip the chart\n  labs(\n    title = \"Land cover change of project jurisdictions, 2017-2023\", \n    x = \"Year\", \n    y = \"Proportion (%)\", \n    fill = \"Land Cover Class\"\n  ) + \n  theme_minimal()\n\n`mask_gola = terra::rast(“./data/BINARY/mask_gola.tif”) mask_tong = terra::rast(“./data/BINARY/mask_tong.tif”) mask_norm = terra::rast(“./data/BINARY/mask_norm.tif”) mask_project = terra::rast(“./data/BINARY/mask_project.tif”) mask_gola=terra::resample(mask_gola, LULC_PROJECT_2014) mask_tong=terra::resample(mask_tong, LULC_PROJECT_2014) mask_norm=terra::resample(mask_norm, LULC_PROJECT_2014) mask_project=terra::resample(mask_project, LULC_PROJECT_2014)\n\n\nForest area\n\ncounties = sf::st_read(\"./data/covariates/places_poly_county.shp\")\njurisdiction = counties |&gt; dplyr::filter(name == \"Grand Cape Mount County\" | name == \"Gharpolu County\" )\njurisdiction$name = 'Grand Cape Mount & Gharpolu Counties'\ntmap::tmap_mode(\"plot\")\ntmap::tm_shape(jurisdiction) + tmap::tm_borders(lwd = 1.2, col=\"green\") + tmap::tm_text(\"name\", col=\"black\", size=0.9) \n\n # project for hectares\nLULC_LIBERIA_2014 = terra::project(LULC_LIBERIA_2014, \"EPSG:32629\")\nLULC_LIBERIA_2019 = terra::project(LULC_LIBERIA_2019, \"EPSG:32629\")\nLULC_LIBERIA_2024 = terra::project(LULC_LIBERIA_2024, \"EPSG:32629\")\n# Forest binary maps\nforest_class = 3\nforest_2014 &lt;- LULC_LIBERIA_2014 == forest_class\nforest_2019 &lt;- LULC_LIBERIA_2019 == forest_class\nforest_2024 &lt;- LULC_LIBERIA_2024 == forest_class\n# Forest loss maps\nforest_loss_2014_2019_gross &lt;- forest_2014 & !forest_2019\nforest_loss_2019_2024_gross &lt;- forest_2019 & !forest_2024\nforest_gain_2014_2019_gross &lt;- !forest_2014 & forest_2019\nforest_gain_2019_2024_gross &lt;- !forest_2019 & forest_2024\nforest_loss_2014_2019 &lt;- forest_loss_2014_2019_gross & !forest_gain_2014_2019_gross\nforest_loss_2019_2024 &lt;- forest_loss_2019_2024_gross & !forest_gain_2019_2024_gross\n# Write to disk\nraster::writeRaster(forest_2014, \"./data/BINARY/forest_2014.tif\",overwrite=T)\nraster::writeRaster(forest_2019, \"./data/BINARY/forest_2019.tif\",overwrite=T)\nraster::writeRaster(forest_2024, \"./data/BINARY/forest_2024.tif\",overwrite=T)\nraster::writeRaster(forest_loss_2014_2019, \"./data/BINARY/forest_loss_2014_2019.tif\",overwrite=T)\nraster::writeRaster(forest_loss_2019_2024, \"./data/BINARY/forest_loss_2019_2024.tif\",overwrite=T)\n\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2014.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2019.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2024.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2014_2019.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2019_2024.tif\n\n\nError: object 'forest_2014' not found\n\n\nError: object 'forest_2019' not found\n\n\nError: object 'forest_2024' not found\n\n\nError: object 'forest_loss_2014_2019' not found\n\n\nError: object 'forest_loss_2019_2024' not found\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': object 'forest_2014' not found\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': object 'forest_2019' not found\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': object 'forest_2024' not found\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': object 'forest_loss_2014_2019' not found\n\n\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': object 'forest_loss_2019_2024' not found\n\n\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2014_gola.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2014_tong.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2014_norm.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2014_project.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2019_gola.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2019_tong.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2019_norm.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2019_project.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2024_gola.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2024_tong.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2024_norm.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_2024_project.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2014_2019_gola.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2014_2019_tong.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2014_2019_norm.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2014_2019_project.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2019_2024_gola.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2019_2024_tong.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2019_2024_norm.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2019_2024_project.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2014_2024_gola.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2014_2024_tong.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2014_2024_norm.tif\n\n\nError: [rast] file does not exist: ./data/BINARY/forest_loss_2014_2024_project.tif\n\n\n\n# Calculate total number of forest pixels for each year\nresolution &lt;- terra::res(forest_2014)[1]\nforest_2014_estimate &lt;- sum(forest_2014[], na.rm = TRUE) * resolution^2 / 10000\nforest_2019_estimate &lt;- sum(forest_2019[], na.rm = TRUE) * resolution^2 / 10000\nforest_2024_estimate &lt;- sum(forest_2024[], na.rm = TRUE) * resolution^2 / 10000\nforest_loss_2014_2019_estimate &lt;- sum(forest_loss_2014_2019[],na.rm=T)*resolution^2/10000\nforest_loss_2019_2024_estimate &lt;- sum(forest_loss_2019_2024[],na.rm=T)*resolution^2/10000\ncat(\"Total forest area across Liberia in 2014:\", forest_2014_estimate, \"hectares\\n\")\ncat(\"Total forest area across Liberia in 2019:\", forest_2019_estimate, \"hectares\\n\")\ncat(\"Total forest area across Liberia in 2024:\", forest_2024_estimate, \"hectares\\n\")\ncat(\"Total forest Loss across Liberia (2014-2019):\", forest_loss_2014_2019_estimate, \"hectares\\n\")\ncat(\"Total forest Loss across Liberia (2019-2024):\", forest_loss_2019_2024_estimate, \"hectares\\n\")\n\n\n# Calculate forest area for each sub-region (in hectares) for all years\nforest_2014=terra::rast(\"./data/BINARY/forest_2014.tif\")\nresolution &lt;- terra::res(forest_2014)[1]\nforest_2014_gola_estimate &lt;- sum(forest_2014_gola[], na.rm = TRUE) * resolution^2 / 10000\nforest_2014_tong_estimate &lt;- sum(forest_2014_tong[], na.rm = TRUE) * resolution^2 / 10000\nforest_2014_norm_estimate &lt;- sum(forest_2014_norm[], na.rm = TRUE) * resolution^2 / 10000\nforest_2014_project_estimate &lt;- sum(forest_2014_project[], na.rm = TRUE) * resolution^2 / 10000\nforest_2019_gola_estimate &lt;- sum(forest_2019_gola[], na.rm = TRUE) * resolution^2 / 10000\nforest_2019_tong_estimate &lt;- sum(forest_2019_tong[], na.rm = TRUE) * resolution^2 / 10000\nforest_2019_norm_estimate &lt;- sum(forest_2019_norm[], na.rm = TRUE) * resolution^2 / 10000\nforest_2019_project_estimate &lt;- sum(forest_2019_project[], na.rm = TRUE) * resolution^2 / 10000\nforest_2024_gola_estimate &lt;- sum(forest_2024_gola[], na.rm = TRUE) * resolution^2 / 10000\nforest_2024_tong_estimate &lt;- sum(forest_2024_tong[], na.rm = TRUE) * resolution^2 / 10000\nforest_2024_norm_estimate &lt;- sum(forest_2024_norm[], na.rm = TRUE) * resolution^2 / 10000\nforest_2024_project_estimate &lt;- sum(forest_2024_project[], na.rm = TRUE) * resolution^2 / 10000\n\n# Calculate forest loss for each sub-region (in hectares) for all periods\nforest_loss_2014_2019_gola_estimate&lt;-sum(forest_loss_2014_2019_gola[],na.rm=T)*resolution^2/10000\nforest_loss_2014_2019_tong_estimate &lt;- sum(forest_loss_2014_2019_tong[],na.rm=T)*resolution^2/10000\nforest_loss_2014_2019_norm_estimate &lt;- sum(forest_loss_2014_2019_norm[],na.rm=T)*resolution^2/10000\nforest_loss_2014_2019_project_estimate &lt;- sum(forest_loss_2014_2019_project[],na.rm=T)*resolution^2/10000\nforest_loss_2019_2024_gola_estimate&lt;- sum(forest_loss_2019_2024_gola[],na.rm=T)*resolution^2/10000\nforest_loss_2019_2024_tong_estimate &lt;- sum(forest_loss_2019_2024_tong[],na.rm=T)*resolution^2/10000\nforest_loss_2019_2024_norm_estimate &lt;- sum(forest_loss_2019_2024_norm[],na.rm=T)*resolution^2/10000\nforest_loss_2019_2024_project_estimate &lt;- sum(forest_loss_2019_2024_project[],na.rm=T)*resolution^2/10000\nforest_loss_2014_2024_gola_estimate &lt;- sum(forest_loss_2014_2024_gola[],na.rm=T)*resolution^2/10000\nforest_loss_2014_2024_tong_estimate &lt;- sum(forest_loss_2014_2024_tong[],na.rm=T)*resolution^2/10000\nforest_loss_2014_2024_norm_estimate &lt;- sum(forest_loss_2014_2024_norm[],na.rm=T)*resolution^2/10000\nforest_loss_2014_2024_project_estimate &lt;- sum(forest_loss_2014_2024_project[],na.rm=T)*resolution^2/10000\n\n# Print out the forest area and loss estimates for each region and year\ncat(\"Forest Area in Gola NP (2014):\", forest_2014_gola_estimate, \"hectares\\n\")\ncat(\"Forest Area in Tonglay (2014):\", forest_2014_norm_estimate, \"hectares\\n\")\ncat(\"Forest Area in Norman (2014):\", forest_2014_tong_estimate, \"hectares\\n\")\ncat(\"Forest Area in Project (2014):\", forest_2014_project_estimate, \"hectares\\n\")\ncat(\"Forest Area in Gola NP (2019):\", forest_2019_gola_estimate, \"hectares\\n\")\ncat(\"Forest Area in Tonglay (2019):\", forest_2019_tong_estimate, \"hectares\\n\")\ncat(\"Forest Area in Norman (2019):\", forest_2019_norm_estimate, \"hectares\\n\")\ncat(\"Forest Area in Project (2019):\", forest_2019_project_estimate, \"hectares\\n\")\ncat(\"Forest Area in Gola NP (2024):\", forest_2024_gola_estimate, \"hectares\\n\")\ncat(\"Forest Area in Tonglay (2024):\", forest_2024_tong_estimate, \"hectares\\n\")\ncat(\"Forest Area in Norman (2024):\", forest_2024_norm_estimate, \"hectares\\n\")\ncat(\"Forest Area in Project (2024):\", forest_2024_project_estimate, \"hectares\\n\")\n\ncat(\"Forest Loss in Gola NP (2014-2019):\", forest_loss_2014_2019_gola_estimate, \"hectares\\n\")\ncat(\"Forest Loss in Tonglay (2014-2019):\", forest_loss_2014_2019_tong_estimate, \"hectares\\n\")\ncat(\"Forest Loss in Norman (2014-2019):\", forest_loss_2014_2019_norm_estimate, \"hectares\\n\")\ncat(\"Forest Loss in Project (2014-2019):\", forest_loss_2014_2019_project_estimate, \"hectares\\n\")\ncat(\"Forest Loss in Gola NP (2019-2024):\", forest_loss_2019_2024_gola_estimate, \"hectares\\n\")\ncat(\"Forest Loss in Tonglay (2019-2024):\", forest_loss_2019_2024_tong_estimate, \"hectares\\n\")\ncat(\"Forest Loss in Norman (2019-2024):\", forest_loss_2019_2024_norm_estimate, \"hectares\\n\")\ncat(\"Forest Loss in Project (2019-2024):\", forest_loss_2019_2024_project_estimate, \"hectares\\n\")\ncat(\"Forest Loss in Gola NP (2014-2024):\", forest_loss_2014_2024_gola_estimate, \"hectares\\n\")\ncat(\"Forest Loss in Tonglay (2014-2024):\", forest_loss_2014_2024_tong_estimate, \"hectares\\n\")\ncat(\"Forest Loss in Norman (2014-2024):\", forest_loss_2014_2024_norm_estimate, \"hectares\\n\")\ncat(\"Forest Loss in Project (2014-2024):\", forest_loss_2014_2024_project_estimate, \"hectares\\n\")",
    "crumbs": [
      "Home",
      "Risk"
    ]
  },
  {
    "objectID": "deforisk.html#deforestation-allocation",
    "href": "deforisk.html#deforestation-allocation",
    "title": "Deforestation Risk",
    "section": "Deforestation allocation",
    "text": "Deforestation allocation\nThe following spatial covariates were imported and processed as potential drivers of deforestation risk. Covariates were merged between sociodemographic and geographic datasets surrounding the project area and national level datasets beyond the project area in order to enable jurisdictions analysis.\nFurther updates are expected to these spatial coveriates pending delivery of proprietary data from the client. We also recommend that these mapping and risk assessments be revised or replaced prior to submission of PD, and following the release of Liberia’s Activity Data and jurisdictional deforestation risk maps planned by Verra in Q3 of 2025. For collective review, final covariates were visualized in the following interactive map.\n\nDemography & topography\n\n##############################\n##### Covariate wrangling#####\n##############################\n\n##### Download sociodemography\npop_url &lt;- \"https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/GHS_POP_GLOBE_R2023A/GHS_POP_E2025_GLOBE_R2023A_54009_1000/V1-0/GHS_POP_E2025_GLOBE_R2023A_54009_1000_V1_0.zip\" \nosm_url &lt;- \"https://download.geofabrik.de/africa/liberia-latest-free.shp.zip\" \n\n##### Built Environment\nplaces_points_project=sf::st_read(\"./data/Winrock_GIS/Communities_8km.shp\")|&gt;\n  st_cast(\"POINT\")|&gt;dplyr::select(name,fclass)|&gt;rename(place=fclass)|&gt;\n  mutate(place = as.factor(place)) |&gt; mutate(name = as.character(name))\n\nplaces_points_liberia_1=sf::st_read(\"./data/liberia-osmdata/liberia_point.shp\")|&gt;\n  st_cast(\"POINT\")|&gt;sf::st_intersection(country)|&gt;\n  dplyr::select(name,place)|&gt;\n  dplyr::mutate(place = as.factor(place)) |&gt; \n  dplyr::mutate(name = as.character(name))\n\nplaces_points_liberia_2 &lt;- sf::st_read(\"./data/liberia-osmdata/gis_osm_places_free_1.shp\")|&gt;\n  st_cast(\"POINT\")|&gt;sf::st_intersection(country)|&gt;\n  dplyr::select(name,fclass)|&gt;\n  dplyr::rename(place=fclass)|&gt;\n  dplyr::mutate(place = as.factor(place))|&gt; \n  dplyr::mutate(name = as.character(name))\n\nplaces_worship &lt;- sf::st_read(\"./data/liberia-osmdata/gis_osm_pofw_free_1.shp\") |&gt;\n  sf::st_intersection(country)|&gt;\n  dplyr::select(name,fclass)|&gt;\n  dplyr::rename(creed=fclass) |&gt; \n  dplyr::mutate(creed=as.factor(creed))  |&gt; \n  dplyr::mutate(name = as.character(name)) |&gt; \n  st_cast(\"POINT\")\n\nplaces_points &lt;- places_points_project %&gt;%\n  bind_rows(places_points_liberia_1,places_points_liberia_2, places_worship) %&gt;%\n  group_by(across(-geometry)) %&gt;%\n  summarise(geometry = st_union(geometry), .groups = \"drop\")\nplaces_points = sf::st_cast(places_points, \"POINT\")\nsf::st_write(places_points, \"./data/covariates/places_points.shp\", delete_dsn=T)\n\n##### Administrative Boundaries\nplaces_poly_liberia &lt;- sf::st_read(\"./data/liberia-osmdata/liberia_poly.shp\")|&gt;st_cast(\"GEOMETRY\")\nplaces_poly_county &lt;- places_poly_liberia[st_geometry_type(places_poly_liberia) %in% c(\"POLYGON\", \"MULTIPOLYGON\"), ] |&gt;\n  sf::st_intersection(country)|&gt;\n  dplyr::select(name,place,admin_leve)|&gt;\n  dplyr::mutate(place = as.factor(place)) |&gt; \n  dplyr::mutate(name = as.character(name)) |&gt;\n  dplyr::rename(admin_level = admin_leve) |&gt;\n  dplyr::filter(admin_level == \"4\") \nplaces_poly_county &lt;- places_poly_county[st_geometry_type(places_poly_county) %in% c(\"POLYGON\", \"MULTIPOLYGON\"), ] |&gt;\n  sf::st_cast(\"MULTIPOLYGON\")\nsf::st_write(places_poly_county, \"./data/covariates/places_poly_county.shp\", delete_dsn=T)  \n\nplaces_poly_district &lt;- places_poly_liberia[st_geometry_type(places_poly_liberia) %in% c(\"POLYGON\", \"MULTIPOLYGON\"), ] |&gt;\n  st_cast(\"POLYGON\")|&gt;sf::st_intersection(country)|&gt;\n  dplyr::select(name,place,admin_leve)|&gt;\n  dplyr::mutate(place = as.factor(place)) |&gt; \n  dplyr::mutate(name = as.character(name)) |&gt;\n  dplyr::rename(admin_level = admin_leve) |&gt;\n  dplyr::filter(admin_level == \"6\")\nplaces_poly_district &lt;- places_poly_district[st_geometry_type(places_poly_district) %in% c(\"POLYGON\", \"MULTIPOLYGON\"), ] |&gt;\n  sf::st_cast(\"MULTIPOLYGON\")\nsf::st_write(places_poly_district, \"./data/covariates/places_poly_district.shp\", delete_dsn=T)  \n\nbuildings_private &lt;- sf::st_read(\"./data/liberia-osmdata/gis_osm_buildings_a_free_1.shp\") |&gt; \n  sf::st_intersection(country) |&gt; sf::st_simplify(preserveTopology = FALSE, dTolerance = 1000) |&gt;\n  dplyr::select(name,fclass) |&gt;\n  dplyr::rename(place = fclass) |&gt; \n  dplyr::mutate(place = as.factor(place))|&gt; \n  dplyr::mutate(name = as.character(name)) |&gt;\n  st_cast(\"MULTIPOLYGON\") \nsf::st_write(buildings_private, \"./data/covariates/buildings_private.shp\", delete_dsn=T)\n\nbuildings_public &lt;- sf::st_read(\"./data/liberia-osmdata/gis_osm_pois_a_free_1.shp\")  |&gt;\n  sf::st_intersection(country) |&gt;\n  dplyr::select(name,fclass) |&gt;\n  dplyr::rename(place = fclass) |&gt; \n  dplyr::mutate(place = as.factor(place))|&gt; \n  dplyr::mutate(name = as.character(name)) |&gt;\n  st_cast(\"MULTIPOLYGON\") \nsf::st_write(buildings_public, \"./data/covariates/buildings_public.shp\", delete_dsn=T)\n\nbuildings_merged &lt;- buildings_private |&gt; bind_rows(buildings_public) |&gt;\n  group_by(across(-geometry)) |&gt; summarise(geometry = st_union(geometry), .groups = \"drop\")\nbuildings_merged = sf::st_cast(buildings_merged, \"POLYGON\")\nsf::st_write(buildings_merged, \"./data/covariates/buildings.shp\", delete_dsn=T)\n\n\n###### Waterways \nwaterways_liberia = sf::st_read(\"./data/liberia-osmdata/gis_osm_waterways_free_1.shp\") |&gt;\n  sf::st_intersection(bbox_country) |&gt;\n  dplyr::select(name,fclass) |&gt;\n  dplyr::mutate(fclass = as.factor(fclass))|&gt; \n  dplyr::mutate(name = as.character(name))\nwaterways_liberia &lt;- waterways_liberia[st_geometry_type(waterways_liberia) %in% c(\"LINESTRING\", \"MULTILINESTRING\"), ] |&gt;\n  st_cast(\"MULTILINESTRING\") \n\nwaterways_project = sf::st_read(\"./data/Winrock_GIS/PA_river.shp\") |&gt;\n  sf::st_intersection(bbox_country) |&gt;\n  dplyr::select(name,fclass) |&gt;\n  dplyr::mutate(fclass = as.factor(fclass))|&gt; \n  dplyr::mutate(name = as.character(name))\nwaterways_project &lt;- waterways_project[st_geometry_type(waterways_project) %in% c(\"LINESTRING\", \"MULTILINESTRING\"), ] |&gt;\n  st_cast(\"MULTILINESTRING\") \n\nwaterways_hydrosheds = sf::st_read(\"/Users/seamus/repos/rspb-redd-risk-new/data/hydro/HydroRIVERS_v10_af.shp\") |&gt; \n  sf::st_intersection(bbox_country)\nwaterways_hydrosheds &lt;- waterways_hydrosheds[st_geometry_type(waterways_hydrosheds) %in% c(\"LINESTRING\", \"MULTILINESTRING\"), ] |&gt;\n  st_cast(\"MULTILINESTRING\") \n    \nwaterways_merged &lt;- waterways_liberia |&gt; bind_rows(waterways_project) |&gt;\n  group_by(across(-geometry)) |&gt; summarise(geometry = st_union(geometry), .groups = \"drop\")\nwaterways_merged = sf::st_cast(waterways_merged, \"MULTILINESTRING\")\nsf::st_write(waterways_merged, \"./data/covariates/waterways_merged.shp\", delete_dsn=T)\n\nwaterbodies_collection = sf::st_read(\"./data/liberia-osmdata/gis_osm_water_a_free_1.shp\") |&gt; \n  sf::st_intersection(bbox_country) |&gt;\n  dplyr::select(name,fclass) |&gt;\n  dplyr::mutate(fclass = as.factor(fclass))|&gt; \n  dplyr::mutate(name = as.character(name))\nwaterbodies_poly &lt;- waterbodies_collection[st_geometry_type(waterbodies_collection) %in% c(\"POLYGON\", \"MULTIPOLYGON\"), ] \nwaterbodies_lines &lt;- waterbodies_collection[st_geometry_type(waterbodies_collection) %in% c(\"LINESTRING\", \"MULTILINESTRING\"), ] \nwaterbodies_poly_lines = sf::st_boundary(waterbodies_poly)\n\nwaterbodies_waterways_merged &lt;- waterbodies_lines |&gt; bind_rows(waterbodies_poly_lines, waterways_merged) |&gt;\n  group_by(across(-geometry)) |&gt; summarise(geometry = st_union(geometry), .groups = \"drop\")\nwaterbodies_waterways_merged = sf::st_cast(waterbodies_waterways_merged, \"MULTILINESTRING\")\nsf::st_write(waterbodies_waterways_merged, \"./data/covariates/waterbodies_waterways_merged.shp\", delete_dsn=T)\n\n\n###### Transport & Infrastructure\ntransport=sf::st_read(\"./data/liberia-osmdata/gis_osm_transport_a_free_1.shp\")|&gt; st_boundary()|&gt;\n  sf::st_intersection(bbox_country_2) |&gt;\n  dplyr::select(name,fclass) |&gt;\n  dplyr::mutate(fclass = as.factor(fclass))|&gt; \n  dplyr::mutate(name = as.character(name))\n\nrailways = sf::st_read(\"./data/liberia-osmdata/gis_osm_railways_free_1.shp\") |&gt;\n  sf::st_intersection(bbox_country_2) |&gt;\n  dplyr::select(name,fclass) |&gt;\n  dplyr::mutate(fclass = as.factor(fclass))|&gt; \n  dplyr::mutate(name = as.character(name))\n\nroads_liberia = sf::st_read(\"./data/liberia-osmdata/gis_osm_roads_free_1.shp\") |&gt;\n  sf::st_intersection(bbox_country_2) |&gt;\n  dplyr::select(name,fclass) |&gt;\n  dplyr::mutate(fclass = as.factor(fclass))|&gt; \n  dplyr::mutate(name = as.character(name))\n\nroads_project = sf::st_read(\"./data/Winrock_GIS/PA_roads.shp\") |&gt;\n  sf::st_intersection(bbox_country_1) |&gt;\n  dplyr::select(name,fclass) |&gt;\n  dplyr::mutate(fclass = as.factor(fclass))|&gt; \n  dplyr::mutate(name = as.character(name))\n\nroads_rail_transport_merged &lt;- transport |&gt; \n  bind_rows(railways, roads_liberia, roads_project) |&gt;\n  group_by(across(-geometry)) |&gt; \n  summarise(geometry = st_union(geometry), .groups = \"drop\")\n\nroads = sf::st_cast(roads_rail_transport_merged, \"MULTILINESTRING\")\nsf::st_write(roads, \"./data/covariates/roads_rail_transport_merged.shp\", delete_dsn=T)\n\nroads &lt;- roads |&gt; bind_rows(roads_sle) |&gt; group_by(across(-geometry)) |&gt; \n  summarise(geometry = st_union(geometry), .groups = \"drop\")\nsf::st_write(roads, \"./data/covariates/roads_intl.shp\", delete_dsn=T)\n\nroads_lib = sf::st_read(\"./data/covariates/roads_intl.shp\") |&gt; st_cast(\"MULTILINESTRING\")\nroads_sle = sf::st_read(\"./data/liberia-osmdata/hotosm_sle_roads_lines_shp.shp\") |&gt;st_cast(\"MULTILINESTRING\")\nroads_lib   = sf::st_intersection(roads_lib, bbox_aoi_2)|&gt;dplyr::select(name)\nroads_sle   = sf::st_intersection(roads_sle, bbox_aoi_2)|&gt;dplyr::select(name)\nroads   = rbind(roads_lib, roads_sle)\nsf::st_write(roads, \"./data/ROADS/roads.shp\", delete_layer=T)\n\nroads_lib = sf::st_intersection(roads_lib, bbox_aoi_2)\nroads_sle = sf::st_intersection(roads_sle, bbox_aoi_2)\n\ntmap::tm_shape(roads_clip) + tmap::tm_lines(col=\"orange\", lwd=0.6) + tmap::tm_shape(aoi) + tm_borders(col=\"red\", lwd=1.7)\n\n##### Slope / Elevation\ndem   = raster::subset(STACK, \"DEM\")\nslope_tangent = raster::terrain(\n  dem, opt=\"slope\",unit=\"tangent\",neighbors=8,filename=\"./data/DEM/slope_tangent.tif\")\nslope_tangent = terra::rast(\"./data/DEM/slope_tangent.tif\")\nslope_percent = slope_tangent * 100\nslope_percent = terra::clamp(slope_percent, 0, 100) \nslope_percent = raster::raster(slope_percent)\nraster::writeRaster(slope_percent, \"./data/covariates/slope_percent.tif\")\n\nurban &lt;- terra::mask(LULC_LIBERIA_2024, LULC_LIBERIA_2024 == 4, maskvalue = FALSE)\nurban &lt;- raster::raster(urban)\nraster::writeRaster(urban, \"./data/covariates/urban.tif\", overwrite=T)\n\n\n\nAnnualized deforestation\n\n# Assign zones\nzones_sf = counties |&gt; sf::st_transform(\"EPSG:32629\")\nzones_sf$zone_id &lt;- 1:nrow(zones_sf)\nzones_sv &lt;- terra::vect(zones_sf)\n\n# Calculate zonal annualization by jurisdiction\nforest_2024 = terra::rast(\"./data/BINARY/forest_2024.tif\")\nforest_loss_2014_2019 = terra::rast(\"./data/BINARY/forest_loss_2014_2019.tif\")\nforest_loss_2019_2024 = terra::rast(\"./data/BINARY/forest_loss_2019_2024.tif\")\nforest_loss_2014_2024 = terra::rast(\"./data/BINARY/forest_loss_2014_2024.tif\")\npixel_area_ha &lt;- 0.088914  # 29.80124 x 29.80124 m² converted to hectares\n\nzonal_2014_2019 &lt;- terra::extract(forest_loss_2014_2019,zones_sv,fun=sum,na.rm=T)\nzonal_2019_2024 &lt;- terra::extract(forest_loss_2019_2024,zones_sv,fun=sum,na.rm=T)\nnames(zonal_2014_2019) &lt;- c(\"zone_id\", \"loss_2014_2019\")\nnames(zonal_2019_2024) &lt;- c(\"zone_id\", \"loss_2019_2024\")\nzonal_2014_2019$loss_2014_2019 &lt;- zonal_2014_2019$loss_2014_2019 * pixel_area_ha\nzonal_2019_2024$loss_2019_2024 &lt;- zonal_2019_2024$loss_2019_2024 * pixel_area_ha\n\n# Merge baseline years\nzonal_stats &lt;- merge(\n  zonal_2014_2019,      # e.g. (zone_id, loss_2014_2019)\n  zonal_2019_2024,      # e.g. (zone_id, loss_2019_2024)\n  by = \"zone_id\",       # Common ID column\n  all = TRUE            # Keep all rows if zones differ\n)\n# Annualize 10-year total & rejoin to sf object\nzonal_stats$loss_10yr &lt;- zonal_stats$loss_2014_2019 + zonal_stats$loss_2019_2024\nzonal_stats$annual_loss_10yr &lt;- zonal_stats$loss_10yr / 10\nzones_sf &lt;- merge(zones_sf, zonal_stats, by=\"zone_id\", all.x=TRUE)\nhead(zones_sf[, c(\"zone_id\", \"loss_2014_2019\", \"loss_2019_2024\", \n                  \"loss_10yr\", \"annual_loss_10yr\")])\n\n# Derive 10-yr annualized raster\nzones_sv &lt;- terra::vect(zones_sf)\nannual_loss_10yr_raster &lt;- rasterize(\n  zones_sv,                  # polygon SpatVector\n  forest_loss_2014_2019,     # template raster for resolution/extent\n  field = \"annual_loss_10yr\") # the column to rasterize\nnames(annual_loss_10yr_raster) &lt;- (\"annual_loss_10yr\")\nraster::writeRaster(annual_loss_10yr_raster,\"./data/BINARY/annual_loss_2014_2024_zonal.tif\",overwrite=T)\n\n\n\nDistance covariates\n\n# Derive distance-to-edge raster \nforest_2024 = terra::rast(\"./data/BINARY/forest_2024.tif\")\nforest_mask &lt;- terra::classify(forest_2024, cbind(c(1,0), c(1,NA)))\nnonForest_mask &lt;- terra::classify(forest_2024, cbind(c(1,0), c(NA,1)))\nwriteRaster(forest_mask, \"./data/BINARY/forest_mask.tif\", overwrite=T)\nwriteRaster(nonForest_mask, \"./data/BINARY/nonForest_mask.tif\", overwrite=T)\n\nforest_for_distance &lt;- forest_mask\nforest_for_distance_raster &lt;- raster::raster(forest_for_distance) \ndistance_to_edge &lt;- distance(forest_for_distance_raster, filename=\"./data/BINARY/distance_to_edge_unix.tif\")\n\n# Derive distance-to-feature rasters\ntemplate &lt;- forest_2024\nroads_rast &lt;- rasterize(vect(transport), template, field=1, background=0)\nroads_rast &lt;- subst(roads_rast, from=0, to=NA)\ndistance_to_roads &lt;- distance(roads_rast)\nwriteRaster(distance_to_roads, \"./data/LULC/distance_to_roads.tif\", overwrite=T)\n\nplaces_vect   &lt;- sf::st_read(\"./data/BINARY/places.shp\") |&gt; terra::vect()\nplaces_rast   &lt;- rasterize(places_vect,template,field=1,background=0,touches=T)\nplaces_rast   &lt;- subst(places_rast, from=0, to=NA)\ndistance_to_places&lt;- distance(places_rast)\nwriteRaster(distance_to_places, \"./data/LULC/distance_to_places.tif\", overwrite=T)\n\nwaterways_rast&lt;-rasterize(vect(waterways_rast), template, field=1, background=0)\nwaterways_rast&lt;-subst(waterways_rast, from=0, to=NA)\ndistance_to_waterways&lt;-distance(waterways_rast)\nwriteRaster(distance_to_waterways, \"./data/LULC/distance_to_waterways.tif\", overwrite=T)\n\nurban_rast    &lt;- raster::raster(urban)\nurban_rast    &lt;- subst(urban_rast, from=0, to=NA)\ndistance_to_urban &lt;- distance(urban_rast)\nwriteRaster(distance_to_urban, \"./data/LULC/distance_to_urban.tif\", overwrite=T)\n\n# Normalize covariates for quicker computing\nnormalize &lt;- function(x){\n  (x-global(x,\"min\",na.rm=T))/\n    (global(x,\"max\",na.rm=T) -\n       global(x, \"min\",na.rm=T))}\n\npopulation= raster::raster(population)\npopulation= normalize_function(population)\nslope     = raster::raster(slope)\nslope     = normalize_function(slope)\n\ndistance_to_forest    = normalize_function(distance_to_forest)\ndistance_to_roads     = normalize_function(distance_to_roads)\ndistance_to_places    = normalize_function(distance_to_places)\ndistance_to_water     = normalize_function(distance_to_waterways)\ndistance_to_urban     = normalize_function(distance_to_urban)\n\n# invert all risk-producing covariates\ndistance_to_edge_inv &lt;- 1 - distance_to_forest\ndistance_to_roads_inv  &lt;- 1 - distance_to_roads\ndistance_to_places_inv &lt;- 1 - distance_to_places\ndistance_to_water_inv &lt;- 1 -  distance_to_waterways\ndistance_to_urban_inv   &lt;- 1 - distance_to_urban\n\nwriteRaster(distance_to_edge_inv, \"./data/BINARY/distance_to_edge_inverted.tif\", overwrite=T)\nwriteRaster(distance_to_roads_inv, \"./data/BINARY/distance_to_roads_inverted.tif\", overwrite=T)\nwriteRaster(distance_to_places_inv, \"./data/BINARY/distance_to_places_inverted.tif\", overwrite=T)\nwriteRaster(distance_to_water_inv, \"./data/BINARY/distance_to_water_inverted.tif\", overwrite=T)\nwriteRaster(distance_to_urban_inv, \"./data/BINARY/distance_to_urban_inverted.tif\", overwrite=T)\nwriteRaster(slope_norm, \"./data/BINARY/slope_norm.tif\", overwrite=T)\n\n\n\nDeforestation risk\nTwo methods were explored for weighting variables and creating a generalized deforestation risk index. We could consider developing a spatial risk model using the spatstat package or logistic regression, as has been cited in recent Verra guides. In addition, some of the heavy lifting with input formatting and data wrangling has already been completed.\nHowever, spatial modelling has tended to produce challenges when fitting such large country-wide covariates. Moreover, these kinds of spatialy driven models tend to require longer training procedures due to their intercept-based spatial kernels and slower resampling patterns.\nAlternatively, we have drafted a tentative risk indexing approach based on a weighted sum of subjectively scored covariate effects. While each variable would still need a carefully reasoned score, this option offers a more streamlined method that is easier to adjust. We applied this risk index to inform a risk weighted allocation of the 10-year deforestation rate, first by multiplying the fraction of pixel risk by zonal forest loss, and second by factoring out annual zonal loss by multiplying by pixel risk values, as shown below\n\\[\n\\mathrm{AllocatedLoss}_{\\mathrm{pixel}}\n=\n\\left(\n  \\frac{\\mathrm{risk}_{\\mathrm{pixel}}}{\\sum \\mathrm{risk}_{\\mathrm{zone}}}\n\\right)\n\\times\n\\mathrm{annual\\_loss\\_10yr}_{\\mathrm{zone}}\n\\]\n\\[\n\\mathrm{allocated\\_loss}_{\\mathrm{pixel}}\n=\n\\mathrm{risk}_{\\mathrm{pixel}}\n\\times\n\\left(\n  \\frac{\\mathrm{annual\\_loss\\_10yr}_{\\mathrm{zone}}}{\\sum \\mathrm{risk}_{\\mathrm{zone}}}\n\\right)\n\\]\nBoth formulas describe the same operation in different orders of multiplication: each pixel in a given zone Z receives a share of annual_loss_10yrZ based on its proportional risk (the pixel’s risk relative to the sum of all pixel risks in that zone). This ensures that higher-risk pixels are allocated more deforestation, in line with the Verra guidance for an allocated deforestation risk map.\nWe intend to present both of these approaches for broader review and discussion in our upcoming meeting.\n\nrisk_index &lt;- (0.2 * distance_to_edge) +\n              (0.2 * distance_to_roads) +\n              (0.2 * distance_to_places) +\n              (0.1 * distance_to_urban) +\n              (0.1 * distance_to_water) +\n              (0.1 * slope)\n\n# Re-normalize the index to between 0 and 1\nrmin &lt;- global(risk_index, \"min\", na.rm=TRUE)[1]\nrmax &lt;- global(risk_index, \"max\", na.rm=TRUE)[1]\nrisk_index_norm &lt;- (risk_index - rmin) / (rmax - rmin)\nwriteRaster(risk_index_norm, \"./data/BINARY/deforestation_risk_index.tif\",overwrite=T)\n\n# Returns a data.frame with columns: ID, risk_index_norm_sum\nrisk_sum &lt;- extract(risk_index_norm, zones_sv, fun = sum, na.rm=TRUE)\ncolnames(risk_sum) &lt;- c(\"zone_id\",\"sum_risk\")\nzones_stats &lt;- merge(zones_sf, risk_sum, by=\"zone_id\", all.x=TRUE)\nzones_rast &lt;- rasterize(vect(zones_stats), risk_index_norm, field=\"zone_id\")\nzones_stats$loss_factor &lt;- zones_stats$annual_loss_10yr / zones_stats$sum_risk\nloss_factor_rast &lt;- rasterize(vect(zones_stats), risk_index_norm, field=\"loss_factor\")\nallocated_loss &lt;- risk_index_norm * loss_factor_rast\nwriteRaster(allocated_loss, \"./data/BINARY/allocated_deforestation.tif\", overwrite=T)\n\n# Visualize\nterra::plot(risk_index_norm, main=\"Deforestation risk map\")\nterra::plot(allocated_loss, main=\"Allocated deforestation map\")\n\n\n\nAppendix I: Reference Period Classifiers\nTo run these, you may change eval=F to eval=T at the top of chunk in the .Rmd or .R file saved in the OneDrive folder.\n\n########################### 2019\n# extract signatures\nsignatures_2019 = raster::extract(STACK_2019, samples ,df=T) # watch for data formats\nsamples_signatures_2019 &lt;- dplyr::inner_join(signatures_2019, samples, by=c(\"ID\"=\"id\"))\nsamples_signatures_2019$geometry &lt;- NULL # set geometry to NULL for model training\n\n# training-test split, p=0.7 -&gt; 70% split\npartitioned_data_2019 &lt;- stratified_partition(samples_signatures_2019,group_col=\"label\", train_ratio=0.7)\ntrainData_2019 &lt;- partitioned_data_2019$train\ntestData_2019 &lt;- partitioned_data_2019$test\ntable(trainData_2019$label)\ntable(testData_2019$label)\n\n# synthetic minority oversampling technique\ntrainData_2019&lt;-performanceEstimation::smote(label ~ .,data=trainData_2019,perc.over=10, perc.under=100)\ntestData_2019&lt;-performanceEstimation::smote(label ~ .,data=testData_2019,perc.over=10,perc.under=100)\n# interpolate NAs with class-median-normalization (NAs -&gt; missing cloud pixels)\ntrainData_2019 &lt;- trainData_2019 |&gt; group_by(label) |&gt; mutate(across(where(is.numeric),\n    ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) |&gt; ungroup()\ntestData_2019 &lt;- testData_2019 |&gt; group_by(label) |&gt; mutate(across(where(is.numeric),\n    ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) |&gt; ungroup()\n\n# assign model variables\nresponse  &lt;- c(\"label\")\npredictors_2019 &lt;- c(\n  \"NDVI_2019\", \"BLUE_2019\", \"GREEN_2019\", \"RED_2019\", \n  \"NIR08_2019\", \"SWIR16_2019\", \"SWIR22_2019\", \"DEM\"\n  )\n\n# train classifier\nrf_model_2019 &lt;- caret::train(\n  label~.,\n  data = trainData_2019[, c(predictors_2019, \"label\")], # drop ID var\n  trControl = cv_regime,\n  method    = \"rf\", \n  metric    = 'Kappa', \n  ntree     = 500,\n  tuneLength= 6,\n  importance= T\n  )\n\nrf_test_2019 &lt;- predict(rf_model_2019, testData_2019)\nprint(rf_model_2019) # cv results\nconfusionMatrix(rf_test_2019,testData_2019$label) # blind test results\n\nindex_feature_2019 &lt;- createMultiFolds(trainData_2019$label, times=5) \npredictor_seq_2019 &lt;-seq(from=1, to=length(predictors_2019),by=2)\n\nsubset_regime_2019 &lt;- rfeControl(\n  method=\"LGOCV\",\n  number = 10,\n  verbose=FALSE,\n  functions=rfFuncs,\n  index=index_feature_2019\n  )\n\nrf_model_subset_2019 &lt;- caret::rfe(\n  label~.,\n  data = trainData_2019[, c(predictors_2019, \"label\")], \n  sizes = predictor_seq_2019,\n  metric = \"Kappa\",\n  ntree=500,\n  method=\"rf\",\n  rfeControl = subset_regime_2019\n  )\n\nrf_subset_test_2019 &lt;- predict(rf_model_subset_2019,testData_2019)\nprint(rf_model_subset_2019)\nconfusionMatrix(rf_subset_test_2019$pred,testData_2019$label)\n\n######################### 2024\n# extract signatures\nsignatures_2024 = raster::extract(STACK_2024, samples ,df=T) # watch for data formats\nsamples_signatures_2024 &lt;- dplyr::inner_join(signatures_2024, samples, by=c(\"ID\"=\"id\"))\nsamples_signatures_2024$geometry &lt;- NULL # set geometry to NULL for model training\n\n# training-test split, p=0.7 -&gt; 70% split\npartitioned_data_2024 &lt;- stratified_partition(samples_signatures_2024,group_col=\"label\", train_ratio=0.7)\ntrainData_2024 &lt;- partitioned_data_2024$train\ntestData_2024 &lt;- partitioned_data_2024$test\ntable(trainData_2024$label)\ntable(testData_2024$label)\n\n# synthetic minority oversampling technique\ntrainData_2024&lt;-performanceEstimation::smote(label ~ .,data=trainData_2024,perc.over=10, perc.under=100)\ntestData_2024&lt;-performanceEstimation::smote(label ~ .,data=testData_2024,perc.over=10,perc.under=100)\n# interpolate missing cloud pixels with class-median-normalization\ntrainData_2024 &lt;- trainData_2024 |&gt; group_by(label) |&gt; mutate(across(where(is.numeric),\n    ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) |&gt; ungroup()\ntestData_2024 &lt;- testData_2024 |&gt; group_by(label) |&gt; mutate(across(where(is.numeric),\n    ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) |&gt; ungroup()\n\n# interpolate NAs with class-median-normalization (NAs -&gt; missing cloud pixels)\ntrainData_2024 &lt;- trainData_2024 |&gt; group_by(label) |&gt; mutate(across(where(is.numeric),\n    ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) |&gt; ungroup()\ntestData_2024 &lt;- testData_2024 |&gt; group_by(label) |&gt; mutate(across(where(is.numeric),\n    ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) |&gt; ungroup()\nwater_2014 &lt;- trainData_2014[trainData_2014$label == \"Water\", ]\nwater_ids &lt;- water_2014$ID\nwater_2024 &lt;- samples_signatures_2024[samples_signatures_2024$ID %in% water_ids, ]\ntrainData_2024 &lt;- rbind(trainData_2024, water_2024)\ntable(trainData_2024$label)\n\n# assign model variables\nresponse  &lt;- c(\"label\")\npredictors_2024 &lt;- c(\n  \"NDVI_2024\", \"BLUE_2024\", \"GREEN_2024\", \"RED_2024\", \n  \"NIR08_2024\", \"SWIR16_2024\", \"SWIR22_2024\", \"DEM\"\n  )\n\n# train classifier\nrf_model_2024 &lt;- caret::train(\n  label~.,\n  data = trainData_2024[, c(predictors_2024, \"label\")], # drop ID var\n  trControl = cv_regime,\n  method    = \"rf\", \n  metric    = 'Kappa', \n  ntree     = 500,\n  tuneLength= 6,\n  importance= T\n  )\n\nrf_test_2024 &lt;- predict(rf_model_2024, testData_2024)\nprint(rf_model_2024) # cv results\nconfusionMatrix(rf_test_2024,testData_2024$label) # blind test results\n\nindex_feature_2024 &lt;- createMultiFolds(trainData_2024$label, times=5) \npredictor_seq_2024 &lt;-seq(from=1, to=length(predictors_2024),by=2)\n\nsubset_regime_2024 &lt;- rfeControl(\n  method=\"LGOCV\",\n  number = 10,\n  verbose=FALSE,\n  functions=rfFuncs,\n  index=index_feature_2024\n  )\n\nrf_model_subset_2024 &lt;- caret::rfe(\n  label~.,\n  data = trainData_2024[, c(predictors_2024, \"label\")], \n  sizes = predictor_seq_2024,\n  metric = \"Kappa\",\n  ntree=500,\n  method=\"rf\",\n  rfeControl = subset_regime_2024\n  )\n\nrf_subset_test_2024 &lt;- predict(rf_model_subset_2024,testData_2024)\nprint(rf_model_subset_2024)\nconfusionMatrix(rf_subset_test_2024$pred,testData_2024$label)\n\n\nLULC_LIBERIA_2014 &lt;- raster::predict(STACK_2014,rf_model_2014, na.rm=TRUE) |&gt; raster::raster()\nraster::writeRaster(LULC_LIBERIA_2014,\"./data/LULC/LULC_LIBERIA_2014-01-04.tif\",\n  format = \"GTiff\", overwrite = T)\n\nLULC_LIBERIA_2019 &lt;- raster::predict(STACK_2019,rf_model_2019, na.rm=TRUE) |&gt; raster::raster() \nraster::writeRaster(LULC_LIBERIA_2019,\"./data/LULC/LULC_LIBERIA_2019-01-02.tif\",\n  format = \"GTiff\",overwrite = T)\n\nLULC_LIBERIA_2024 &lt;- raster::predict(STACK_2024,rf_model_2014, na.rm=TRUE) |&gt; raster::raster() \nraster::writeRaster(LULC_LIBERIA_2024,\"./data/LULC/LULC_LIBERIA_2024-01-16x.tif\",\n  format = \"GTiff\",overwrite = T)\n\n\n\nAppendix II: Runtime snapshot\n\ndevtools::session_info()\n\n\nLULC_PROJECT_2015=terra::rast(\"./data/LULC/LULC_PROJECT_2015.tif\")\nLULC_PROJECT_2019=terra::rast(\"./data/LULC/LULC_PROJECT_2019.tif\")\nLULC_PROJECT_2024=terra::rast(\"./data/LULC/LULC_PROJECT_2024.tif\")\nLULC_PROJECT_2015=terra::project(LULC_PROJECT_2015, \"EPSG:32629\")\nLULC_PROJECT_2024=terra::project(LULC_PROJECT_2024, \"EPSG:32629\")\nLULC_PROJECT_2019=terra::project(LULC_PROJECT_2019, \"EPSG:32629\")\n\nvoi = sf::st_transform(aoi, 32629) |&gt; terra::vect() \nLULC_PROJECT_2015 = terra::crop(LULC_PROJECT_2015, voi, mask=T)\nLULC_PROJECT_2019 = terra::crop(LULC_PROJECT_2019, voi, mask=T)\nLULC_PROJECT_2024 = terra::crop(LULC_PROJECT_2024, voi, mask=T)\n\ncode_dict &lt;- data.frame(\n  id = c(0, 1, 2, 3, 4, 5, 6, 7),\n  label = c(\"Water\", \"Forest\", \"Grassland\", \n            \"Wetland\", \"Croplan\", \"Shrubland\", \n            \"Urban\", \"Bareground\"))\n\nlevels(LULC_PROJECT_2015) &lt;- code_dict\nlevels(LULC_PROJECT_2019) &lt;- code_dict\nlevels(LULC_PROJECT_2024) &lt;- code_dict\n\nterra::plot(LULC_PROJECT_2015, main = \"LULC 2015\")\nterra::plot(LULC_PROJECT_2015, main = \"LULC 2019\")\nterra::plot(LULC_PROJECT_2015, main = \"LULC 2024\")\n\nraster_res &lt;- terra::res(LULC_PROJECT_2015) # 9.933065 x 9.933065 m2\npixel_area_ha &lt;- (raster_res[1] * raster_res[2]) / 10000  # Convert m² to hectares\nfreq_2015 &lt;- as.data.frame(terra::freq(LULC_PROJECT_2015))\nfreq_2015$area_ha &lt;- freq_2015$count * pixel_area_ha\nfreq_2015$percentage &lt;- (freq_2015$area_ha / sum(freq_2015$area_ha)) * 100\nfreq_2015$year &lt;- 2015\n\nfreq_2019 &lt;- as.data.frame(terra::freq(LULC_PROJECT_2019))\nfreq_2019$area_ha &lt;- freq_2019$count * pixel_area_ha\nfreq_2019$percentage &lt;- (freq_2019$area_ha / sum(freq_2019$area_ha)) * 100\nfreq_2019$year &lt;- 2019\n\nfreq_2024 &lt;- as.data.frame(terra::freq(LULC_PROJECT_2024))\nfreq_2024$area_ha &lt;- freq_2024$count * pixel_area_ha\nfreq_2024$percentage &lt;- (freq_2024$area_ha / sum(freq_2024$area_ha)) * 100\nfreq_2024$year &lt;- 2024\n\nland_cover_summary=bind_rows(freq_2015, freq_2019, freq_2024)\nland_cover_summary=merge(land_cover_summary,code_dict, by.x=\"value\",by.y=\"id\",all.x=T)\n\nland_cover_summary_wide &lt;- land_cover_summary %&gt;%\n  select(label, year, area_ha, percentage) %&gt;%\n  pivot_wider(names_from = year, values_from = c(area_ha, percentage))\nprint(land_cover_summary_wide)\n\n\nunique_values_2015 &lt;- terra::unique(LULC_PROJECT_2015)\nunique_values_2019 &lt;- terra::unique(LULC_PROJECT_2019)\nunique_values_2024 &lt;- terra::unique(LULC_PROJECT_2024)\n\nprint(unique_values_2015)\nprint(unique_values_2019)\nprint(unique_values_2024)\n\nprint(terra::is.factor(LULC_PROJECT_2015))\nprint(terra::levels(LULC_PROJECT_2015))\nprint(terra::levels(LULC_PROJECT_2019))\nprint(terra::levels(LULC_PROJECT_2024))\n\n\nlevels(LULC_PROJECT_2015) &lt;- data.frame(ID = code_dict$id, label = code_dict$label)\nlevels(LULC_PROJECT_2019) &lt;- data.frame(ID = code_dict$id, label = code_dict$label)\nlevels(LULC_PROJECT_2024) &lt;- data.frame(ID = code_dict$id, label = code_dict$label)\nfreq_2015 &lt;- as.data.frame(terra::freq(LULC_PROJECT_2015))\nfreq_2019 &lt;- as.data.frame(terra::freq(LULC_PROJECT_2019))\nfreq_2024 &lt;- as.data.frame(terra::freq(LULC_PROJECT_2024))\n\nprint(freq_2015)\nprint(freq_2019)\nprint(freq_2024)\n\nprint(LULC_PROJECT_2015)\nprint(LULC_PROJECT_2019)\nprint(LULC_PROJECT_2024)\n\nplot(LULC_PROJECT_2015, main = \"LULC 2015\")\nplot(LULC_PROJECT_2019, main = \"LULC 2019\")\nplot(LULC_PROJECT_2024, main = \"LULC 2024\")",
    "crumbs": [
      "Home",
      "Risk"
    ]
  },
  {
    "objectID": "deforisk.html#footnotes",
    "href": "deforisk.html#footnotes",
    "title": "Deforestation Risk",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPlease note that model performance metrics differ slightly with each runtime due to Monte Carlo resampling and the number of randomForest decision trees. This is to say that accuracy results in the chunk below may not be precisely matching the in-text reporting here if a new run has been implemented locally on your machine.↩︎",
    "crumbs": [
      "Home",
      "Risk"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "VM0048",
    "section": "",
    "text": "Baseline Emissions\n\n\nA workflow for deriving baseline emissions from reference period compliant the VM0048 (V1.0) consolidated methodology.\n\n\n\n\n\n\nJan 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeforestation Risk\n\n\nA workflow for deriving jurisidictional allocated deforestation risk mapping compliant with Verra’s VMD0055 (V1.1) module.\n\n\n\nSeamus Murphy\n\n\nJan 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeakage Belt\n\n\nA locator map showing the geographic position of a field site within its local and national context, helping users quickly identify its broader location.\n\n\n\nSeamus Murphy\n\n\nJan 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nUncertainty\n\n\nUncertainty checks\n\n\n\n\n\n\nJan 11, 2025\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "VM0048",
    "section": "",
    "text": "VM0047: ARR Project Feasibility\n\n\nFeasibility assessment framework for Afforestation, Reforestation, and Revegetation (ARR) projects under VM0047 methodology. This resource provides standardized protocol for evaluating land degradation, forest change detection algorithms, and baseline establishment procedures, including data processing workflows for satellite imagery analysis and soil carbon stock potential to support project developers in initial feasibility screening.\n\n\n\n\n\nOct 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nVM0010: IFM Reporting Template\n\n\nReporting template for Improved Forest Management (IFM) projects under VM0010 methodology. Provides standardized procedures for forest inventory data collection, carbon stock calculations, emission reduction quantification, and MRV reporting requirements. Includes field measurement protocols, allometric equation selection guidance, statistical sampling design, and automated calculation templates ensuring VCS compliance for commercial forest carbon projects.\n\n\n\n\n\nNov 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nVT0007: JREDD+ Risk Mapping Scripts\n\n\nRisk assessment toolkit for Jurisdictional REDD+ programs implementing VT0007 methodology. Features geospatial analysis scripts for identifying and mapping deforestation risk factors, including proximity to infrastructure, agricultural pressure zones, and historical forest loss patterns. Integrates multiple satellite data sources (Landsat, Sentinel-2, MODIS) with socioeconomic indicators to generate probabilistic risk surfaces supporting strategic intervention planning and monitoring system design for jurisdictional-scale forest conservation programs.\n\n\n\n\n\nNov 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nART-TREES: Repository Demo\n\n\nDemonstration repository showcasing version control best practices for greenhouse gas calculation workflows under ART-TREES methodology. Features standardized Git workflows, automated testing frameworks, and documentation templates ensuring reproducible carbon accounting processes. Includes branching strategies for collaborative development, continuous integration pipelines for calculation validation, and release management procedures supporting transparent and auditable REDD+ project development.\n\n\n\n\n\nAug 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nART-TREES: Allometry Validation\n\n\nValidation and calibration procedures for allometric biomass models compliant with ART-TREES requirements. Technical guidance in model selection methodology for avoiding Types 1-4 statistical errors, bias corrections and hyperparameter tuning.\n\n\n\n\n\nFeb 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nART-TREES: Monte Carlo Tools\n\n\nMonte Carlo simulation methods for estimating uncertainty of REDD+ emission factors and activity data in compliance with ART-TREES Standard V2.0. Features workflows for biomass estimation uncertainty analysis, allometric model error propagation, and activity data variance assessment using 10,000-iteration simulations with 90% confidence intervals. Includes specialized modules for cross-validation bias detection, spatial uncertainty modeling, and automated uncertainty deduction calculations that also incorporate best practices from CEOS LPV Biomass Protocol.\n\n\n\n\n\nDec 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMapping Templates: Site Visualization\n\n\nCollection of interactive cartographic templates and visualization frameworks for forest carbon project mapping. Provides symbology, layout templates, and map generation for site locator, project boundary and watershed delineation.\n\n\n\n\n\nDec 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLiDAR: Forest Height Analysis\n\n\nAdvanced forest structure analysis toolkit combining LiDAR and photogrammetric data for operational forest inventory planning. Features automated tree top detection algorithms, canopy height model generation, and stand structure characterization supporting efficient field plot allocation and sampling design. Includes crown delineation protocols, diameter-height relationship modeling, and accessibility analysis for optimizing field crew deployment in complex terrain environments.\n\n\n\n\n\nOct 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWetland Mapping: SAR & Landsat Workflows\n\n\nFramework for mapping endorheic wetland dynamics, combining Sentinel-1 InSAR processing with Landsat time series analysis (1994-2015), using water extraction indices (NDWI, MNDWI, AWEIsh) and spectral mixture analysis for sub-pixel water detection. Community mapping components include key informant interviews, focus group discussions, and rapid participatory appraisals capturing local ecological knowledge of seasonal fishing migration patterns and traditional resource management practices.\n\n\n\n\n\nJun 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGeoODK Survey: Open Source Build\n\n\nOpen-source mobile data collection framework built on Open Data Kit (GeoODK) architecture for socioeconomic field surveys. Provides customizable survey templates, GPS-enabled data collection forms, with automated quality control protocols, multilingual support, and integrated statistical sampling tools using android mobile devices\n\n\n\n\n\nFeb 5, 2018\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "About",
      "Teaching"
    ]
  },
  {
    "objectID": "assets/inputs/lakes_country.html",
    "href": "assets/inputs/lakes_country.html",
    "title": "VM0048",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "assets/inputs/chilwa_watershed_extent.html",
    "href": "assets/inputs/chilwa_watershed_extent.html",
    "title": "VM0048",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n         0 0     false"
  },
  {
    "objectID": "assets/inputs/rivers_country.html",
    "href": "assets/inputs/rivers_country.html",
    "title": "VM0048",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "baseline.html#introduction",
    "href": "baseline.html#introduction",
    "title": "Baseline Emissions",
    "section": "1. Introduction",
    "text": "1. Introduction\nThis workflow establishes baseline emissions estimates through systematic processing of satellite remote sensing data using cloud-based Earth Engine catalog and python API functions. The methodology integrates Analysis Ready Data (ARD) products with standardized atmospheric correction and quality assessment protocols to support jurisdictional REDD+ baseline development.\n\nStudy Area\nThe analysis focuses on a jurisdictional study area within the Upper Guinea Forest biodiversity hotspot, encompassing critical forest landscapes under conservation management. The region’s tropical climate and complex forest-agricultural mosaics present typical challenges for satellite-based forest monitoring in West Africa. Spatial boundaries were derived from authoritative administrative datasets to ensure compatibility with national forest monitoring systems.\nThe region features:\n\nTropical humid climate with distinct wet and dry seasons\nElevation gradients from coastal plains to interior highlands\nMixed forest-agricultural landscapes with varying management intensities\nComplex hydrology including major river systems and wetland areas",
    "crumbs": [
      "Home",
      "Baseline"
    ]
  },
  {
    "objectID": "baseline.html#method",
    "href": "baseline.html#method",
    "title": "Baseline Emissions",
    "section": "2. Method",
    "text": "2. Method\n\nEarth Engine\nInitial setup requires authentication with Google Earth Engine services to access satellite data archives and cloud computing resources.\n\n!earthengine authenticate\n#!ee.Authenticate() # deprecated in certain Colab environments\nee.Initialize(project = \"murphys-deforisk\")\n\n\n\nArea of Interest\nSpatial boundaries are established using the Global Administrative Unit Layers (GAUL) dataset, providing standardized administrative boundaries for consistent geographic analysis.\n\n\nNA Deleting source `./assets/AOI/aoi_country.shp' using driver `ESRI Shapefile'\nNA Writing layer `aoi_country' to data source \nNA   `./assets/AOI/aoi_country.shp' using driver `ESRI Shapefile'\nNA Writing 1 features with 2 fields and geometry type Multi Polygon.\n\n\nNA Deleting source `./assets/AOI/aoi_states.shp' using driver `ESRI Shapefile'\nNA Writing layer `aoi_states' to data source \nNA   `./assets/AOI/aoi_states.shp' using driver `ESRI Shapefile'\nNA Writing 1 features with 11 fields and geometry type Polygon.\n\n\n\n\n\n\n\naoi_country = ee.FeatureCollection('FAO/GAUL/2015/level1').filter(\n    ee.Filter.equals(\"ADM0_NAME\", \"Liberia\"))\naoi_states_all = country.aggregate_array('ADM1_NAME').distinct().getInfo()\naoi_states =  ee.FeatureCollection('FAO/GAUL/2015/level1').filter(\n    ee.Filter.equals('ADM1_NAME', \"Barima Waini (region N°1)\"))\n\nred = {\"color\": \"red\", \"width\": 1, \"lineType\": \"solid\", \"fillColor\": \"00000000\"}\npurple = {\"color\": \"purple\", \"width\": 2, \"lineType\": \"solid\", \"fillColor\": \"00000000\"}\ncountry_label = ee.FeatureCollection([ee.Feature(\n    country.geometry().centroid(), \n    {'country_name': country.first().get(\"ADM0_NAME\").getInfo()})])\n\nMap = geemap.Map()\nMap.centerObject(country, 6)\nMap.add_basemap('OpenTopoMap')\nMap.addLayer(aoi_country.style(**purple), {}, \"Guyana\")\nMap.addLayer(aoi_state.style(**red), {}, \"Barima Waini (region N°1)\")\nMap\n\nFigure 1: Interactive map showing area of interest polygons\n\n\nImagery Processing\nRobust cloud masking is essential for tropical forest monitoring where persistent cloud cover poses significant challenges. The implemented approach uses Landsat Collection-2 QA_PIXEL and QA_RADSAT bands to identify and remove cloud-contaminated observations. In the following, pixel quality assessment was implemented using:\n\nQA_PIXEL: Pixel quality flags for cloud/shadow detection\nQA_RADSAT: Radiometric saturation assessment\nSurface reflectance scaling with Collection-2 coefficients\nThermal band scaling for surface temperature\nNDVI calculation for vegetation assessment\n\n\n# derive masking, scaling, and ndvi function\ndef maskL8sr(image):\n    qaMask = image.select('QA_PIXEL').bitwiseAnd(int('11111', 2)).eq(0)\n    saturationMask = image.select('QA_RADSAT').eq(0)\n    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n    thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n    ndvi = image.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI').toFloat()\n    image = image.addBands(opticalBands, None, True) \\\n                 .addBands(thermalBands, None, True) \\\n                 .addBands(ndvi)\n    return image.select(\n        ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'NDVI'],\n        ['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']\n    ).updateMask(qaMask).updateMask(saturationMask)\n\n# create collections for 2014 and 2024\ncollection_2014 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n                    .filterDate('2014-01-01', '2014-12-31') \\\n                    .filterBounds(country) \\\n                    .map(maskL8sr)\n\ncollection_2019 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n                    .filterDate('2019-01-01', '2019-12-31') \\\n                    .filterBounds(country) \\\n                    .map(maskL8sr)\n\ncollection_2024 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n                    .filterDate('2024-01-01', '2024-12-31') \\\n                    .filterBounds(country) \\\n                    .map(maskL8sr)\n\n# median composites for 2014 and 2024\ncomposite_2014 = collection_2014.select(['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']).median().clip(country).toFloat()\ncomposite_2019 = collection_2019.select(['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']).median().clip(country).toFloat()\ncomposite_2024 = collection_2024.select(['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']).median().clip(country).toFloat()\n\n\n# Visualization parameters\nndviVis = {'min': 0.2, 'max': 0.8, 'palette': ['red', 'yellow', 'green']}\n\n# Create histogram for 2014\nplt.figure()\nplt.hist(composite_2014.select('NDVI'), color='springgreen', edgecolor='black')\nplt.title('NDVI Distribution, 2014')\nplt.xlabel('NDVI Value')\nplt.ylabel('Frequency')\nplt.savefig('NDVI_2014_histogram.png')\nplt.close()\n\n# Create histogram for 2019\nplt.figure()\nplt.hist(composite_2019.select('NDVI'), color='springgreen', edgecolor='black')\nplt.title('NDVI Distribution, 2019')\nplt.xlabel('NDVI Value')\nplt.ylabel('Frequency')\nplt.savefig('NDVI_2019_histogram.png')\nplt.close()\n\n# Create histogram for 2024\nplt.figure()\nplt.hist(composite_2024.select('NDVI'), color='springgreen', edgecolor='black')\nplt.title('NDVI Distribution, 2024')\nplt.xlabel('NDVI Value')\nplt.ylabel('Frequency')\nplt.savefig('NDVI_2024_histogram.png')\nplt.close()\n\n# --- Plot Rasters ---\n# The xlim/ylim parameters in R's `plot` function are equivalent to `bounds` or `extent` in Python.\n# You need to manually calculate the extent for the desired output.\n# The `plot` function in `rasterio` and `matplotlib.pyplot` handle the visualization.\nwith rasterio.open(composite_2014.select('NDVI')) as src:\n    raster_data = src.read(1)\n    extent = [src.bounds.left, src.bounds.right, src.bounds.bottom, src.bounds.top]\n    axes[1, 0].imshow(raster_data, cmap='viridis', extent=extent)\n    axes[1, 0].set_title(\"NDVI, 2014\")\n    axes[1, 0].set_xlim(-11.5, -7.5)\n    axes[1, 0].set_ylim(4.1, 8.6)\n    axes[1, 0].set_xlabel(\"Longitude\")\n    axes[1, 0].set_ylabel(\"Latitude\")\n\nwith rasterio.open(composite_2019.select('NDVI')) as src:\n    raster_data = src.read(1)\n    extent = [src.bounds.left, src.bounds.right, src.bounds.bottom, src.bounds.top]\n    axes[1, 1].imshow(raster_data, cmap='viridis', extent=extent)\n    axes[1, 1].set_title(\"NDVI, 2019\")\n    axes[1, 1].set_xlim(-11.5, -7.5)\n    axes[1, 1].set_ylim(4.1, 8.6)\n    axes[1, 1].set_xlabel(\"Longitude\")\n    axes[1, 1].set_ylabel(\"Latitude\")\n\nwith rasterio.open(composite_2024.select('NDVI')) as src:\n    raster_data = src.read(1)\n    extent = [src.bounds.left, src.bounds.right, src.bounds.bottom, src.bounds.top]\n    axes[1, 2].imshow(raster_data, cmap='viridis', extent=extent)\n    axes[1, 2].set_title(\"NDVI, 2024\")\n    axes[1, 2].set_xlim(-11.5, -7.5)\n    axes[1, 2].set_ylim(4.1, 8.6)\n    axes[1, 2].set_xlabel(\"Longitude\")\n    axes[1, 2].set_ylabel(\"Latitude\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Multi-temporal satellite composites showing NDVI composites across the baseline period.\n\n\nMetadata QA/QC\nMetadata extraction ensures data provenance and enables quality control throughout the processing workflow. This steps comes in handy before exporting large collections from earth engine to personal drive, such as this one (&gt;10GB).\n\n# confirm dates, scene IDs, band names of images\nfirstImage_2014 = collection_2014.first()\nsceneId_2014 = firstImage_2014.get('system:index').getInfo()\nprint(f\"Scene ID for collection_2014: {sceneId_2014}\")\n\nfirstImage_2019 = collection_2019.first()\nsceneId_2019 = firstImage_2019.get('system:index').getInfo()\nprint(f\"Scene ID for collection_2019: {sceneId_2019}\")\n\nfirstImage_2024 = collection_2024.first()\nsceneId_2024 = firstImage_2024.get('system:index').getInfo()\nprint(f\"Scene ID for collection_2024: {sceneId_2024}\")\n\nbandNames_2014 = composite_2014.bandNames().getInfo()\nprint(f\"Band names: {bandNames_2014}\")\n\nbandNames_2019 = composite_2019.bandNames().getInfo()\nprint(f\"Band names: {bandNames_2019}\")\n\nbandNames_2024 = composite_2024.bandNames().getInfo()\nprint(f\"Band names: {bandNames_2024}\")\n\nScene ID for collection_2014: LC08_198055_20140104\nScene ID for collection_2019: LC08_198055_20190102\nScene ID for collection_2024: LC08_198055_20240116\nBand names: ['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']\nBand names: ['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']\nBand names: ['BLUE', 'GREEN', 'RED', 'NIR08', 'SWIR16', 'SWIR22', 'NDVI']\nResults confirm consistent band availability and standardized naming conventions across all periods.\n\n\nExport Rasters\nCloud-optimized GeoTIFF format ensures efficient data access and interoperability with downstream analysis tools. The following export workflow also implements systematic file naming conventions suitable for metadata parsing required in remote sensing packages.\n\nfrom datetime import datetime\n\n# extract pathrow and date from scene ID\ndef get_pathrow_date(image_collection):\n  first_image = image_collection.first()\n  scene_id = first_image.get('system:index').getInfo()\n  parts = scene_id.split('_')\n  pathrow = parts[1]\n  date_str = parts[2]\n  date_obj = datetime.strptime(date_str, '%Y%m%d')\n  date = date_obj.strftime('%Y-%m-%d')\n  return pathrow, date\n\n# define export parameters\ndef define_export_params(image, pathrow, date, band_name):\n  description = f'composite_{date}_{band_name if isinstance(band_name, str) else \"RGB\"}_export'[:100]\n  return {\n    'image': image.select(band_name),\n    'description': description,\n    'folder': 'VT0007-deforestation-map',\n    'fileNamePrefix': f'LANDSAT_TM-ETM-OLI_{pathrow}_{band_name if isinstance(band_name, str) else \"RGB\"}_{date}',\n    'scale': 30,\n    'region': country.geometry(),\n    'maxPixels': 1e13,\n    'fileFormat': 'GeoTIFF',\n    'formatOptions': {'cloudOptimized': True}\n  }\n\n# get pathrow and date for each collection\npathrow_2014, date_2014 = get_pathrow_date(collection_2014)\npathrow_2019, date_2019 = get_pathrow_date(collection_2019)\npathrow_2024, date_2024 = get_pathrow_date(collection_2024)\n\n# get band names\nbandNames_2014 = composite_2014.bandNames().getInfo()\nbandNames_2019 = composite_2019.bandNames().getInfo()\nbandNames_2024 = composite_2024.bandNames().getInfo()\n\n# export to cloud bucket\nfor band_name in bandNames_2014:\n    export_params_2014 = define_export_params(composite_2014, pathrow_2014, date_2014, band_name)\n    task_2014 = ee.batch.Export.image.toDrive(**export_params_2014)\n    task_2014.start()\n    print(f\"Exporting 2014 image for band {band_name}. Task ID: {task_2014.id}\")\n\nfor band_name in bandNames_2019:\n    export_params_2019 = define_export_params(composite_2019, pathrow_2019, date_2019, band_name)\n    task_2019 = ee.batch.Export.image.toDrive(**export_params_2019)\n    task_2019.start()\n    print(f\"Exporting 2019 image for band {band_name}. Task ID: {task_2019.id}\")\n\nfor band_name in bandNames_2024:\n    export_params_2024 = define_export_params(composite_2024, pathrow_2024, date_2024, band_name)\n    task_2024 = ee.batch.Export.image.toDrive(**export_params_2024)\n    task_2024.start()\n    print(f\"Exporting 2024 image for band {band_name}. Task ID: {task_2024.id}\")\n\nexport_params_2014_rgb = define_export_params(composite_2014, pathrow_2014, date_2014, ['RED', 'GREEN', 'BLUE'])\nexport_params_2014_rgb['image'] = composite_2014.visualize(**rgbVis)\ntask_2014_rgb = ee.batch.Export.image.toDrive(**export_params_2014_rgb)\ntask_2014_rgb.start()\nprint(f\"Exporting 2014 RGB image. Task ID: {task_2014_rgb.id}\")\n\nexport_params_2019_rgb = define_export_params(composite_2019, pathrow_2019, date_2019, ['RED', 'GREEN', 'BLUE'])\nexport_params_2019_rgb['image'] = composite_2019.visualize(**rgbVis)\ntask_2019_rgb = ee.batch.Export.image.toDrive(**export_params_2019_rgb)\ntask_2019_rgb.start()\nprint(f\"Exporting 2019 RGB image. Task ID: {task_2019_rgb.id}\")\n\nexport_params_2024_rgb = define_export_params(composite_2024, pathrow_2024, date_2024, ['RED', 'GREEN', 'BLUE'])\nexport_params_2024_rgb['image'] = composite_2024.visualize(**rgbVis)\ntask_2024_rgb = ee.batch.Export.image.toDrive(**export_params_2024_rgb)\ntask_2024_rgb.start()\nprint(f\"Exporting 2024 RGB image. Task ID: {task_2024_rgb.id}\")\n\nExporting 2014 image for band BLUE. Task ID: IRDIBYVEMKUAVGKZQ5HXKPBC\nExporting 2014 image for band GREEN. Task ID: EEWSBCRWWKUPRQWV4TQZ3B6C\nExporting 2014 image for band RED. Task ID: WXC6RRPJFOILRBYH5C3WOKTP\nExporting 2014 image for band NIR08. Task ID: 6PKRX3FP7ABDPURUHPZYDPWE\nExporting 2014 image for band SWIR16. Task ID: XK6EE5UFGWCCG7QSIDKKTJF5\nExporting 2014 image for band SWIR22. Task ID: W57UBUFB7HRB3EKMLJHNEW6H\nExporting 2014 image for band NDVI. Task ID: ZY7IGAO2K3CIVCUGRXKDNXVA\nExporting 2019 image for band BLUE. Task ID: E3J5YYQM2ZI2HSRDCBPRBWI4\nExporting 2019 image for band GREEN. Task ID: XVQICHKGYHHCLCFS2H4DEVUK\nExporting 2019 image for band RED. Task ID: 7ISMPTUBERKDVN2OZ2DR7U56\nExporting 2019 image for band NIR08. Task ID: 5QGL7XCZ6QPT2NKXEZFKXIPR\nExporting 2019 image for band SWIR16. Task ID: 4TDZ3QLG3JXJ5DXGZIIPPQAX\nExporting 2019 image for band SWIR22. Task ID: SK4Q6PS6IXIVWUICHTRX55UL\nExporting 2019 image for band NDVI. Task ID: 4XWVQ4UNRFEA4JV25IL22THI\nExporting 2024 image for band BLUE. Task ID: BITRT6BI7PKM6P6Z3FWPTEEL\nExporting 2024 image for band GREEN. Task ID: 2VUH34ENCZVIAYSRD3BJQG2G\nExporting 2024 image for band RED. Task ID: 2U5PRUP3VUAJIIC6WPR7L4IG\nExporting 2024 image for band NIR08. Task ID: Y2M2FPLUNIDRRKMEYTWWDBPD\nExporting 2024 image for band SWIR16. Task ID: WPGNYNGXEOCB67CX6VGCPOLG\nExporting 2024 image for band SWIR22. Task ID: L43YZOYPUYVWUMGJCCHS46UA\nExporting 2024 image for band NDVI. Task ID: 3LRYV6LDKHOGQ2TJ4Z3FV4QT\nExporting 2014 RGB image. Task ID: WWHVXMWV2RUT5IKPZNVCFQLA\nExporting 2024 RGB image. Task ID: DA6UDTKJM5NG4QQHHLQ7S2KZ\nThe export generates 18 individual band files plus 2 RGB and 3 NDVI composites, totaling 23 data products spanning the 10-year baseline period. Each file maintains consistent 30-meter spatial resolution and geographic projection for seamless integration with subsequent analysis workflows.\n\n\nTraining Samples\nTraining samples were developed from the global land cover time series dataset (GLanCE) (Stanimirova et al. 2023). This approach addresses class migration and temporal consistency requirements for baseline period analysis. Although not mandatory (verraVM0048ReducingEmissions2023a?; verraVMD0055EstimationEmission2024?; Verra 2021), we recommend incorporating processing steps or training sample sources that include feature class migration checks. The following showcases improvements in accuracy metrics due to this remote sensing best practice.\nTable 1 Class conversions applied to GLanCE training samples\n\n\n\n\n\n\n\n\nGLanCE classes\nConverted classes\nGLanCE definitions\n\n\nBarren (4)\nBareground (0)\nAreas of soils, sand, or rocks where &lt;10% is vegetated\n\n\nHerbaceous (7)\nRegrowth (1)\nAreas of &lt;30% tree, &gt;10% vegetation, but &lt;10% shrub\n\n\nShrublands (6)\nFarmbush (2)\nAreas of &lt;30% tree, &gt;10% vegetation, & &gt;10% shrub\n\n\nTree Cover (5)\nForest (3)\nAreas of tree cover &gt; 30%.\n\n\nWater (1)\nWater (4)\nAreas covered with water year-round (lakes & streams)\n\n\nDeveloped (3)\nUrban (99)\nAreas covered with structures, built-up\n\n\nIce/Snow (2)\nIce/Snow (88)\nAreas of snow cover &gt; 50% year-round\n\n\n\n\n# import & tidy samples\nsamples_raw = read.csv(\"./assets/LULC/inputs/training_samples/glance_training.csv\")\nsamples_clean = samples_raw |&gt;\n  dplyr::select(Lon, Lat, Glance_Class_ID_level1, Start_Year, End_Year)|&gt;\n  dplyr::rename(longitude = Lon) |&gt;\n  dplyr::rename(latitude = Lat) |&gt;\n  dplyr::rename(label_old = Glance_Class_ID_level1) |&gt;\n  dplyr::mutate(start_date = as.Date(paste(Start_Year,\"01\",\"01\",sep = \"-\")))|&gt;\n  dplyr::mutate(end_date = as.Date(paste(End_Year, \"01\", \"01\", sep = \"-\")))|&gt;\n  dplyr::select(longitude, latitude, start_date, end_date, label_old)|&gt;\n  dplyr::mutate(code = case_when(\n    label_old == '4' ~ 0, \n    label_old == '7' ~ 1, \n    label_old == '6' ~ 2, \n    label_old == '5' ~ 3, \n    label_old == '1' ~ 4, \n    label_old == '3' ~ 99, \n    label_old == '2' ~ 88)\n    ) |&gt;\n  dplyr::mutate(label = case_when(\n    code == '0'  ~ \"Bareground\", \n    code == '1'  ~ \"Regrowth\", \n    code == '2'  ~ \"Farmbush\", \n    code == '3'  ~ \"Forest\", \n    code == '4'  ~ \"Water\", \n    code == '99' ~ \"Urban\", \n    code == '88' ~ \"Snow\")\n    ) |&gt; \n  dplyr::mutate(label = as.factor(label)) |&gt;\n  dplyr::mutate(id = row_number()) |&gt; \n  dplyr::select(-label_old) |&gt;\n  dplyr::select(-code)\n# filter to project\nsamples_sf       = sf::st_as_sf(samples_clean, crs = 4326, coords = c(\"longitude\", \"latitude\"))\nsamples_clipped  = sf::st_intersection(samples_sf, country) # n = 364\nsamples_country  = samples_sf[samples_clipped, ] |&gt; sf::st_transform(4326)\nsamples          = sf::st_crop(samples_country, st_bbox(country))\nsf::st_write(samples, \"./assets/LULC/inputs/training_samples/glance_spatial_clip.shp\", delete_dsn = T)\nwrite.csv(samples, \"./assets/LULC/inputs/training_samples/glance_spatial_clip.csv\", row.names = F)\ndplyr::count(samples, label)\n\n\n\nNA Error in read.table(file = file, header = header, sep = sep, quote = quote, : duplicate 'row.names' are not allowed\n\n\nNA Error: object 'samples' not found\n\n\n\n\nRuntime Info\n\nsession_info.show()\n\n-----\nbackports           NA\nee                  1.2.0\ngeemap              0.16.4\ngoogle              NA\nipyleaflet          0.19.2\nnumpy               1.26.4\nsession_info        1.0.0\n-----\nClick to view modules imported as dependencies\n-----\nIPython             7.34.0\njupyter_client      6.1.12\njupyter_core        5.7.2\njupyterlab          4.3.3\nnotebook            6.5.5\n-----\nPython 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\nLinux-6.1.85+-x86_64-with-glibc2.35\n-----\nSession information updated at 2024-12-15 22:22\n\ndevtools::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.0 (2023-04-21)\n os       macOS 15.6.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Vancouver\n date     2025-08-26\n pandoc   3.6.1 @ /usr/local/bin/ (via rmarkdown)\n quarto   1.7.33 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package           * version    date (UTC) lib source\n abind               1.4-8      2024-09-12 [1] CRAN (R 4.3.3)\n animation         * 2.7        2021-10-07 [1] CRAN (R 4.3.3)\n backports           1.5.0      2024-05-23 [1] CRAN (R 4.3.3)\n base64enc           0.1-3      2015-07-28 [1] CRAN (R 4.3.3)\n bibtex            * 0.5.1      2023-01-26 [1] CRAN (R 4.3.3)\n BIOMASS           * 2.2.4      2025-05-19 [1] CRAN (R 4.3.3)\n cachem              1.1.0      2024-05-16 [1] CRAN (R 4.3.3)\n cellranger          1.1.0      2016-07-27 [1] CRAN (R 4.3.0)\n chromote            0.5.1      2025-04-24 [1] CRAN (R 4.3.3)\n class               7.3-23     2025-01-01 [1] CRAN (R 4.3.3)\n classInt            0.4-11     2025-01-08 [1] CRAN (R 4.3.3)\n cli                 3.6.5      2025-04-23 [1] CRAN (R 4.3.3)\n codetools           0.2-20     2024-03-31 [1] CRAN (R 4.3.1)\n colorspace          2.1-1      2024-07-26 [1] CRAN (R 4.3.3)\n cols4all            0.8        2024-10-16 [1] CRAN (R 4.3.3)\n crosstalk           1.2.1      2023-11-23 [1] CRAN (R 4.3.3)\n data.table          1.17.8     2025-07-10 [1] CRAN (R 4.3.3)\n DBI                 1.2.3      2024-06-02 [1] CRAN (R 4.3.3)\n devtools            2.4.5      2022-10-11 [1] CRAN (R 4.3.0)\n dials               1.4.0      2025-02-13 [1] CRAN (R 4.3.3)\n DiceDesign          1.10       2023-12-07 [1] CRAN (R 4.3.3)\n dichromat           2.0-0.1    2022-05-02 [1] CRAN (R 4.3.3)\n digest              0.6.37     2024-08-19 [1] CRAN (R 4.3.3)\n dplyr             * 1.1.4      2023-11-17 [1] CRAN (R 4.3.1)\n e1071               1.7-16     2024-09-16 [1] CRAN (R 4.3.3)\n ellipsis            0.3.2      2021-04-29 [1] CRAN (R 4.3.3)\n evaluate            1.0.4      2025-06-18 [1] CRAN (R 4.3.3)\n extrafont         * 0.19       2023-01-18 [1] CRAN (R 4.3.3)\n extrafontdb         1.0        2012-06-11 [1] CRAN (R 4.3.3)\n farver              2.1.2      2024-05-13 [1] CRAN (R 4.3.3)\n fastmap             1.2.0      2024-05-15 [1] CRAN (R 4.3.3)\n forcats             1.0.0      2023-01-29 [1] CRAN (R 4.3.0)\n foreach             1.5.2      2022-02-02 [1] CRAN (R 4.3.3)\n fs                  1.6.6      2025-04-12 [1] CRAN (R 4.3.3)\n furrr               0.3.1      2022-08-15 [1] CRAN (R 4.3.0)\n future              1.40.0     2025-04-10 [1] CRAN (R 4.3.3)\n future.apply        1.11.3     2024-10-27 [1] CRAN (R 4.3.3)\n generics            0.1.4      2025-05-09 [1] CRAN (R 4.3.3)\n geodata           * 0.6-2      2024-06-10 [1] CRAN (R 4.3.3)\n ggplot2           * 3.5.2      2025-04-09 [1] CRAN (R 4.3.3)\n globals             0.17.0     2025-04-16 [1] CRAN (R 4.3.3)\n glue                1.8.0      2024-09-30 [1] CRAN (R 4.3.3)\n gower               1.0.2      2024-12-17 [1] CRAN (R 4.3.3)\n GPfit               1.0-9      2025-04-12 [1] CRAN (R 4.3.3)\n gridExtra           2.3        2017-09-09 [1] CRAN (R 4.3.3)\n gtable              0.3.6      2024-10-25 [1] CRAN (R 4.3.3)\n hardhat             1.4.1      2025-01-31 [1] CRAN (R 4.3.3)\n hms                 1.1.3      2023-03-21 [1] CRAN (R 4.3.0)\n htmltools         * 0.5.8.1    2024-04-04 [1] CRAN (R 4.3.3)\n htmlwidgets         1.6.4      2023-12-06 [1] CRAN (R 4.3.1)\n httpuv              1.6.16     2025-04-16 [1] CRAN (R 4.3.3)\n ipred               0.9-15     2024-07-18 [1] CRAN (R 4.3.3)\n iterators           1.0.14     2022-02-05 [1] CRAN (R 4.3.3)\n janitor           * 2.2.1      2024-12-22 [1] CRAN (R 4.3.3)\n jquerylib           0.1.4      2021-04-26 [1] CRAN (R 4.3.3)\n jsonlite            2.0.0      2025-03-27 [1] CRAN (R 4.3.3)\n kableExtra        * 1.4.0      2024-01-24 [1] CRAN (R 4.3.1)\n KernSmooth          2.23-26    2025-01-01 [1] CRAN (R 4.3.3)\n knitr             * 1.50       2025-03-16 [1] CRAN (R 4.3.3)\n later               1.4.2      2025-04-08 [1] CRAN (R 4.3.3)\n lattice             0.22-7     2025-04-02 [1] CRAN (R 4.3.3)\n lava                1.8.1      2025-01-12 [1] CRAN (R 4.3.3)\n leafem              0.2.4      2025-05-01 [1] CRAN (R 4.3.3)\n leaflegend          1.2.1      2024-05-09 [1] CRAN (R 4.3.3)\n leaflet             2.2.2      2024-03-26 [1] CRAN (R 4.3.1)\n leaflet.providers   2.0.0      2023-10-17 [1] CRAN (R 4.3.3)\n leafsync            0.1.0      2019-03-05 [1] CRAN (R 4.3.0)\n lhs                 1.2.0      2024-06-30 [1] CRAN (R 4.3.3)\n lifecycle           1.0.4      2023-11-07 [1] CRAN (R 4.3.3)\n listenv             0.9.1      2024-01-29 [1] CRAN (R 4.3.3)\n logger              0.4.0      2024-10-22 [1] CRAN (R 4.3.3)\n lubridate           1.9.4      2024-12-08 [1] CRAN (R 4.3.3)\n lwgeom              0.2-14     2024-02-21 [1] CRAN (R 4.3.1)\n magrittr            2.0.3      2022-03-30 [1] CRAN (R 4.3.3)\n maptiles            0.10.0     2025-05-07 [1] CRAN (R 4.3.3)\n MASS                7.3-60.0.1 2024-01-13 [1] CRAN (R 4.3.1)\n Matrix              1.6-5      2024-01-11 [1] CRAN (R 4.3.1)\n memoise             2.0.1      2021-11-26 [1] CRAN (R 4.3.3)\n microbenchmark      1.5.0      2024-09-04 [1] CRAN (R 4.3.3)\n mime                0.13       2025-03-17 [1] CRAN (R 4.3.3)\n miniUI              0.1.2      2025-04-17 [1] CRAN (R 4.3.3)\n minpack.lm          1.2-4      2023-09-11 [1] CRAN (R 4.3.3)\n nnet                7.3-20     2025-01-01 [1] CRAN (R 4.3.3)\n openxlsx          * 4.2.8      2025-01-25 [1] CRAN (R 4.3.3)\n pacman              0.5.1      2019-03-11 [1] CRAN (R 4.3.3)\n parallelly          1.45.0     2025-06-02 [1] CRAN (R 4.3.3)\n parsnip             1.3.2      2025-05-28 [1] CRAN (R 4.3.3)\n pillar              1.11.0     2025-07-04 [1] CRAN (R 4.3.3)\n pkgbuild            1.4.8      2025-05-26 [1] CRAN (R 4.3.3)\n pkgconfig           2.0.3      2019-09-22 [1] CRAN (R 4.3.3)\n pkgload             1.4.0      2024-06-28 [1] CRAN (R 4.3.3)\n plyr                1.8.9      2023-10-02 [1] CRAN (R 4.3.3)\n png                 0.1-8      2022-11-29 [1] CRAN (R 4.3.3)\n processx            3.8.6      2025-02-21 [1] CRAN (R 4.3.3)\n prodlim             2025.04.28 2025-04-28 [1] CRAN (R 4.3.3)\n profvis             0.4.0      2024-09-20 [1] CRAN (R 4.3.3)\n PROJ              * 0.6.0      2025-04-03 [1] CRAN (R 4.3.3)\n proj4               1.0-15     2025-03-21 [1] CRAN (R 4.3.3)\n promises            1.3.3      2025-05-29 [1] CRAN (R 4.3.3)\n proxy               0.4-27     2022-06-09 [1] CRAN (R 4.3.3)\n ps                  1.9.1      2025-04-12 [1] CRAN (R 4.3.3)\n purrr               1.1.0      2025-07-10 [1] CRAN (R 4.3.0)\n R6                  2.6.1      2025-02-15 [1] CRAN (R 4.3.3)\n rappdirs            0.3.3      2021-01-31 [1] CRAN (R 4.3.3)\n raster              3.6-32     2025-03-28 [1] CRAN (R 4.3.3)\n RColorBrewer        1.1-3      2022-04-03 [1] CRAN (R 4.3.3)\n Rcpp                1.1.0      2025-07-02 [1] CRAN (R 4.3.3)\n recipes             1.3.1      2025-05-21 [1] CRAN (R 4.3.3)\n remotes             2.5.0      2024-03-17 [1] CRAN (R 4.3.3)\n reproj            * 0.7.0      2024-06-11 [1] CRAN (R 4.3.3)\n reticulate          1.42.0     2025-03-25 [1] CRAN (R 4.3.3)\n rlang               1.1.6      2025-04-11 [1] CRAN (R 4.3.3)\n rmarkdown           2.29       2024-11-04 [1] CRAN (R 4.3.3)\n rpart               4.1.24     2025-01-07 [1] CRAN (R 4.3.3)\n rsample             1.3.0      2025-04-02 [1] CRAN (R 4.3.3)\n rstudioapi          0.17.1     2024-10-22 [1] CRAN (R 4.3.3)\n Rttf2pt1            1.3.12     2023-01-22 [1] CRAN (R 4.3.3)\n s2                  1.1.9      2025-05-23 [1] CRAN (R 4.3.3)\n scales              1.4.0      2025-04-24 [1] CRAN (R 4.3.3)\n sessioninfo         1.2.3      2025-02-05 [1] CRAN (R 4.3.3)\n sf                * 1.0-22     2025-08-25 [1] Github (r-spatial/sf@3660edf)\n shiny               1.11.1     2025-07-03 [1] CRAN (R 4.3.3)\n snakecase           0.11.1     2023-08-27 [1] CRAN (R 4.3.0)\n sp                  2.2-0      2025-02-01 [1] CRAN (R 4.3.3)\n spacesXYZ           1.6-0      2025-06-06 [1] CRAN (R 4.3.3)\n stars               0.6-8      2025-02-01 [1] CRAN (R 4.3.3)\n stringi             1.8.7      2025-03-27 [1] CRAN (R 4.3.3)\n stringr             1.5.1      2023-11-14 [1] CRAN (R 4.3.1)\n survival            3.8-3      2024-12-17 [1] CRAN (R 4.3.3)\n svglite             2.2.1      2025-05-12 [1] CRAN (R 4.3.3)\n systemfonts         1.2.3      2025-04-30 [1] CRAN (R 4.3.3)\n terra             * 1.8-60     2025-07-21 [1] CRAN (R 4.3.0)\n textshaping         1.0.1      2025-05-01 [1] CRAN (R 4.3.3)\n tibble              3.3.0      2025-06-08 [1] CRAN (R 4.3.3)\n tidyr               1.3.1      2024-01-24 [1] CRAN (R 4.3.1)\n tidyselect          1.2.1      2024-03-11 [1] CRAN (R 4.3.1)\n timechange          0.3.0      2024-01-18 [1] CRAN (R 4.3.3)\n timeDate            4041.110   2024-09-22 [1] CRAN (R 4.3.3)\n tinytex           * 0.57       2025-04-15 [1] CRAN (R 4.3.3)\n tmap              * 4.1        2025-05-12 [1] CRAN (R 4.3.3)\n tmaptools         * 3.2        2025-01-13 [1] CRAN (R 4.3.3)\n tune              * 1.3.0      2025-02-21 [1] CRAN (R 4.3.3)\n units               0.8-7      2025-03-11 [1] CRAN (R 4.3.3)\n urlchecker          1.0.1      2021-11-30 [1] CRAN (R 4.3.3)\n useful            * 1.2.6.1    2023-10-24 [1] CRAN (R 4.3.1)\n usethis             3.1.0      2024-11-26 [1] CRAN (R 4.3.3)\n vctrs               0.6.5      2023-12-01 [1] CRAN (R 4.3.3)\n viridisLite         0.4.2      2023-05-02 [1] CRAN (R 4.3.3)\n webshot           * 0.5.5      2023-06-26 [1] CRAN (R 4.3.0)\n webshot2          * 0.1.2      2025-04-23 [1] CRAN (R 4.3.3)\n websocket           1.4.4      2025-04-10 [1] CRAN (R 4.3.3)\n withr               3.0.2      2024-10-28 [1] CRAN (R 4.3.3)\n wk                  0.9.4      2024-10-11 [1] CRAN (R 4.3.3)\n workflows           1.2.0      2025-02-19 [1] CRAN (R 4.3.3)\n xfun                0.53       2025-08-19 [1] CRAN (R 4.3.0)\n XML                 3.99-0.18  2025-01-01 [1] CRAN (R 4.3.3)\n xml2                1.3.8      2025-03-14 [1] CRAN (R 4.3.3)\n xtable              1.8-4      2019-04-21 [1] CRAN (R 4.3.3)\n yaml                2.3.10     2024-07-26 [1] CRAN (R 4.3.3)\n yardstick           1.3.2      2025-01-22 [1] CRAN (R 4.3.3)\n zip                 2.3.3      2025-05-13 [1] CRAN (R 4.3.3)\n\n [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\n * ── Packages attached to the search path.\n\n──────────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "Home",
      "Baseline"
    ]
  }
]